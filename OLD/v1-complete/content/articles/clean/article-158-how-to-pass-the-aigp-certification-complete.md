
![Article 158: How to Pass the AIGP Certification — Complete Study Guide]({{IMAGE_PLACEHOLDER_article-158-how-to-pass-the-aigp-certification-complete-stud}})

---
tldr: "This article provides a comprehensive framework for AI governance and implementation. It provides valuable insights for practitioners and decision-makers in the AI governance space."
category: "AI Risks & Principles"
learning_objectives:

  - "Understand the key concepts and principles of ai governance principles"
  - "Implement implementation strategies in real-world scenarios"
  - "Evaluate compliance frameworks for organizational compliance"
seo_keywords:

  - "article"
  - "pass"
  - "AI governance"
  - "certification"
  - "introduction the"
word_count: 262
processed_date: "2025-12-18T20:00:54.607Z"
---


## About the AIGP Certification


### What is AIGP?

```
AIGP CERTIFICATION OVERVIEW

Credential:        AI Governance Professional (AIGP)
Issuing Body:      IAPP (International Association of Privacy Professionals)
Launch Date:       2024
Target Audience:   Professionals responsible for AI governance,
                   ethics, risk management, compliance, and policy

Purpose:
The AIGP certification validates knowledge and skills needed to:

- Govern AI systems throughout their lifecycle
- Implement responsible AI practices
- Manage AI-related risks
- Ensure compliance with AI regulations
- Bridge technical and business stakeholders

Recognition:

- Globally recognized credential
- Vendor-neutral and framework-agnostic
- Complements privacy certifications (CIPP, CIPM, CIPT)
- Growing employer demand as AI regulations emerge
```


### Who Should Get AIGP?

```
IDEAL CANDIDATES FOR AIGP

ROLES THAT BENEFIT:

AI/ML Professionals:
├── AI/ML Engineers seeking governance knowledge
├── Data Scientists expanding into governance
├── AI Product Managers
└── Technical Leads on AI projects

Governance Professionals:
├── Privacy professionals (CIPP/CIPM holders)
├── Compliance officers
├── Risk managers
├── Ethics officers
└── GRC professionals

Legal and Policy:
├── Technology lawyers
├── Policy analysts
├── Regulatory affairs professionals
└── In-house counsel

Business Leaders:
├── Chief AI Officers
├── Chief Data Officers
├── Chief Ethics Officers
├── Digital transformation leaders
└── Consultants and advisors

PREREQUISITES:

Required: None (open to all)

Recommended Background:

- Familiarity with AI/ML concepts
- Understanding of privacy principles
- Experience with governance or compliance
- Knowledge of regulatory frameworks
```


### Exam Details

```
AIGP EXAM SPECIFICATIONS

Format:

- Multiple choice questions
- 90 scored questions + unscored pilot questions
- Computer-based testing

Time:

- 2.5 hours (150 minutes)
- Optional 15-minute break

Scoring:

- Scaled score: 100-500
- Passing score: 300
- Results: Immediate preliminary pass/fail
- Official results: Within 3-4 weeks

Languages:

- English (primary)
- Other languages may be added

Testing Options:

- Pearson VUE test centers (in-person)
- Online proctored (OnVUE)

Cost (as of 2024):

- IAPP Members: $549
- Non-Members: $699
- Membership: $275/year (includes one certification)

Retake Policy:

- Wait 30 days between attempts
- No limit on retakes
- Same exam fee applies
```

---


## AIGP Body of Knowledge


### Domain Structure

```
AIGP BODY OF KNOWLEDGE - 7 DOMAINS

Domain I: Understanding AI
├── Weight: ~14%
├── Focus: AI fundamentals, types, capabilities
└── Key: Definitions, classifications, technology stack

Domain II: AI Impacts and Responsible AI
├── Weight: ~14%
├── Focus: Risks, harms, ethical principles
└── Key: Trustworthy AI characteristics, global principles

Domain III: Current Laws Applying to AI
├── Weight: ~14%
├── Focus: Existing legal frameworks
└── Key: Privacy laws, discrimination, liability

Domain IV: Emerging AI Laws and Standards
├── Weight: ~14%
├── Focus: AI-specific regulations
└── Key: EU AI Act, NIST AI RMF, global laws

Domain V: AI Development Lifecycle
├── Weight: ~14%
├── Focus: Planning through deployment
└── Key: Design, development, implementation phases

Domain VI: Implementing AI Governance
├── Weight: ~16%
├── Focus: Practical governance implementation
└── Key: Infrastructure, processes, monitoring

Domain VII: Ongoing Issues and Concerns
├── Weight: ~14%
├── Focus: Unresolved challenges
└── Key: Legal issues, user concerns, auditing

TOTAL: 100%
```


### Domain-by-Domain Breakdown

```
═══════════════════════════════════════════════════════════════
DOMAIN I: UNDERSTANDING AI (~14%)
═══════════════════════════════════════════════════════════════

TOPIC I.1: AI Definitions and Terminology
─────────────────────────────────────────────────────────────────
Key Concepts:
□ OECD AI definition
□ ISO/IEC 22989 terminology
□ EU AI Act definition
□ Distinguishing AI from traditional software
□ AI system components

Study Focus:

- Memorize key definitions from major frameworks
- Understand why definitions matter for governance
- Know the common elements across definitions

Sample Question Type:
"According to the OECD, which of the following is NOT
a characteristic of an AI system?"

─────────────────────────────────────────────────────────────────
TOPIC I.2: AI as Socio-Technical Systems
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Human-AI interaction
□ Social context of AI
□ Multidisciplinary requirements
□ Stakeholder considerations
□ Organizational factors

Study Focus:

- AI systems are more than just technology
- Understand human factors in AI
- Role of different disciplines (UX, sociology, etc.)

─────────────────────────────────────────────────────────────────
TOPIC I.3: Types of AI Systems
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Strong AI vs. Weak AI (AGI vs. Narrow AI)
□ Machine learning approaches:

  - Supervised learning
  - Unsupervised learning
  - Semi-supervised learning
  - Reinforcement learning
□ Deep learning and neural networks
□ Generative AI and foundation models
□ Natural Language Processing
□ Computer vision
□ Robotics vs. RPA

Study Focus:

- Know the differences between AI types
- Understand training approaches
- Be able to identify AI type from descriptions

─────────────────────────────────────────────────────────────────
TOPIC I.4: AI Technology Stack
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Compute infrastructure (GPUs, TPUs, cloud)
□ Model layer (foundation models, fine-tuned)
□ Application layer
□ Data requirements
□ Major AI providers and platforms

Study Focus:

- Three layers of AI stack
- Infrastructure implications for governance
- Provider landscape awareness

─────────────────────────────────────────────────────────────────
TOPIC I.5: AI History and Trends
─────────────────────────────────────────────────────────────────
Key Concepts:
□ AI winters and summers
□ Key milestones (Dartmouth, Deep Blue, AlphaGo, GPT)
□ Current AI capabilities
□ Trends enabling modern AI
□ Transformer architecture significance

Study Focus:

- Major historical milestones
- Why current AI wave is different
- Technology trends (data, compute, algorithms)

═══════════════════════════════════════════════════════════════
DOMAIN II: AI IMPACTS AND RESPONSIBLE AI (~14%)
═══════════════════════════════════════════════════════════════

TOPIC II.1: AI Risks and Harms
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Individual harms:

  - Civil rights violations
  - Economic discrimination
  - Physical safety risks
  - Privacy violations
□ Group/societal harms:

  - Algorithmic discrimination
  - Democratic process threats
  - Misinformation
  - Job displacement
□ Organizational risks:

  - Reputational damage
  - Legal liability
  - Operational failures
□ Ecosystem harms:

  - Environmental impact
  - Concentration of power

Study Focus:

- Know categories of harm with examples
- Understand risk propagation
- Real-world case studies

─────────────────────────────────────────────────────────────────
TOPIC II.2: Trustworthy AI Characteristics
─────────────────────────────────────────────────────────────────
Key Concepts:
□ NIST AI RMF characteristics:

  - Valid and reliable
  - Safe
  - Secure and resilient
  - Accountable and transparent
  - Explainable and interpretable
  - Privacy-enhanced
  - Fair with harmful bias managed
□ Human-centric design
□ Human oversight requirements

Study Focus:

- Memorize trustworthy AI characteristics
- Understand relationship between characteristics
- Know how to assess trustworthiness

─────────────────────────────────────────────────────────────────
TOPIC II.3: Global AI Ethics Principles
─────────────────────────────────────────────────────────────────
Key Concepts:
□ OECD AI Principles
□ EU High-Level Expert Group Ethics Guidelines
□ UNESCO Recommendation on AI Ethics
□ Asilomar AI Principles
□ IEEE Ethically Aligned Design
□ White House AI Bill of Rights
□ Singapore Model AI Governance Framework

Study Focus:

- Know the major frameworks and their sources
- Identify common themes across frameworks
- Understand differences in approaches

═══════════════════════════════════════════════════════════════
DOMAIN III: CURRENT LAWS APPLYING TO AI (~14%)
═══════════════════════════════════════════════════════════════

TOPIC III.1: Consumer Protection Laws
─────────────────────────────────────────────────────────────────
Key Concepts:
□ FTC Act Section 5 (unfair/deceptive practices)
□ FTC AI enforcement actions
□ Consumer protection and AI transparency
□ Dark patterns and manipulative AI

Study Focus:

- How FTC Act applies to AI
- Recent enforcement examples
- Unfair vs. deceptive practices

─────────────────────────────────────────────────────────────────
TOPIC III.2: Non-Discrimination Laws
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Title VII Civil Rights Act (employment)
□ Equal Credit Opportunity Act (ECOA)
□ Fair Housing Act
□ Americans with Disabilities Act
□ Disparate impact vs. disparate treatment
□ Protected characteristics

Study Focus:

- Which law applies to which domain
- Disparate impact doctrine
- How AI can violate these laws

─────────────────────────────────────────────────────────────────
TOPIC III.3: Privacy Laws and AI
─────────────────────────────────────────────────────────────────
Key Concepts:
□ GDPR and AI:

  - Article 22 (automated decision-making)
  - Right to explanation
  - Data Protection Impact Assessments
  - Data subject rights
□ CCPA/CPRA provisions
□ Sector-specific laws (HIPAA, GLBA, FERPA)
□ Anonymization and AI

Study Focus:

- GDPR Article 22 requirements in detail
- When DPIA is required
- Right to meaningful information

─────────────────────────────────────────────────────────────────
TOPIC III.4: Product Liability and IP
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Traditional product liability limitations
□ EU Product Liability Directive reforms
□ AI Liability Directive (proposed)
□ Copyright and AI-generated content
□ Training data IP issues
□ AI inventorship questions

Study Focus:

- How AI challenges traditional liability
- New EU liability frameworks
- AI and intellectual property debates

═══════════════════════════════════════════════════════════════
DOMAIN IV: EMERGING AI LAWS AND STANDARDS (~14%)
═══════════════════════════════════════════════════════════════

TOPIC IV.1: EU AI Act
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Risk-based classification:

  - Prohibited AI (Article 5)
  - High-risk AI (Annex III)
  - Limited risk
  - Minimal risk
□ High-risk requirements (Articles 9-15):

  - Risk management system
  - Data governance
  - Technical documentation
  - Record-keeping
  - Transparency
  - Human oversight
  - Accuracy, robustness, cybersecurity
□ GPAI and foundation model rules
□ Conformity assessment
□ Penalties (up to 7% global revenue)
□ Implementation timeline

Study Focus:

- Know the four risk tiers with examples
- Memorize high-risk requirements
- Understand GPAI obligations
- Know key dates and deadlines

─────────────────────────────────────────────────────────────────
TOPIC IV.2: Other Global AI Laws
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Canada AIDA (Artificial Intelligence and Data Act)
□ US state laws:

  - Colorado AI Act
  - NYC Local Law 144
  - California AI legislation
□ China AI regulations:

  - Algorithm recommendation rules
  - Generative AI regulations
  - Deep synthesis rules
□ Brazil AI Bill
□ Other emerging frameworks

Study Focus:

- Key provisions of major laws
- Compare approaches (risk-based vs. use-case)
- Know effective dates

─────────────────────────────────────────────────────────────────
TOPIC IV.3: AI Risk Management Frameworks
─────────────────────────────────────────────────────────────────
Key Concepts:
□ NIST AI Risk Management Framework:

  - GOVERN function
  - MAP function
  - MEASURE function
  - MANAGE function
□ ISO/IEC 42001 AI Management System
□ ISO 31000 Risk Management
□ Singapore Model AI Governance Framework
□ IEEE 7000 series
□ Council of Europe HUDERIA

Study Focus:

- NIST AI RMF four functions in detail
- How frameworks complement each other
- Practical application guidance

═══════════════════════════════════════════════════════════════
DOMAIN V: AI DEVELOPMENT LIFECYCLE (~14%)
═══════════════════════════════════════════════════════════════

TOPIC V.1: AI System Planning
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Business objectives and requirements
□ Project scoping
□ Governance structure for projects
□ Stakeholder identification
□ Resource planning
□ Go/no-go criteria

Study Focus:

- Planning phase governance controls
- Stakeholder engagement requirements
- Project approval processes

─────────────────────────────────────────────────────────────────
TOPIC V.2: AI System Design
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Data strategy:

  - Data gathering and sourcing
  - Data wrangling and cleansing
  - Data labeling
  - Data quality assurance
□ Privacy-Enhancing Technologies:

  - Differential privacy
  - Federated learning
  - Anonymization techniques
□ Model selection
□ Accuracy vs. interpretability tradeoffs

Study Focus:

- Data governance for AI
- When to use different PETs
- Design documentation requirements

─────────────────────────────────────────────────────────────────
TOPIC V.3: AI System Development
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Model building process
□ Feature engineering
□ Model training approaches
□ Testing and validation:

  - Train/validation/test splits
  - Cross-validation
  - Performance metrics
  - Bias testing

Study Focus:

- Development best practices
- Testing requirements
- Validation methodologies

─────────────────────────────────────────────────────────────────
TOPIC V.4: AI System Implementation
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Deployment readiness assessment
□ Deployment strategies:

  - Blue-green deployment
  - Canary releases
  - Shadow mode
  - A/B testing
□ Production monitoring
□ Model drift detection
□ Maintenance and updates
□ Decommissioning

Study Focus:

- Deployment approval processes
- Monitoring requirements
- Update and maintenance procedures

═══════════════════════════════════════════════════════════════
DOMAIN VI: IMPLEMENTING AI GOVERNANCE (~16%)
═══════════════════════════════════════════════════════════════

TOPIC VI.1: AI Risk Interoperability
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Integration with enterprise risk management
□ Security risk integration
□ Privacy risk integration
□ Business risk integration
□ Three lines of defense model

Study Focus:

- How AI risk connects to other risks
- Cross-functional collaboration
- Risk aggregation approaches

─────────────────────────────────────────────────────────────────
TOPIC VI.2: AI Governance Principles
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Pro-innovation mindset
□ Risk-centric governance
□ Consensus-driven planning
□ Outcome-focused teams
□ Non-prescriptive approach
□ Law/technology agnostic framework

Study Focus:

- How to balance innovation and governance
- Stakeholder engagement approaches
- Cultural change strategies

─────────────────────────────────────────────────────────────────
TOPIC VI.3: AI Governance Infrastructure
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Roles and responsibilities:

  - Developers
  - Deployers
  - Users
□ Key governance roles:

  - Chief Privacy Officer
  - Chief Ethics Officer
  - Responsible AI Office
  - AI Governance Committee
□ AI/ML inventory and repository
□ Training and awareness programs
□ Third-party AI risk management

Study Focus:

- Know key roles and responsibilities
- Governance structure options
- Third-party management requirements

─────────────────────────────────────────────────────────────────
TOPIC VI.4: AI Project Governance
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Business case and cost/benefit analysis
□ Risk identification and classification
□ Algorithmic Impact Assessment (AIA)
□ Human oversight levels
□ Stakeholder engagement
□ TEVV (Test, Evaluation, Verification, Validation)

Study Focus:

- Project-level governance processes
- Impact assessment approaches
- Stakeholder engagement methods

─────────────────────────────────────────────────────────────────
TOPIC VI.5: Testing and Validation
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Trustworthiness evaluation
□ Model cards and fact sheets
□ Explainability methods:

  - Counterfactual explanations
  - Feature importance
  - LIME, SHAP
□ Adversarial testing
□ Privacy-preserving ML testing
□ AI failure modes:

  - Brittleness
  - Hallucinations
  - Embedded bias
  - Catastrophic forgetting

Study Focus:

- Testing methodologies
- Explainability techniques
- Common AI failure modes

─────────────────────────────────────────────────────────────────
TOPIC VI.6: Post-Deployment Management
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Post-hoc testing
□ Automation bias awareness
□ Continuous improvement
□ Champion vs. challenger models
□ Version control
□ Red teaming
□ Deactivation procedures
□ Incident response

Study Focus:

- Ongoing monitoring requirements
- Update and retraining processes
- Incident response procedures

═══════════════════════════════════════════════════════════════
DOMAIN VII: ONGOING ISSUES AND CONCERNS (~14%)
═══════════════════════════════════════════════════════════════

TOPIC VII.1: Legal Issues
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Tort liability challenges
□ AI model and data licensing
□ Intellectual property rights
□ Evolving legal frameworks
□ Cross-border considerations

Study Focus:

- Unresolved legal questions
- Emerging legal theories
- International coordination challenges

─────────────────────────────────────────────────────────────────
TOPIC VII.2: User Concerns
─────────────────────────────────────────────────────────────────
Key Concepts:
□ User education challenges
□ Workforce upskilling/reskilling
□ Opt-out mechanisms
□ Digital divide
□ Trust and transparency

Study Focus:

- User empowerment approaches
- Workforce transition strategies
- Providing meaningful choice

─────────────────────────────────────────────────────────────────
TOPIC VII.3: AI Auditing and Accountability
─────────────────────────────────────────────────────────────────
Key Concepts:
□ Building auditor profession
□ Audit frameworks and standards
□ Audit trigger indicators
□ Balancing productivity and governance
□ Continuous compliance
□ Future of AI governance

Study Focus:

- Audit methodologies
- Professional development
- Emerging standards
```

---


## Study Plan


### Recommended Study Timeline

```
AIGP STUDY PLAN - 12 WEEKS

════════════════════════════════════════════════════════════════
PHASE 1: FOUNDATION (Weeks 1-4)
═══════════════════════════════════════════════════════════════

Week 1: Domain I - Understanding AI
─────────────────────────────────────────────────────────────────
□ Read AIGP Body of Knowledge Domain I
□ Study AI definitions (OECD, ISO, EU AI Act)
□ Learn AI types and training methods
□ Understand technology stack
□ Review AI history and trends
□ Create flashcards for key terms
□ Time: 8-10 hours

Week 2: Domain II - AI Impacts and Responsible AI
─────────────────────────────────────────────────────────────────
□ Read AIGP BOK Domain II
□ Study categories of AI harms
□ Learn trustworthy AI characteristics
□ Review major ethics frameworks
□ Study case examples of AI harms
□ Create flashcards
□ Time: 8-10 hours

Week 3: Domain III - Current Laws
─────────────────────────────────────────────────────────────────
□ Read AIGP BOK Domain III
□ Study FTC Act and enforcement
□ Learn non-discrimination laws
□ Deep dive on GDPR and AI (Article 22)
□ Review product liability issues
□ Create flashcards
□ Time: 8-10 hours

Week 4: Domain IV - Emerging Laws
─────────────────────────────────────────────────────────────────
□ Read AIGP BOK Domain IV
□ Deep dive on EU AI Act
□ Study US state laws
□ Review global AI regulations
□ Learn NIST AI RMF thoroughly
□ Create flashcards
□ Time: 10-12 hours

END OF PHASE 1: Take practice quiz on Domains I-IV

═══════════════════════════════════════════════════════════════
PHASE 2: CORE KNOWLEDGE (Weeks 5-8)
═══════════════════════════════════════════════════════════════

Week 5: Domain V - AI Development Lifecycle
─────────────────────────────────────────────────────────────────
□ Read AIGP BOK Domain V
□ Study planning phase governance
□ Learn design phase requirements
□ Understand development best practices
□ Review implementation and monitoring
□ Create flashcards
□ Time: 8-10 hours

Week 6: Domain VI Part 1 - Governance Foundations
─────────────────────────────────────────────────────────────────
□ Read AIGP BOK Domain VI (first half)
□ Study risk integration
□ Learn governance principles
□ Understand governance infrastructure
□ Review roles and responsibilities
□ Create flashcards
□ Time: 8-10 hours

Week 7: Domain VI Part 2 - Governance Processes
─────────────────────────────────────────────────────────────────
□ Read AIGP BOK Domain VI (second half)
□ Study project governance
□ Learn testing and validation
□ Understand post-deployment management
□ Review incident response
□ Create flashcards
□ Time: 8-10 hours

Week 8: Domain VII - Ongoing Issues
─────────────────────────────────────────────────────────────────
□ Read AIGP BOK Domain VII
□ Study legal issues and challenges
□ Learn user concerns
□ Understand auditing and accountability
□ Review future trends
□ Create flashcards
□ Time: 6-8 hours

END OF PHASE 2: Take full-length practice exam #1

═══════════════════════════════════════════════════════════════
PHASE 3: DEEP REVIEW (Weeks 9-10)
═══════════════════════════════════════════════════════════════

Week 9: Weak Area Focus
─────────────────────────────────────────────────────────────────
□ Review practice exam results
□ Identify weak areas
□ Re-study weak domains
□ Create additional flashcards
□ Read supplementary materials
□ Time: 10-12 hours

Week 10: Integration and Application
─────────────────────────────────────────────────────────────────
□ Review cross-domain connections
□ Practice scenario-based questions
□ Study real-world applications
□ Review all flashcards
□ Take practice exam #2
□ Time: 10-12 hours

═══════════════════════════════════════════════════════════════
PHASE 4: FINAL PREPARATION (Weeks 11-12)
═══════════════════════════════════════════════════════════════

Week 11: Intensive Review
─────────────────────────────────────────────────────────────────
□ Review all domains systematically
□ Focus on memorization items
□ Practice timing with questions
□ Review wrong answers from practice exams
□ Time: 12-15 hours

Week 12: Final Week
─────────────────────────────────────────────────────────────────
□ Light review (don't cram)
□ Final flashcard review
□ Take practice exam #3
□ Rest and prepare mentally
□ Logistics preparation
□ Time: 6-8 hours (lighter)

EXAM DAY: You're ready!

TOTAL STUDY TIME: 100-120 hours over 12 weeks
```


### Study Resources

```
AIGP STUDY RESOURCES

═══════════════════════════════════════════════════════════════
PRIMARY RESOURCES
═══════════════════════════════════════════════════════════════

IAPP Official Materials:
□ AIGP Body of Knowledge (BOK) - FREE download

  - Essential reference document
  - Covers all exam domains
  - Basis for exam questions

□ AIGP Textbook - $75-100

  - Comprehensive coverage
  - Detailed explanations
  - Practice questions

□ IAPP AIGP Training - $1,200+

  - Official course
  - Expert instruction
  - Most comprehensive prep

□ AIGP Practice Exam - $50

  - Official practice questions
  - Exam-like format
  - Highly recommended

═══════════════════════════════════════════════════════════════
FREE RESOURCES
═══════════════════════════════════════════════════════════════

Framework Documents:
□ NIST AI RMF - nist.gov/itl/ai-risk-management-framework

  - Full framework document
  - Playbook
  - Profiles

□ EU AI Act - eur-lex.europa.eu

  - Full regulation text
  - Recitals and annexes

□ OECD AI Principles - oecd.ai

  - Principles documentation
  - Implementation guidance

□ ISO Standards Summaries

  - ISO/IEC 22989 overview
  - ISO/IEC 42001 overview

Government Resources:
□ White House AI Bill of Rights
□ FTC AI guidance documents
□ EEOC AI employment guidance
□ Singapore PDPC AI governance framework

IAPP Free Resources:
□ IAPP Resource Center
□ IAPP Daily Dashboard newsletter
□ IAPP webinars (many free)
□ Privacy Perspectives blog

═══════════════════════════════════════════════════════════════
SUPPLEMENTARY RESOURCES
═══════════════════════════════════════════════════════════════

Books:
□ "The AI Governance Handbook" (various)
□ "Responsible AI" (various publishers)
□ "AI Ethics" (Mark Coeckelbergh)

Online Courses:
□ Coursera: AI Ethics courses
□ edX: Responsible AI courses
□ LinkedIn Learning: AI governance

Academic Resources:
□ Stanford HAI reports
□ MIT AI Ethics resources
□ Berkman Klein Center publications

Industry Resources:
□ World Economic Forum AI resources
□ Partnership on AI publications
□ AI Now Institute reports
```

---


## Study Strategies


### Effective Study Techniques

```
STUDY TECHNIQUES FOR AIGP

═══════════════════════════════════════════════════════════════
ACTIVE LEARNING STRATEGIES
═══════════════════════════════════════════════════════════════

1. FLASHCARDS (Spaced Repetition)
─────────────────────────────────────────────────────────────────
Create flashcards for:
□ Definitions (OECD AI definition, trustworthy AI characteristics)
□ Lists (7 high-risk requirements, 4 NIST AI RMF functions)
□ Frameworks (risk tiers, harm categories)
□ Laws and regulations (key provisions, dates)

Tools:

- Anki (free, spaced repetition)
- Quizlet
- Physical cards

Technique:

- Create cards as you study
- Review daily
- Focus on cards you get wrong
- Aim for 90%+ accuracy

2. PRACTICE QUESTIONS
─────────────────────────────────────────────────────────────────
□ Take practice exams under timed conditions
□ Review ALL answers (right and wrong)
□ Understand WHY answers are correct
□ Identify patterns in question types
□ Track your weak areas

3. TEACH/EXPLAIN
─────────────────────────────────────────────────────────────────
□ Explain concepts to others (or pretend to)
□ Write summaries in your own words
□ Create study guides
□ Answer questions in study groups

4. REAL-WORLD APPLICATION
─────────────────────────────────────────────────────────────────
□ Apply concepts to your work
□ Analyze AI systems you use
□ Read news through AIGP lens
□ Discuss with colleagues

═══════════════════════════════════════════════════════════════
MEMORIZATION PRIORITIES
═══════════════════════════════════════════════════════════════

MUST MEMORIZE:

Definitions:
□ OECD AI definition elements
□ Trustworthy AI characteristics (NIST)
□ EU AI Act risk categories

Lists:
□ EU AI Act high-risk requirements (Articles 9-15)
□ NIST AI RMF four functions (GOVERN, MAP, MEASURE, MANAGE)
□ Categories of AI harm
□ GDPR Article 22 requirements

Dates:
□ EU AI Act implementation timeline
□ Key regulatory effective dates

Frameworks:
□ EU AI Act risk pyramid
□ NIST AI RMF structure
□ GDPR automated decision-making provisions

UNDERSTAND (not memorize verbatim):
□ How concepts apply in practice
□ Relationships between frameworks
□ Governance implementation approaches
□ Real-world case examples
```


### Common Pitfalls to Avoid

```
COMMON STUDY MISTAKES

DON'T:

❌ Focus only on technical AI content
   → Exam heavily tests governance, law, and ethics

❌ Skip the legal domains
   → Domains III and IV are significant portions

❌ Ignore the EU AI Act
   → Major focus area, know it well

❌ Memorize without understanding
   → Scenario questions require application

❌ Study only one resource
   → Use multiple sources for depth

❌ Wait until last minute
   → Content is broad, needs time to absorb

❌ Skip practice exams
   → Essential for timing and format familiarity

❌ Ignore weak areas
   → Address gaps, don't avoid them

DO:

✓ Balance technical and governance study
✓ Understand "why" not just "what"
✓ Practice scenario-based thinking
✓ Review real-world examples
✓ Take multiple practice exams
✓ Study consistently over time
✓ Rest before the exam
```

---


## Practice Questions


### Sample Question Types

```
AIGP QUESTION TYPES AND EXAMPLES

═══════════════════════════════════════════════════════════════
TYPE 1: DEFINITION/KNOWLEDGE
═══════════════════════════════════════════════════════════════

Example:
According to the NIST AI Risk Management Framework, which of
the following is NOT one of the four core functions?

A. GOVERN
B. MAP
C. ASSESS
D. MANAGE

Answer: C (ASSESS is not a function; the four are GOVERN,
MAP, MEASURE, MANAGE)

Study Tip: Memorize key frameworks and their components

═══════════════════════════════════════════════════════════════
TYPE 2: SCENARIO-BASED
═══════════════════════════════════════════════════════════════

Example:
A company is deploying an AI system that will be used to
screen job applications for a position in France. The system
analyzes resumes and ranks candidates. Under the EU AI Act,
this system would most likely be classified as:

A. Prohibited AI
B. High-risk AI
C. Limited risk AI
D. Minimal risk AI

Answer: B (Employment and recruitment AI is listed in
Annex III as high-risk)

Study Tip: Know how to apply frameworks to real situations

═══════════════════════════════════════════════════════════════
TYPE 3: BEST PRACTICE
═══════════════════════════════════════════════════════════════

Example:
An organization is implementing an AI governance program.
Which of the following should be done FIRST?

A. Conduct bias testing on all AI systems
B. Create an inventory of AI systems
C. Implement continuous monitoring
D. Train all employees on AI ethics

Answer: B (You need to know what AI you have before you
can govern it)

Study Tip: Understand proper sequencing and priorities

═══════════════════════════════════════════════════════════════
TYPE 4: LEGAL/REGULATORY
═══════════════════════════════════════════════════════════════

Example:
Under GDPR Article 22, which of the following is required
when automated decision-making produces legal or similarly
significant effects?

A. The decision must always be made by a human
B. The data subject must be able to obtain human intervention
C. The organization must publish its algorithm
D. An external audit must be conducted annually

Answer: B (Article 22 requires safeguards including the
right to obtain human intervention)

Study Tip: Know key regulatory requirements precisely

═══════════════════════════════════════════════════════════════
TYPE 5: COMPARISON/DISTINCTION
═══════════════════════════════════════════════════════════════

Example:
What is the primary difference between disparate treatment
and disparate impact in the context of AI discrimination?

A. Disparate treatment is illegal while disparate impact is not
B. Disparate treatment requires intent while disparate impact
   does not
C. Disparate impact only applies to protected classes while
   disparate treatment applies to all
D. Disparate treatment applies to AI while disparate impact
   only applies to human decisions

Answer: B (Disparate treatment requires intentional
discrimination; disparate impact can be unintentional)

Study Tip: Understand key distinctions between similar concepts
```


### Self-Assessment Quiz

```
AIGP SELF-ASSESSMENT QUIZ (25 Questions)

Test your readiness. Answers at the end.

DOMAIN I: Understanding AI

1. Which of the following best describes "narrow AI"?
   A. AI that can perform any intellectual task a human can
   B. AI designed for specific, limited tasks
   C. AI with reduced computational requirements
   D. AI that operates in controlled environments

2. In supervised learning, the training data:
   A. Is unlabeled and the model finds patterns
   B. Includes labeled examples with correct outputs
   C. Comes from real-time user interactions
   D. Is generated synthetically

DOMAIN II: AI Impacts and Responsible AI

3. Which is NOT a characteristic of trustworthy AI per NIST?
   A. Valid and reliable
   B. Profitable
   C. Fair with harmful bias managed
   D. Secure and resilient

4. The OECD AI Principles include all EXCEPT:
   A. Transparency and explainability
   B. Mandatory human decision-making
   C. Accountability
   D. Human-centered values

DOMAIN III: Current Laws

5. GDPR Article 22 applies to decisions that are:
   A. Made by any computer system
   B. Based solely on automated processing with legal effects
   C. Made using any personal data
   D. Reviewed by a human at any point

6. The FTC Act Section 5 prohibits:
   A. All uses of AI in consumer products
   B. Unfair or deceptive acts or practices
   C. AI that processes personal data
   D. Automated decision-making without consent

DOMAIN IV: Emerging Laws

7. Under the EU AI Act, which is considered prohibited AI?
   A. AI for job candidate screening
   B. Social scoring by public authorities
   C. AI chatbots
   D. Recommendation systems

8. The NIST AI RMF function that establishes governance is:
   A. MAP
   B. MEASURE
   C. GOVERN
   D. MANAGE

9. NYC Local Law 144 requires:
   A. Registration of all AI systems
   B. Bias audits for automated employment decision tools
   C. Disclosure of all algorithms
   D. Government approval before AI deployment

DOMAIN V: AI Development Lifecycle

10. Which is a Privacy-Enhancing Technology (PET)?
    A. Data cleansing
    B. Differential privacy
    C. Feature engineering
    D. Cross-validation

11. "Model drift" refers to:
    A. Models moving between servers
    B. Degradation of model performance over time
    C. Updates to model architecture
    D. Transfer learning between domains

DOMAIN VI: Implementing AI Governance

12. In the three lines of defense model, who provides
    independent assurance?
    A. First line (operations)
    B. Second line (risk management)
    C. Third line (internal audit)
    D. External regulators

13. A model card typically includes:
    A. Source code for the model
    B. Intended use and limitations
    C. User personal data
    D. Competitor analysis

14. Red teaming in AI governance refers to:
    A. Prioritizing high-risk systems
    B. Adversarial testing to find weaknesses
    C. Classifying systems by color code
    D. Emergency response procedures

DOMAIN VII: Ongoing Issues

15. A key challenge in AI auditing is:
    A. Too many certified auditors
    B. Lack of consistent standards and frameworks
    C. Excessive regulatory guidance
    D. Auditors having too much access

SCENARIO QUESTIONS

16. A bank uses AI to approve or deny loan applications.
    The AI makes decisions without human review. Under GDPR,
    this is potentially problematic because:
    A. GDPR prohibits all AI use
    B. Financial decisions require paper records
    C. Article 22 restricts solely automated decisions with
       significant effects
    D. Banks are exempt from GDPR

17. An AI system categorizes social media content for
    content moderation. Under the EU AI Act, this is
    likely classified as:
    A. Prohibited
    B. High-risk
    C. Limited risk
    D. Minimal risk

18. A company wants to deploy facial recognition in its
    retail stores to identify shoplifters. This use case
    raises concerns primarily related to:
    A. AI accuracy only
    B. Privacy, bias, and civil liberties
    C. Computational efficiency
    D. Training data availability

19. An organization discovers its hiring AI has been
    rejecting more candidates from certain zip codes.
    This is most likely an example of:
    A. Direct discrimination
    B. Proxy discrimination
    C. Random error
    D. Model drift

20. When implementing AI governance, which should typically
    come FIRST?
    A. Advanced bias testing
    B. AI system inventory
    C. External AI audit
    D. Public transparency report

ADVANCED QUESTIONS

21. The EU AI Act's conformity assessment for high-risk AI:
    A. Always requires third-party assessment
    B. May be self-assessed for some categories
    C. Is voluntary for small businesses
    D. Only applies to public sector

22. Under the EU AI Act, GPAI models with systemic risk:
    A. Are automatically prohibited
    B. Have additional obligations including adversarial testing
    C. Are exempt from the regulation
    D. Only need basic documentation

23. The concept of "meaningful human oversight" requires:
    A. A human approves every AI decision
    B. Humans can understand, intervene, and override AI
    C. Only senior executives review AI outputs
    D. Annual human review of AI systems

24. Counterfactual explanations in AI:
    A. Explain what would need to change for a different outcome
    B. Provide the full source code
    C. Compare AI to human decisions
    D. Document historical model versions

25. Under the EU AI Act, when do provisions for
    prohibited AI practices take effect?
    A. Immediately upon publication
    B. 6 months after entry into force
    C. 24 months after entry into force
    D. 36 months after entry into force

─────────────────────────────────────────────────────────────────

ANSWERS:

1-B, 2-B, 3-B, 4-B, 5-B, 6-B, 7-B, 8-C, 9-B, 10-B,
11-B, 12-C, 13-B, 14-B, 15-B, 16-C, 17-C, 18-B, 19-B, 20-B,
21-B, 22-B, 23-B, 24-A, 25-B

SCORING:
23-25: Excellent - Ready for exam
20-22: Good - Light review needed
17-19: Fair - Focus on weak areas
<17: More study needed

Review any questions you missed and study those topics!
```

---


## Exam Day


### Before the Exam

```
EXAM PREPARATION CHECKLIST

ONE WEEK BEFORE:
□ Confirm exam date, time, and location
□ Review testing center or online requirements
□ Take final practice exam
□ Identify any remaining weak areas
□ Light review of key concepts
□ Prepare identification documents
□ Get adequate sleep all week

ONE DAY BEFORE:
□ Light review only (no cramming)
□ Review flashcards one final time
□ Prepare everything you need
□ Know the route to test center (if in-person)
□ Set multiple alarms
□ Go to bed early
□ Avoid alcohol and heavy meals

EXAM DAY:
□ Wake up with plenty of time
□ Eat a good breakfast
□ Bring required identification
□ Arrive 30 minutes early (in-person)
□ Or log in 30 minutes early (online)
□ Stay calm and confident
□ Use the bathroom before starting
```


### During the Exam

```
EXAM-TAKING STRATEGIES

TIME MANAGEMENT:
─────────────────────────────────────────────────────────────────
Total time: 150 minutes
Questions: ~90 scored + unscored
Time per question: ~1.5 minutes average

Strategy:

- Don't spend more than 2 minutes on any question
- Flag difficult questions and return later
- Leave 15-20 minutes for review
- Use the optional break if needed

QUESTION APPROACH:
─────────────────────────────────────────────────────────────────

1. Read the ENTIRE question carefully
2. Identify what's being asked
3. Eliminate obviously wrong answers
4. Choose the BEST answer (not just a correct one)
5. Don't second-guess unless certain
6. Flag uncertain questions for review

COMMON TRAPS:
─────────────────────────────────────────────────────────────────
□ "All of the above" - verify ALL options are correct
□ "None of the above" - verify NO option is correct
□ Absolutes ("always," "never") - usually wrong
□ Two very similar answers - one is likely correct
□ Longest answer - not always right, but read carefully
□ Questions with "NOT" or "EXCEPT" - read carefully

SCENARIO QUESTIONS:
─────────────────────────────────────────────────────────────────

1. Identify the key facts
2. Determine what framework/law applies
3. Apply the relevant rules
4. Choose the answer that best fits

WHEN UNSURE:
─────────────────────────────────────────────────────────────────

1. Eliminate wrong answers
2. Use reasoning to narrow down
3. Go with your first instinct
4. Never leave blank (no penalty for guessing)
5. Flag and review if time permits
```


### After the Exam

```
POST-EXAM PROCESS

IMMEDIATE:
□ You'll see a preliminary pass/fail result
□ Take a screenshot if desired
□ Don't discuss specific questions publicly

WITHIN 3-4 WEEKS:
□ Official score report delivered
□ Digital badge available (if passed)
□ Certificate available for download

IF YOU PASS:
□ Celebrate your achievement!
□ Update LinkedIn profile
□ Add credential to resume/email signature
□ Maintain certification (no CPE required currently)
□ Consider joining IAPP AI Governance community

IF YOU DON'T PASS:
□ Don't be discouraged - many people need multiple attempts
□ Review your score report for weak areas
□ Wait 30 days before retaking
□ Focus study on weak domains
□ Take additional practice exams
□ Consider different study resources
□ Schedule retake when ready

CERTIFICATION MAINTENANCE:
□ AIGP currently has no continuing education requirement
□ Stay current through IAPP resources
□ Consider complementary certifications (CIPP, CIPM)
□ Engage with AI governance community
```

---


## Quick Reference: Key Items to Memorize

```
AIGP MEMORIZATION CHEAT SHEET

═══════════════════════════════════════════════════════════════
EU AI ACT
═══════════════════════════════════════════════════════════════

Risk Tiers:

1. Prohibited (Article 5)
2. High-Risk (Annex III)
3. Limited Risk
4. Minimal Risk

High-Risk Requirements (Articles 9-15):

1. Risk management system (Art. 9)
2. Data governance (Art. 10)
3. Technical documentation (Art. 11)
4. Record-keeping (Art. 12)
5. Transparency (Art. 13)
6. Human oversight (Art. 14)
7. Accuracy, robustness, cybersecurity (Art. 15)

Key Dates:

- Aug 2024: Entry into force
- Feb 2025: Prohibited AI applies
- Aug 2025: GPAI rules apply
- Aug 2026: Most high-risk applies

Penalties: Up to 7% global annual revenue

═══════════════════════════════════════════════════════════════
NIST AI RMF
═══════════════════════════════════════════════════════════════

Four Functions:

1. GOVERN - Establish governance
2. MAP - Understand context and risks
3. MEASURE - Assess and analyze
4. MANAGE - Prioritize and act

═══════════════════════════════════════════════════════════════
TRUSTWORTHY AI CHARACTERISTICS (NIST)
═══════════════════════════════════════════════════════════════

1. Valid and Reliable
2. Safe
3. Secure and Resilient
4. Accountable and Transparent
5. Explainable and Interpretable
6. Privacy-Enhanced
7. Fair with Harmful Bias Managed

═══════════════════════════════════════════════════════════════
GDPR ARTICLE 22
═══════════════════════════════════════════════════════════════

Applies to:

- Solely automated decisions
- Producing legal or similarly significant effects

Rights:

- Human intervention
- Express point of view
- Contest the decision

Exceptions:

- Contract necessity
- Legal authorization
- Explicit consent

═══════════════════════════════════════════════════════════════
CATEGORIES OF AI HARM
═══════════════════════════════════════════════════════════════

1. Individual (civil rights, economic, safety, privacy)
2. Group/Societal (discrimination, democracy, misinfo)
3. Organizational (reputation, legal, operational)
4. Ecosystem (environment, concentration of power)

═══════════════════════════════════════════════════════════════
KEY FRAMEWORKS/LAWS
═══════════════════════════════════════════════════════════════

- OECD AI Principles (2019)
- UNESCO AI Ethics Recommendation (2021)
- EU AI Act (2024)
- NIST AI RMF (2023)
- NYC Local Law 144 (2023)
- Colorado AI Act (2026)
- White House AI Bill of Rights (2022)

═══════════════════════════════════════════════════════════════
DISCRIMINATION CONCEPTS
═══════════════════════════════════════════════════════════════

Disparate Treatment: Intentional discrimination
Disparate Impact: Unintentional but discriminatory effect
Proxy Variables: Neutral variables that correlate with
                 protected characteristics
```

---


## Summary

Passing the AIGP exam requires:

1. **Comprehensive Knowledge** — All seven domains matter; don't skip any
2. **Framework Mastery** — Know EU AI Act, NIST AI RMF, and GDPR thoroughly
3. **Applied Understanding** — Be able to apply concepts to scenarios
4. **Consistent Study** — 100+ hours over 8-12 weeks works best
5. **Practice Testing** — Take multiple practice exams under timed conditions
6. **Strategic Preparation** — Focus on weak areas, memorize key items

The AIGP certification validates your expertise in a rapidly growing field. As AI governance becomes increasingly important, this credential will distinguish you as a qualified professional.

Good luck on your exam!

---

**Word Count:** Approximately 7,200 words
**Estimated Reading Time:** 35-40 minutes
**Practice Questions Included:** 25+
**Checklists Included:** 10+

---

*End of Guide*
