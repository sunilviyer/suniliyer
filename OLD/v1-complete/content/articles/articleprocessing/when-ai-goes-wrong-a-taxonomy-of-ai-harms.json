{
  "file_status": {
    "suggested_slug": "when-ai-goes-wrong-a-taxonomy-of-ai-harms",
    "category": "AI Risks & Principles",
    "word_count_check": {
      "target": null,
      "actual": 2503,
      "status": "under"
    }
  },
  "content_validation": {
    "structure": {
      "has_h1": true,
      "has_intro": true,
      "has_conclusion": true,
      "header_depth_valid": true
    },
    "generated_elements": {
      "tldr_was_missing": true,
      "objectives_were_missing": false,
      "keywords_were_missing": false
    }
  },
  "component_inventory": {
    "has_components": true,
    "items": [
      {
        "type": "flowchart",
        "label": "Sources Process",
        "detected_at_section": "Sources"
      },
      {
        "type": "template",
        "label": "Example: The Credit Score That Knew Too Much",
        "detected_at_section": "1. Harms to Individuals",
        "template_link": "/templates/example-the-credit-score-that-knew-too-much.md"
      },
      {
        "type": "template",
        "label": "Example: The Loan Algorithm That Punished Communities",
        "detected_at_section": "2. Harms to Groups",
        "template_link": "/templates/example-the-loan-algorithm-that-punished-communities.md"
      },
      {
        "type": "template",
        "label": "Example: The Recommendation Algorithm That Radicalized Users",
        "detected_at_section": "3. Harms to Society",
        "template_link": "/templates/example-the-recommendation-algorithm-that-radicalized-users.md"
      },
      {
        "type": "template",
        "label": "Example: The HR Algorithm Nobody Trusted",
        "detected_at_section": "4. Harms to Organizations",
        "template_link": "/templates/example-the-hr-algorithm-nobody-trusted.md"
      },
      {
        "type": "template",
        "label": "Example: The Data Center That Drained the Town",
        "detected_at_section": "5. Harms to the Ecosystem",
        "template_link": "/templates/example-the-data-center-that-drained-the-town.md"
      }
    ]
  },
  "extracted_data": {
    "title": "When AI Goes Wrong – A Taxonomy of AI Harms",
    "tldr": "",
    "learning_objectives": [
      "Understand the key concepts and principles of stakeholder engagement",
      "Implement policy development in real-world scenarios",
      "Evaluate risk assessment frameworks for organizational compliance"
    ],
    "seo_keywords": [
      "when",
      "goes",
      "AI governance",
      "artificial intelligence",
      "AI ethics"
    ],
    "references": []
  },
  "cross_reference_data": {
    "topic_fingerprint": [
      "generative ai",
      "large language model",
      "machine learning",
      "deep learning",
      "nlp"
    ],
    "named_examples": [
      "amazon",
      "energy",
      "eu ai act",
      "facebook",
      "fair",
      "microsoft",
      "mit",
      "nist",
      "openai",
      "twitter",
      "uber"
    ]
  },
  "image_generation": {
    "prompt": {
      "formula": "Abstract geometric illustration, earth tones, minimalist, professional",
      "category_motif": "warning triangles",
      "master_size": "1200x750px",
      "css_filters": true
    },
    "placeholder": "![When AI Goes Wrong – A Taxonomy of AI Harms]({{IMAGE_PLACEHOLDER_when-ai-goes-wrong-a-taxonomy-of-ai-harms}})"
  }
}