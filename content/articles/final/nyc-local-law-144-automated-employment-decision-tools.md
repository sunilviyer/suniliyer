---
title: NYC Local Law 144 - Automated Employment Decision Tools
slug: nyc-local-law-144-automated-employment-decision-tools
path: responsibility
publishDate: 2025-09-01
tldr: NYC Local Law 144 (effective 2023) establishes first US regulation specifically targeting AI hiring tools requiring employers/agencies using Automated Employment Decision Tools (AEDTs) in NYC to conduct annual independent bias audits calculating selection rates and impact ratios across sex (male, female, non-binary/unknown) and race/ethnicity categories (White, Black, Hispanic/Latino, Asian, Native Hawaiian/Pacific Islander, American Indian/Alaska Native, two+ races) applying EEOC's four-fifths rule benchmark where protected group selection <80% highest group indicates potential adverse impact. Three core requirements mandate (1) independent auditor bias audit before use and annually thereafter testing disparate impact, (2) public disclosure of audit results on company website including dates, category distributions, selection/scoring rates, impact ratios with transparency enabling applicant review, (3) candidate notice at least 10 business days before AEDT use via job postings/email explaining assessed qualifications, alternative selection process availability, reasonable accommodation request procedures. Audit process involves data collection from historical candidates, category assignment identifying demographics, outcome tracking of selections, rate calculation per category, impact analysis comparing ratios, report generation documenting methodology. Real-world compliance challenges include data availability (candidates don't always provide demographics requiring historical data or proxy estimation), defining "substantially assist" (gray area determining what counts as substantial human judgment replacement), third-party tool responsibility (vendor vs employer audit obligations, data sharing refusals, shared audit questions), and audit costs ($5K-$50K+ creating burden for smaller employers). Enforcement by NYC Department of Consumer and Worker Protection imposes penalties up to $500 first violation, $1,500 subsequent violations with each day as separate violation though late 2024 enforcement remains light focusing on education/outreach. Law influences beyond NYC - Colorado AI Act includes employment as consequential decision, Illinois strengthens AI Video Interview Act enforcement, California considers similar disclosure requirements, EEOC references LL 144 in AI guidance, vendors increasingly offer built-in bias auditing, national employers adopt LL 144-like practices company-wide for simplicity and preparation for expected regulation elsewhere. Compliance best practices require employers to inventory hiring tools, assess AEDT coverage, engage auditors early, coordinate with vendors requesting bias documentation/audit support, update job postings with notice language, train recruiters on requirements, prepare for candidate questions about alternatives, document everything. NYC LL 144 milestone establishes accountability principle - when AI makes livelihood decisions, transparency and bias testing are mandatory, though law has limitations and critics from all sides (employers find burdensome/vague, advocates find narrow/weak enforcement, vendors worry about competitive disadvantage/gaming risk).
relatedConcepts:
  - nyc-local-law-144
  - automated-employment-decision-tools
  - aedt
  - bias-audits
  - employment-ai-regulation
  - adverse-impact
  - selection-rates
  - impact-ratios
  - four-fifths-rule
  - eeoc-guidance
  - independent-auditor
  - demographic-testing
  - sex-categories
  - race-ethnicity-categories
  - public-disclosure
  - candidate-notice
  - transparency-requirements
  - alternative-selection-process
  - reasonable-accommodation
  - audit-methodology
  - data-availability
  - substantially-assist
  - third-party-ai-vendors
  - audit-costs
  - dcwp-enforcement
  - penalty-structure
  - hiring-ai-compliance
  - nyc-geography-trigger
  - vendor-audit-support
  - national-compliance-adoption
examples:
  - algorithmic-bias-case-studies
  - ai-governance-use-cases
  - ai-safety-incidents-case-studies
templates:
  - ai-governance-framework-builder
  - ai-vendor-assessment-template
  - ai-regulatory-readiness-assessment
crossPathRefs:
  - path: responsibility
    articles:
      - ai-and-employment-law-hiring-algorithms-under-scrutiny
      - ai-governance-frameworks-building-your-organizations-approach
      - the-legal-patchwork-existing-laws-that-apply-to-ai
  - path: risk
    articles:
      - algorithmic-bias-how-ai-discriminates-and-why
      - building-trustworthy-ai-the-seven-pillars
tags:
  - nyc-law-144
  - aedt
  - bias-audits
  - employment-ai
  - hiring-algorithms
  - compliance
  - transparency
  - regulation
  - discrimination
  - accountability
category: Legal Frameworks
image: nyc-local-law-144-automated-employment-decision-tools.jpg
imageAlt: NYC Local Law 144 compliance workflow showing bias audit requirement, public disclosure, and candidate notice for automated employment decision tools
author: Sunil Iyer
readingTime: 18
seoTitle: NYC Local Law 144 - AI Hiring Bias Audit & Compliance Guide
seoDescription: NYC Local Law 144 AI hiring regulation - bias audit requirements (selection rates, impact ratios, four-fifths rule), public disclosure, candidate notice, independent auditor, AEDT definition, compliance challenges (data, substantially assist, vendor responsibility), enforcement, best practices.
---

## Summary

NYC Local Law 144, effective July 2023, establishes the United States' first regulation specifically targeting AI in hiring, requiring employers and employment agencies using Automated Employment Decision Tools (AEDTs) in New York City to ensure fairness through bias audits, public transparency, and candidate notification. An AEDT is defined as "any computational process, derived from machine learning, statistical modeling, data analytics, or artificial intelligence, that issues simplified output, including a score, classification, or recommendation, that is used to substantially assist or replace discretionary decision making for making employment decisions" requiring the tool to (1) use AI/ML techniques not just keyword matching, (2) produce score/classification/recommendation, (3) substantially assist or replace human judgment, (4) be used for employment decisions. The law applies based on where the job is located, not where company or candidate is located—San Francisco company hiring for NYC positions must comply. Three core requirements create accountability framework: Requirement 1 annual independent bias audit before AEDT use and annually thereafter conducted by independent auditor (not employed by company or vendor, no financial interest in outcome) calculating selection rates (or scoring rates for ranking systems) for sex categories (male, female, non-binary/unknown) and race/ethnicity categories (Hispanic/Latino, White, Black/African American, Asian, Native Hawaiian/Pacific Islander, American Indian/Alaska Native, two or more races) then computing impact ratios comparing each category's selection rate to highest-selected category's rate with EEOC's four-fifths rule (80% threshold) typically referenced where protected group selection rate <80% highest group indicates potential adverse impact requiring investigation. Requirement 2 public disclosure publishing bias audit summary on company website including most recent audit date, candidate distribution across categories if available, selection/scoring rates for each category, impact ratios creating transparency enabling job applicants to see how AI tools perform across demographic groups. Requirement 3 candidate notice provided at least 10 business days before AEDT use for candidates residing in NYC (via job posting, email, or written communication) and employees evaluated for promotion/retention explaining what job qualifications the AEDT assesses, informing of right to request alternative selection process, explaining how to request reasonable accommodation.

Audit process involves systematic evaluation: (1) data collection gathering historical data on candidates evaluated by AEDT with sufficient volume for statistical significance, (2) category assignment identifying candidates' race/ethnicity and sex categories which presents challenges when candidates don't provide demographic information requiring historical data use or proxy estimation, (3) outcome tracking recording who was selected/scored positively versus not selected for each demographic category, (4) rate calculation computing selection rates (selected candidates / total candidates) for each sex and race/ethnicity category, (5) impact analysis calculating impact ratios (each category's rate / highest category's rate) where ratios below 0.80 indicate potential adverse impact, (6) report generation documenting findings including methodology, sample sizes, rates, ratios, limitations with independent auditor certification. Audit results don't automatically prohibit tools showing disparate impact—law requires audit not discrimination elimination—but results might indicate violations under existing civil rights laws (Title VII, ADEA, ADA) prompting companies to investigate causes, work with vendors to adjust/retrain systems, or discontinue use.

Real-world compliance challenges create implementation complexity: Challenge 1 data availability where many employers lack complete demographic data on applicants since candidates aren't required to provide race/ethnicity creating options of using historical data from voluntary reporting (risking unrepresentative samples) or using proxy data through statistical estimation based on name/geography (controversial and imperfect). Challenge 2 defining "substantially assist" where law covers tools that substantially assist decisions but interpretation remains unclear—AI ranking candidates 1-100 with recruiters interviewing only top 10 clearly covered, AI providing suggested scores frequently overridden by recruiters presents gray area, AI organizing resumes alphabetically likely not covered—with NYC Department of Consumer and Worker Protection providing some guidance but interpretation challenges persisting. Challenge 3 third-party tool responsibility where many employers use hiring platforms from vendors (HireVue, Pymetrics, HiredScore) raising questions whether employer or vendor responsible for audit, what happens when vendor refuses to share needed data, whether multiple employers can share one vendor audit—current practice sees many vendors providing audit results to clients though employers remain ultimately responsible. Challenge 4 audit costs ranging $5,000-$50,000+ depending on AEDT complexity, historical data volume, number of tools, analysis depth creating significant burden for smaller employers.

Enforcement by NYC Department of Consumer and Worker Protection establishes penalty structure: first violation up to $500 civil penalty, subsequent violations up to $1,500 per violation with each day of non-compliance counting as separate violation (example: AEDT use without proper notice for 30 days = $500 first day + $1,500 × 29 = $44,000 total). Late 2024 enforcement remains relatively light with DCWP focusing on education/outreach, no major penalty actions publicly announced, apparent grace period for compliance though this may change as law matures and enforcement resources increase. Impact beyond NYC demonstrates national influence: Colorado AI Act includes employment as "consequential decision" requiring impact assessments, Illinois strengthens AI Video Interview Act enforcement, California considers similar disclosure requirements, EEOC references LL 144 in AI guidance on automated employment decision systems, industry self-regulation accelerates with vendors increasingly offering built-in bias auditing/industry groups developing best practices/third-party auditor ecosystem expanding/transparency becoming competitive differentiator, national employers adopt LL 144-like practices company-wide finding this easier than location-specific compliance while demonstrating fair hiring commitment and preparing for expected regulation elsewhere.

Compliance best practices for employers require systematic approach: (1) inventory hiring tools knowing what AI/ML systems used in recruiting across all platforms/vendors/internal tools, (2) assess AEDT coverage determining which tools qualify under definition (AI/ML technique, simplified output, substantially assist, employment decision), (3) engage auditors early since good independent auditors have limited capacity requiring advance booking, (4) coordinate with vendors requesting bias documentation, audit support including data access, demographic information, audit cost sharing where applicable, (5) update job postings including required notice language example: "This job posting uses an automated employment decision tool to help screen candidates. More information about the tool, including the bias audit results, is available at [link]. Candidates may request an alternative selection process or a reasonable accommodation under applicable laws," (6) train recruiters ensuring staff understand requirements, can answer candidate questions, know alternative process procedures, document decisions, (7) prepare for candidate questions developing responses about how AI works, what it assesses, how to request alternatives/accommodations, how decisions are made, (8) document everything maintaining records of audits, notices, candidate requests, vendor communications, decision processes for regulatory examination/legal defense. For vendors best practices include conducting internal bias testing before client audits, providing audit support helping clients obtain required data, offering transparency considering publishing own bias analysis, building in fairness incorporating bias mitigation into development, communicating proactively keeping clients informed about compliance. For job seekers rights include looking for AEDT notices in job postings, requesting alternative selection processes (human review), knowing discrimination remains illegal regardless of AI involvement, filing complaints reporting violations to NYC DCWP.

Future developments likely include NYC possible amendments clarifying ambiguities and strengthening enforcement, federal EEOC continuing to develop AI guidance with possible legislation, states more states adopting similar requirements following NYC template, courts eventual lawsuits clarifying interpretations of substantially assist/independent auditor/bias thresholds. Emerging best practices across jurisdictions converge on principles: regular auditing of AI hiring tools, transparency about AI use in recruiting, human oversight for significant decisions, candidate rights to explanation and appeal, ongoing monitoring after deployment recognizing point-in-time audits insufficient for systems that drift over time.

## Key Learning Objectives

After reading this article, you will be able to:

1. **Define AEDT requirements** - Four elements (AI/ML technique, simplified output, substantially assist, employment decision) with geographic trigger
2. **Implement bias audit process** - Six steps (data collection, category assignment, outcome tracking, rate calculation, impact analysis, reporting)
3. **Apply four-fifths rule** - Impact ratio calculation comparing protected group selection rate to highest group, <0.80 indicates adverse impact
4. **Navigate demographic categories** - Sex (male, female, non-binary/unknown) and race/ethnicity (seven categories) for selection rate testing
5. **Meet public disclosure requirements** - Website publication of audit date, distributions, selection/scoring rates, impact ratios with stakeholder accessibility
6. **Provide candidate notice** - 10 business day advance notice explaining assessed qualifications, alternative processes, accommodation requests
7. **Address compliance challenges** - Data availability (historical/proxy), substantially assist definition, third-party responsibility, audit costs
8. **Understand enforcement structure** - DCWP authority, penalty tiers ($500 first, $1,500 subsequent), per-day violations, current light enforcement
9. **Recognize national influence** - Colorado/Illinois/California adoption, EEOC guidance references, vendor ecosystem changes, employer nationwide practices
10. **Execute best practices** - Inventory tools, assess coverage, engage auditors early, coordinate vendors, update postings, train staff, document comprehensively

---

*[Full article content from staging file with all sections on What Problem Law Solving, Requirements, Audit Process, Challenges, Criticisms, Enforcement, Company Responses, Impact Beyond NYC, Best Practices, Future of AI Hiring Regulation, Conclusion]*

---

## Sources

1. New York City Council. "Local Law 144 of 2021." https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4344524

2. NYC Department of Consumer and Worker Protection. "Automated Employment Decision Tools." 2023. https://www.nyc.gov/site/dca/about/automated-employment-decision-tools.page

3. NYC DCWP. "Final Rules for Automated Employment Decision Tools." April 2023. https://rules.cityofnewyork.us/rule/automated-employment-decision-tools-background/

4. EEOC. "The Americans with Disabilities Act and the Use of Software, Algorithms, and Artificial Intelligence to Assess Job Applicants and Employees." May 2022.

5. Brookings Institution. "New York City's Automated Decision Systems Law: A First Look." 2023.

6. Center for Democracy and Technology. "NYC Local Law 144: AI Hiring Law Analysis." 2023.

7. Reuters. "Amazon scraps secret AI recruiting tool that showed bias against women." October 2018.

8. MIT Technology Review. "Bias isn't the only problem with AI in hiring." August 2023.

9. Hunton Andrews Kurth. "NYC Automated Employment Decision Tools Law Takes Effect." July 2023.

10. Society for Human Resource Management. "NYC AI Hiring Law: What HR Needs to Know." 2023.

---

*Next: California AI Regulations – The Golden State's Approach*
