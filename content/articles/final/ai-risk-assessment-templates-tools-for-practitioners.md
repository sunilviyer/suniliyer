---
title: "AI Risk Assessment Templates: Tools for Practitioners"
slug: ai-risk-assessment-templates-tools-for-practitioners
path: risk
publishDate: 2025-10-27
tldr: Practical AI risk assessment templates transform abstract governance principles into concrete operational tools, enabling consistent, efficient, and thorough risk evaluation across AI systems. Five essential templates address the complete risk management lifecycle—Template 1 (AI System Initial Risk Screening) provides quick 15-30 minute triage determining assessment level through 20 risk factors across decision impact, scale/scope, vulnerable populations, technical factors, and regulatory considerations with scoring producing risk classification (0-4 low, 5-9 medium, 10-14 high, 15-20 critical) determining assessment depth required. Template 2 (Standard AI Risk Assessment) offers comprehensive 2-4 hour assessment for medium-risk systems across 7 parts (system description, risk identification covering fairness/bias/privacy/safety/transparency/reliability/security, risk analysis with likelihood/impact matrix, existing controls, mitigation plan, residual risk, monitoring requirements) with structured approval process. Template 3 (AI Risk Register) enables enterprise-level ongoing tracking across multiple systems with dashboard showing total systems, open risks distributed by severity, trend analysis, individual risk entries tracking ID, system, description, category, likelihood/impact/level, controls, mitigation, owner, status, and change log. Template 4 (AI Bias Assessment Checklist) provides focused fairness evaluation covering context assessment (domain, protected groups, harm potential), data assessment (representation analysis, historical bias, label quality), feature assessment (protected characteristics, proxy variables, relevance validation), outcome testing (disparate impact with four-fifths rule, error rate analysis, fairness metrics), and findings with recommended actions. Template 5 (AI Incident Report) documents learning from AI-related incidents through systematic capture of incident description, impact assessment (individuals affected, harm types, severity), immediate response (actions taken, system status, notifications), root cause analysis (technical and process causes, contributing factors), corrective actions with owners and timelines, and lessons learned for preventing recurrence. Templates enable consistent coverage of important areas, create comparable documentation across systems/time/teams, save time on format/structure focusing energy on analysis, support training by codifying what to assess, facilitate reporting by standardizing information collection, enable trending by making risk data comparable, and demonstrate diligence through systematic documented processes. Implementation requires customization to organizational context (terminology, categories, depth), integration with existing processes (risk management, project management, documentation systems), version control, user training on proper completion, starting simple with screening template adding complexity as maturity grows, creating reference examples from real systems, collecting user feedback for iteration, and automation where possible through digital forms or GRC systems. The best template is one that gets used—start with what works, improve over time, and build toolkit serving organizational needs, recognizing templates are tools making assessment faster, more consistent, and complete but cannot substitute for genuine analysis and judgment.
relatedConcepts:
  - ai-risk-assessment-templates
  - risk-assessment-tools
  - practical-risk-assessment
  - risk-screening-template
  - initial-risk-triage
  - risk-factor-scoring
  - decision-impact-assessment
  - scale-scope-assessment
  - vulnerable-population-assessment
  - technical-risk-factors
  - regulatory-risk-factors
  - risk-level-classification
  - low-risk-classification
  - medium-risk-classification
  - high-risk-classification
  - critical-risk-classification
  - assessment-depth-determination
  - standard-risk-assessment
  - comprehensive-risk-assessment
  - system-description-documentation
  - risk-identification
  - fairness-bias-risks
  - privacy-data-risks
  - safety-risks
  - transparency-explainability-risks
  - reliability-risks
  - security-risks
  - risk-analysis-matrix
  - likelihood-impact-matrix
  - existing-controls-assessment
  - mitigation-plan-development
  - residual-risk-evaluation
  - monitoring-requirements
  - approval-process
  - ai-risk-register
  - enterprise-risk-tracking
  - risk-dashboard
  - risk-distribution
  - trend-analysis
  - risk-entry-tracking
  - risk-id-system
  - risk-categorization
  - risk-status-tracking
  - change-log
  - closed-risks-archive
  - bias-assessment-checklist
  - fairness-evaluation
  - context-assessment
  - protected-groups-analysis
  - harm-potential-assessment
  - data-assessment
  - representation-analysis
  - historical-bias-assessment
  - label-quality-assessment
  - feature-assessment
  - protected-characteristics-analysis
  - proxy-variable-detection
  - relevance-validation
  - outcome-testing
  - disparate-impact-analysis
  - four-fifths-rule
  - error-rate-analysis
  - fairness-metrics-testing
  - demographic-parity-testing
  - equal-opportunity-testing
  - predictive-parity-testing
  - findings-documentation
  - recommended-actions
  - ai-incident-report
  - incident-documentation
  - learning-from-incidents
  - incident-description
  - discovery-method
  - incident-categorization
  - impact-assessment-incident
  - individuals-affected
  - harm-types
  - severity-assessment-incident
  - immediate-response
  - system-status
  - notification-requirements
  - root-cause-analysis
  - technical-root-cause
  - process-root-cause
  - contributing-factors
  - corrective-actions
  - action-owners
  - action-timelines
  - lessons-learned
  - recurrence-prevention
  - template-customization
  - organizational-adaptation
  - process-integration
  - version-control
  - user-training
  - simple-start
  - reference-examples
  - feedback-collection
  - template-iteration
  - automation
  - digital-forms
  - grc-systems
  - consistent-coverage
  - comparable-documentation
  - time-efficiency
  - training-support
  - reporting-facilitation
  - trending-enablement
  - diligence-demonstration
examples:
  - Customer churn prediction model completing initial screening with 5 Yes responses (medium risk) triggering standard risk assessment requirement
  - Resume screening AI comprehensive assessment identifying gender discrimination (likelihood Medium, impact High = High risk level) requiring mitigation before deployment
  - Enterprise risk register tracking 47 AI systems with 12 open risks (3 critical, 4 high, 3 medium, 2 low), trend improving from previous quarter
  - Hiring AI bias assessment revealing age discrimination (selection rate 22% vs 38% baseline, 58% ratio failing four-fifths rule) requiring immediate remediation
  - Credit scoring AI incident report documenting discriminatory outcomes affecting 1,247 individuals, root cause analysis identifying training data bias, corrective actions including model retraining and fairness constraints
  - Fraud detection system monitoring plan with monthly demographic parity testing, threshold <85% triggering immediate investigation
  - Healthcare diagnostic AI requiring critical-risk full impact assessment with executive/board approval and external independent review
templates:
  - AI System Initial Risk Screening Template (20 risk factors across 5 categories with scoring guide)
  - Standard AI Risk Assessment Template (7-part comprehensive assessment)
  - AI Risk Register Template (enterprise tracking with dashboard, entries, closed risks, change log)
  - AI Bias Assessment Checklist Template (context, data, features, outcomes, findings)
  - AI Incident Report Template (description, impact, response, root cause, corrective actions, lessons)
  - Risk Screening Completed Example (customer churn model)
  - Risk Assessment Approval Form
  - Mitigation Plan Tracking Table
  - Monitoring Requirements Table
  - Lessons Learned Documentation Form
crossPathRefs:
  - slug: nist-ai-rmf-core-functions-govern-map-measure-manage
    path: risk
    relevance: Templates operationalize NIST AI RMF functions—screening aligns with GOVERN (categorization), assessment implements MAP (context/risks), monitoring supports MEASURE (tracking/analysis), incident reports enable MANAGE (response/improvement)
  - slug: algorithmic-impact-assessments-a-step-by-step-guide
    path: responsibility
    relevance: Risk assessment templates provide practical tools implementing AIA process—initial screening determines AIA depth needed, standard assessment covers AIA steps 1-7, bias checklist implements AIA Step 5 fairness deep dive
  - slug: iso-31000-for-ai-applying-risk-management-principles
    path: risk
    relevance: Templates structure ISO 31000 risk management process—risk identification (scope/context/criteria), analysis (likelihood/impact), evaluation (risk level), treatment (mitigation plan), monitoring (ongoing tracking)
  - slug: the-singapore-model-ai-governance-framework-practical-implementation
    path: responsibility
    relevance: Templates implement Singapore framework practical guidance—risk screening supports decision model determination, assessment covers operations management requirements, monitoring aligns with ISAGO self-assessment
  - slug: ai-ethics-principles-and-frameworks
    path: responsibility
    relevance: Templates translate abstract ethics principles into concrete assessments—fairness becomes bias checklist with quantitative testing, transparency becomes explainability risk assessment, accountability becomes incident reporting process
tags:
  - article
  - risk-assessment-templates
  - practical-tools
  - risk-screening
  - risk-register
  - bias-assessment
  - incident-reporting
  - ai-governance-tools
  - risk-management
  - assessment-frameworks
  - documentation-templates
  - monitoring-tools
  - enterprise-risk-management
  - operational-tools
  - practitioner-resources
category: AI Risks & Principles
image: article-75-ai-risk-assessment-templates-tools-for-practitioners.jpg
imageAlt: AI Risk Assessment Templates - Tools for Practitioners
author: Sunil Iyer
readingTime: 20
seoTitle: AI Risk Assessment Templates - Tools for Practitioners
seoDescription: Five practical AI risk assessment templates for screening, comprehensive assessment, risk registers, bias evaluation, and incident reporting. Ready-to-use tools with examples and implementation guidance.
---



## Summary

Practical AI risk assessment templates transform abstract governance principles into concrete operational tools, enabling consistent, efficient, and thorough risk evaluation across AI systems. While frameworks provide conceptual guidance, templates provide the structured forms, checklists, and documentation tools practitioners actually use to operationalize governance.

Five essential templates address the complete risk management lifecycle from initial triage through ongoing monitoring and incident response:

**Template 1: AI System Initial Risk Screening** provides quick 15-30 minute triage to determine what level of assessment an AI system needs, prioritizing assessment efforts efficiently. The template evaluates 20 risk factors across five categories: B1 Decision Impact (does system make decisions about individuals, are decisions reversible, potential financial harm >$1000, physical health/safety impact), B2 Scale and Scope (affects >1000 people annually, operates >6 months, operates without human oversight, multi-jurisdictional), B3 Vulnerable Populations (children affected, employment decisions, disadvantaged groups, sensitive domains like healthcare/education/housing/criminal justice), B4 Technical Risk Factors (personal data inputs, difficult to explain, learns in production, third-party system with limited visibility), and B5 Regulatory Considerations (specific AI regulations apply, sector-specific regulations, regulator interest, significant legal liability). Scoring produces risk classification: 0-4 Yes responses indicates Low Risk requiring abbreviated assessment with standard development practices; 5-9 Yes indicates Medium Risk requiring standard risk assessment with department-level approval; 10-14 Yes indicates High Risk requiring comprehensive risk assessment with senior management approval and consideration of external review; 15-20 Yes indicates Critical Risk requiring full impact assessment with executive/board approval, external independent review, and careful consideration of whether to proceed.

**Template 2: Standard AI Risk Assessment** offers comprehensive 2-4 hour assessment for medium-risk systems requiring input from multiple stakeholders. The template structures assessment across seven parts: Part 1 System Description documents identification, purpose/functionality, users/stakeholders, and human oversight level; Part 2 Risk Identification systematically evaluates fairness and bias risks (protected characteristics, training data bias, proxy variables), privacy and data risks (personal data types, protection concerns, quality issues), safety risks (physical, psychological, financial harm potential), transparency and explainability risks (can decisions be explained, are users aware), reliability risks (accuracy concerns, performance degradation, dependency risks), security risks (adversarial attacks, data security), and other risks not covered; Part 3 Risk Analysis applies likelihood/impact matrix to each identified risk determining combined risk level (Critical/High/Medium/Low); Part 4 Existing Controls documents technical, procedural, and governance controls already in place with effectiveness assessment; Part 5 Mitigation Plan defines specific actions for High/Critical risks with owners and due dates; Part 6 Residual Risk and Recommendation assesses risks remaining after mitigation, determines acceptability, and makes deployment recommendation (Proceed/Proceed with Conditions/Defer/Do Not Proceed); Part 7 Monitoring Requirements specifies ongoing metrics, measurement frequency, alert thresholds, reassessment triggers, and next scheduled review with structured approval process (assessor, reviewer, approver signatures with conditions if applicable).

**Template 3: AI Risk Register** enables enterprise-level ongoing tracking of all AI risks across organization or portfolio of systems for regular reporting to leadership. The template provides Summary Dashboard (total AI systems, total open risks, risk distribution by Critical/High/Medium/Low, trend vs last period as Improving/Stable/Worsening), detailed Risk Register Entries for each risk tracking ID, System, Risk Description, Category (Bias/Privacy/Safety/Reliability/Security/Transparency/Other), Likelihood (H/M/L), Impact (H/M/L), Risk Level (Critical/High/Medium/Low), Current Controls, Mitigation Plan, Owner, Due Date, Status (Open/In Progress/Pending Review/Closed), Last Update, and Notes, Closed Risks archive maintaining last 12 months of closed risks with ID, System, Risk Description, Resolution, and Closed Date, and Risk Register Change Log documenting all register modifications with Date, Change Description, and By whom.

**Template 4: AI Bias Assessment Checklist** provides focused fairness evaluation addressing discrimination risks systematically. The checklist covers five sections: Section 1 Context Assessment evaluates domain/use case (what decisions system informs, harm potential from biased decisions ranging from Critical to Minimal), relevant anti-discrimination laws/regulations, and Protected Groups Analysis identifying which protected characteristics could be affected (age, gender/sex, race/ethnicity, disability, religion, national origin, sexual orientation, veteran status, pregnancy, genetic information, other) and historically disadvantaged groups in domain; Section 2 Data Assessment reviews training data sources/time period/geographic scope, Representation Analysis comparing demographic breakdown of training data to target population identifying underrepresented groups, Historical Bias assessment (could historical discrimination be reflected in data with likelihood rating), and Label Quality (who/what created labels, could labeling reflect human bias); Section 3 Feature Assessment analyzes Protected Characteristics as Features (used directly, derived, or not), Proxy Variable Analysis identifying features that may proxy for protected characteristics with correlation analysis, and Feature Relevance validating all features are demonstrably relevant to legitimate purpose; Section 4 Outcome Testing documents testing methodology (test data source, sample size, demographic labels availability), Disparate Impact Analysis using 80% four-fifths rule as threshold with selection rates by group and pass/fail determination, Error Rate Analysis comparing false positive/false negative rates across groups, and Other Fairness Metrics tested (demographic parity, equal opportunity, predictive parity, calibration, individual fairness); Section 5 Findings and Recommendations summarizes key findings, assigns overall Bias Risk Level (High with significant disparities, Medium with some concerns, Low with no significant issues), lists Recommended Actions with priority and owner, and provides Monitoring Recommendations with approval/deployment decision.

**Template 5: AI Incident Report** documents learning from AI-related incidents including harm, near-misses, discovered bias/errors in production, or complaints about AI decisions. The template systematically captures seven sections: Section 1 System Information (name, owner, version); Section 2 Incident Description (summary of what happened, how discovered through user complaint/internal monitoring/external report/audit finding/other, incident category as discriminatory outcome/incorrect decision/privacy breach/system failure/security incident/safety issue/other); Section 3 Impact Assessment (who was affected with number of individuals and groups particularly affected, what was the harm categorized as financial loss/physical harm/psychological harm/privacy violation/reputational harm/other, Severity Assessment rating Critical/High/Medium/Low based on harm scope and impact); Section 4 Immediate Response (immediate actions taken, system status as continued/modified/suspended/decommissioned, whether affected parties were notified with timing and method); Section 5 Root Cause Analysis (technical root cause, process root cause explaining why not caught earlier, contributing factors); Section 6 Corrective Actions table listing Action, Owner, and Due Date for each remediation; Section 7 Lessons Learned documenting what should be done differently, changes to prevent recurrence, whether other systems should be reviewed and which ones, with Approvals and Closure section requiring report completion, review, closure, and closure verification checklist confirming all corrective actions completed, effectiveness verified, documentation updated, and lessons learned shared.

Templates deliver multiple organizational benefits: Consistent Coverage ensuring important areas aren't overlooked through systematic checklists; Comparable Documentation across systems, time periods, and teams enabling apples-to-apples comparison; Time Efficiency saving time on format and structure so energy focuses on analysis and decisions rather than figuring out what to document; Training Support codifying what to assess helping new team members learn risk assessment systematically; Reporting Facilitation standardizing information collection making reports to leadership easier to compile; Trending Enablement making risk data comparable across time enabling pattern detection and improvement tracking; and Diligence Demonstration showing systematic documented processes valuable for regulators, auditors, and stakeholders.

Implementation requires several key practices: Customization adapting templates to organizational context (modify terminology, categories, depth to fit industry, culture, maturity level); Process Integration connecting templates to existing risk management, project management, and documentation systems rather than creating parallel processes; Version Control maintaining template versions and documenting changes over time; User Training ensuring users understand how to complete templates correctly through instruction, examples, and support; Starting Simple beginning with screening template and adding complexity as maturity grows rather than overwhelming teams with comprehensive assessments initially; Creating Reference Examples completing templates for real systems creating reference examples teams can learn from; Collecting Feedback asking users what works and what doesn't, iterating based on real experience; and Automation where possible moving templates to digital forms or GRC systems for better tracking, automated alerting, and easier reporting rather than static documents.

The fundamental truth about templates is simple: The best template is one that gets used. A perfect comprehensive template that teams find too burdensome and therefore skip is worthless. A simpler template that teams actually complete, finding it genuinely helpful, creates real value. Start with what works for your organization's current state, improve over time based on feedback and experience, and build a toolkit serving your actual needs. Templates are tools making AI risk assessment faster, more consistent, and complete—but they cannot substitute for genuine analysis and judgment. Use templates to structure and document thinking, not replace it.



## Key Learning Objectives

1. Understand role of templates in operationalizing abstract AI governance principles into concrete assessment practices
2. Apply AI System Initial Risk Screening to triage systems and determine appropriate assessment depth in 15-30 minutes
3. Conduct Standard AI Risk Assessment covering identification, analysis, controls, mitigation, residual risk, and monitoring in 2-4 hours
4. Maintain AI Risk Register tracking enterprise-level risks across multiple systems with dashboard, entries, and trend analysis
5. Execute AI Bias Assessment Checklist evaluating context, data, features, and outcomes with disparate impact testing
6. Document AI incidents systematically capturing description, impact, response, root cause, corrective actions, and lessons learned
7. Customize templates to organizational context while maintaining core assessment rigor and consistency
8. Integrate templates into existing risk management and project management processes
9. Create reference examples and training materials enabling effective template adoption
10. Recognize templates as tools supporting but not replacing genuine analysis, judgment, and decision-making



## Template 1: AI System Initial Risk Screening


### Purpose

Quick triage to determine what level of assessment an AI system needs. Use this first to prioritize assessment efforts.

*Example:* Organization discovers 23 AI systems across departments through inventory. Rather than conducting lengthy comprehensive assessments for all systems equally, uses initial screening to classify: 3 as high-risk requiring comprehensive assessment (hiring AI, credit decisioning, healthcare diagnostic), 8 as medium-risk requiring standard assessment (customer service routing, fraud detection, pricing optimization), 10 as low-risk requiring abbreviated assessment (spam filtering, autocomplete, internal search), 2 as minimal-risk requiring only brief documentation (website analytics, A/B testing). Screening enables efficient resource allocation focusing rigor on highest-risk systems.


### When to Use

- When a new AI system is proposed
- When an existing system is discovered in inventory
- When deciding resource allocation for assessments


### Time to Complete

15-30 minutes


### Template

```
═══════════════════════════════════════════════════════════════
AI SYSTEM INITIAL RISK SCREENING
═══════════════════════════════════════════════════════════════

SECTION A: SYSTEM IDENTIFICATION

System Name: _________________________________________________
System ID/Version: ___________________________________________
Date of Screening: ___________________________________________
Screener Name/Role: __________________________________________
System Owner: ________________________________________________

Brief Description (2-3 sentences):
______________________________________________________________
______________________________________________________________
______________________________________________________________

───────────────────────────────────────────────────────────────
SECTION B: QUICK RISK FACTORS
───────────────────────────────────────────────────────────────

Answer each question. Each "Yes" adds to risk level.

B1. Decision Impact
[ ] Does the system make or significantly influence decisions
    about individuals? (employment, credit, healthcare, etc.)
[ ] Are decisions difficult or impossible to reverse?
[ ] Could wrong decisions cause financial harm >$1,000 to
    individuals?
[ ] Could wrong decisions affect physical health or safety?

B2. Scale and Scope
[ ] Will the system affect >1,000 people per year?
[ ] Will it be used for >6 months?
[ ] Will it operate without direct human oversight?
[ ] Does it operate across multiple jurisdictions?

B3. Vulnerable Populations
[ ] Are children (<18) directly affected?
[ ] Are decisions made about employees or job applicants?
[ ] Are disadvantaged or marginalized groups specifically
    affected?
[ ] Is the system used in healthcare, education, housing, or
    criminal justice?

B4. Technical Risk Factors
[ ] Does the system use personal data as inputs?
[ ] Is the decision-making process difficult to explain?
[ ] Does the system learn/update from new data in production?
[ ] Is the system provided by a third party with limited
    visibility?

B5. Regulatory Considerations
[ ] Does the system fall under specific AI regulations
    (EU AI Act, state laws)?
[ ] Is the domain subject to sector-specific regulations
    (financial, healthcare)?
[ ] Have regulators expressed interest in this type of AI?
[ ] Could deployment create significant legal liability?

───────────────────────────────────────────────────────────────
SECTION C: RISK LEVEL DETERMINATION
───────────────────────────────────────────────────────────────

Count "Yes" responses:

Section B1 (Decision Impact):     ___ / 4
Section B2 (Scale and Scope):     ___ / 4
Section B3 (Vulnerable Populations): ___ / 4
Section B4 (Technical Factors):   ___ / 4
Section B5 (Regulatory):          ___ / 4

TOTAL "Yes" responses:            ___ / 20

Risk Level (circle one):

0-4 Yes:   LOW RISK
           → Abbreviated assessment sufficient
           → Standard development practices apply

5-9 Yes:   MEDIUM RISK
           → Standard risk assessment required
           → Department-level approval needed

10-14 Yes: HIGH RISK
           → Comprehensive risk assessment required
           → Senior management approval needed
           → Consider external review

15-20 Yes: CRITICAL RISK
           → Full impact assessment required
           → Executive/Board approval required
           → External independent review required
           → Consider whether to proceed

───────────────────────────────────────────────────────────────
SECTION D: SCREENING NOTES AND NEXT STEPS
───────────────────────────────────────────────────────────────

Key concerns identified:
______________________________________________________________
______________________________________________________________
______________________________________________________________

Recommended assessment level: _________________________________

Next steps:
[ ] Proceed to standard risk assessment
[ ] Proceed to comprehensive risk assessment
[ ] Proceed to full impact assessment
[ ] Schedule stakeholder consultation
[ ] Escalate to [role] for guidance
[ ] Other: ___________________________________________________

Screener Signature: ____________________ Date: ________________

═══════════════════════════════════════════════════════════════
```


### Example: Completed Screening

```
System Name: Customer Churn Prediction Model
System ID/Version: CHURN-v2.1
Date of Screening: October 15, 2024
Screener Name/Role: Alex Chen, Risk Analyst
System Owner: Marketing Analytics Team

Brief Description: Machine learning model that predicts which
customers are likely to cancel their subscription in the next
90 days based on usage patterns, support tickets, and payment
history. Used to trigger retention offers (discounts, feature
upgrades, outreach).

B1. Decision Impact: 1 Yes
[X] Affects decisions about individuals (customers)
[ ] Decisions difficult to reverse (offers can be modified)
[ ] Financial harm >$1000 (typical retention offer $50-200)
[ ] Physical health/safety (not applicable)

B2. Scale and Scope: 2 Yes
[X] >1,000 people per year (5,000 customers annually)
[X] >6 months (ongoing production use)
[ ] Without human oversight (marketing reviews recommendations)
[ ] Multi-jurisdictional (single country operation)

B3. Vulnerable Populations: 0 Yes
[ ] Children (B2B product, corporate customers only)
[ ] Employment decisions (not applicable)
[ ] Disadvantaged groups specifically (general customer base)
[ ] Healthcare/education/housing/justice (subscription software)

B4. Technical Factors: 2 Yes
[X] Personal data inputs (usage data, payment history, support interactions)
[X] Difficult to explain (complex ML model, partial opacity)
[ ] Learns in production (model retrained quarterly, not real-time)
[ ] Third-party system (developed internally)

B5. Regulatory: 0 Yes
[ ] Specific AI regulations (not currently covered)
[ ] Sector-specific regulations (general software, not regulated industry)
[ ] Regulator interest (no known scrutiny)
[ ] Significant legal liability (low risk of harm)

TOTAL: 5 Yes → MEDIUM RISK

Key concerns identified:
- Uses personal behavioral data for targeting decisions
- Customers unaware of profiling for retention purposes
- Potential for unfair treatment if model biased by usage patterns
- Some opacity in decision-making process

Recommended assessment level: Standard risk assessment

Next steps:
[X] Proceed to standard risk assessment
[ ] Consult with Privacy team before deployment
[ ] Document retention offer fairness metrics
[ ] Consider customer transparency notice

Screener Signature: A. Chen  Date: 10/15/2024
```

---


## Template 2: Standard AI Risk Assessment


### Purpose

Comprehensive assessment of AI system risks for medium-risk systems.


### When to Use

- Initial screening indicated medium risk
- Required before deploying new AI systems
- Periodic reassessment of existing systems


### Time to Complete

2-4 hours (may require input from multiple stakeholders)


### Template

```
═══════════════════════════════════════════════════════════════
STANDARD AI RISK ASSESSMENT
═══════════════════════════════════════════════════════════════

DOCUMENT CONTROL
Assessment ID: _____________  Version: ________
Assessment Date: ___________  Next Review: __________
Assessor(s): ________________________________________________
Reviewed by: ________________________________________________

───────────────────────────────────────────────────────────────
PART 1: SYSTEM DESCRIPTION
───────────────────────────────────────────────────────────────

1.1 System Identification
Name: _______________________________________________________
Version: ____________________________________________________
Type: [ ]Classification [ ]Regression [ ]NLP [ ]Computer Vision
      [ ]Recommendation [ ]Generative [ ]Other: ______________
Vendor/Developer: ___________________________________________
Deployment Status: [ ]Proposed [ ]Development [ ]Production

1.2 Purpose and Functionality
Business purpose:
______________________________________________________________
______________________________________________________________

What problem does this solve?
______________________________________________________________
______________________________________________________________

Inputs (what data does it receive?):
______________________________________________________________
______________________________________________________________

Outputs (what does it produce?):
______________________________________________________________
______________________________________________________________

How outputs are used:
______________________________________________________________
______________________________________________________________

1.3 Users and Stakeholders
Primary users (who operates the system):
______________________________________________________________

People affected by decisions:
______________________________________________________________

Other stakeholders:
______________________________________________________________

1.4 Human Oversight
Level: [ ]Human-in-the-loop [ ]Human-on-the-loop
       [ ]Human-out-of-the-loop
Describe oversight mechanism:
______________________________________________________________
______________________________________________________________

───────────────────────────────────────────────────────────────
PART 2: RISK IDENTIFICATION
───────────────────────────────────────────────────────────────

2.1 Fairness and Bias Risks

Could the system disadvantage any groups?
______________________________________________________________

Protected characteristics potentially affected:
[ ]Age [ ]Gender [ ]Race/Ethnicity [ ]Disability [ ]Religion
[ ]National Origin [ ]Other: _________________________________

Training data bias concerns:
______________________________________________________________

Proxy variable concerns:
______________________________________________________________

2.2 Privacy and Data Risks

Personal data processed:
[ ]Name [ ]Contact info [ ]Financial [ ]Health [ ]Behavioral
[ ]Biometric [ ]Location [ ]Other: ___________________________

Data protection concerns:
______________________________________________________________

Data quality issues:
______________________________________________________________

2.3 Safety Risks

Could errors cause physical harm?   [ ]Yes [ ]No
Could errors cause psychological harm? [ ]Yes [ ]No
Could errors cause financial harm?  [ ]Yes [ ]No

Describe potential harms:
______________________________________________________________
______________________________________________________________

2.4 Transparency and Explainability Risks

Can decisions be explained to affected parties?
[ ]Yes [ ]Partial [ ]No

Describe explainability challenges:
______________________________________________________________

Are users aware AI is used? [ ]Yes [ ]Partial [ ]No

2.5 Reliability Risks

Accuracy concerns:
______________________________________________________________

Performance degradation risks:
______________________________________________________________

Dependency risks (what if system fails?):
______________________________________________________________

2.6 Security Risks

Adversarial attack vulnerabilities:
______________________________________________________________

Data security concerns:
______________________________________________________________

2.7 Other Risks

Additional concerns not covered above:
______________________________________________________________
______________________________________________________________

───────────────────────────────────────────────────────────────
PART 3: RISK ANALYSIS
───────────────────────────────────────────────────────────────

For each identified risk, assess likelihood and impact:

┌────────────────────────┬────────────┬──────────┬───────────┐
│ Risk Description       │ Likelihood │ Impact   │ Risk Level│
│                        │ (H/M/L)    │ (H/M/L)  │ (Critical/│
│                        │            │          │ High/Med/ │
│                        │            │          │ Low)      │
├────────────────────────┼────────────┼──────────┼───────────┤
│                        │            │          │           │
├────────────────────────┼────────────┼──────────┼───────────┤
│                        │            │          │           │
├────────────────────────┼────────────┼──────────┼───────────┤
│                        │            │          │           │
├────────────────────────┼────────────┼──────────┼───────────┤
│                        │            │          │           │
├────────────────────────┼────────────┼──────────┼───────────┤
│                        │            │          │           │
├────────────────────────┼────────────┼──────────┼───────────┤
│                        │            │          │           │
└────────────────────────┴────────────┴──────────┴───────────┘

Risk Level Matrix:
                    Impact
                    Low    Medium    High
Likelihood  High    Medium  High     Critical
            Medium  Low     Medium   High
            Low     Low     Low      Medium

───────────────────────────────────────────────────────────────
PART 4: EXISTING CONTROLS
───────────────────────────────────────────────────────────────

What controls are already in place?

Technical controls:
______________________________________________________________
______________________________________________________________

Procedural controls:
______________________________________________________________
______________________________________________________________

Governance controls:
______________________________________________________________
______________________________________________________________

Assessment of control effectiveness:
[ ]Effective [ ]Partially effective [ ]Ineffective [ ]Unknown

───────────────────────────────────────────────────────────────
PART 5: MITIGATION PLAN
───────────────────────────────────────────────────────────────

For each High/Critical risk, define mitigation:

┌────────────────┬───────────────────┬──────────┬──────────────┐
│ Risk           │ Mitigation Action │ Owner    │ Due Date     │
├────────────────┼───────────────────┼──────────┼──────────────┤
│                │                   │          │              │
├────────────────┼───────────────────┼──────────┼──────────────┤
│                │                   │          │              │
├────────────────┼───────────────────┼──────────┼──────────────┤
│                │                   │          │              │
├────────────────┼───────────────────┼──────────┼──────────────┤
│                │                   │          │              │
└────────────────┴───────────────────┴──────────┴──────────────┘

───────────────────────────────────────────────────────────────
PART 6: RESIDUAL RISK AND RECOMMENDATION
───────────────────────────────────────────────────────────────

After mitigations, what risks remain?
______________________________________________________________
______________________________________________________________

Is residual risk acceptable? [ ]Yes [ ]No [ ]Conditional

Recommendation:
[ ] PROCEED - Risks acceptable, deploy with standard monitoring
[ ] PROCEED WITH CONDITIONS - Deploy subject to: _______________
    ___________________________________________________________
[ ] DEFER - Address mitigations before deployment
[ ] DO NOT PROCEED - Risks unacceptable

───────────────────────────────────────────────────────────────
PART 7: MONITORING REQUIREMENTS
───────────────────────────────────────────────────────────────

Metrics to monitor:
┌─────────────────────────┬───────────────┬───────────────────┐
│ Metric                  │ Frequency     │ Alert Threshold   │
├─────────────────────────┼───────────────┼───────────────────┤
│                         │               │                   │
├─────────────────────────┼───────────────┼───────────────────┤
│                         │               │                   │
├─────────────────────────┼───────────────┼───────────────────┤
│                         │               │                   │
└─────────────────────────┴───────────────┴───────────────────┘

Reassessment trigger events:
______________________________________________________________

Next scheduled review date: __________________________________

───────────────────────────────────────────────────────────────
APPROVALS
───────────────────────────────────────────────────────────────

Assessor:
Signature: __________________ Date: __________

Reviewer:
Name/Role: __________________ Date: __________
Signature: __________________

Approver:
Name/Role: __________________ Date: __________
Signature: __________________
Decision: [ ]Approved [ ]Approved with conditions [ ]Not approved
Conditions (if any):
______________________________________________________________

═══════════════════════════════════════════════════════════════
```

---


## Template 3: AI Risk Register


### Purpose

Ongoing tracking of all AI risks across an organization or portfolio of systems.


### When to Use

- Enterprise-level AI risk management
- Tracking risks across multiple AI systems
- Regular reporting to leadership

*Example:* Organization with 47 AI systems across business units maintains centralized risk register showing 12 open risks (3 critical requiring immediate executive attention, 4 high with active mitigation plans, 3 medium under monitoring, 2 low accepted), trend improving from previous quarter when 18 risks were open, enabling Chief Risk Officer to provide board with comprehensive AI risk overview quarterly including risk distribution, emerging patterns (3 of 4 new risks in Q3 were privacy-related suggesting need for enhanced data governance), and mitigation effectiveness (8 risks closed in Q3, average time to closure 45 days down from 62 days in Q2).


### Template

```
═══════════════════════════════════════════════════════════════
AI RISK REGISTER
═══════════════════════════════════════════════════════════════

Organization: ________________________________________________
Register Owner: ______________________________________________
Last Updated: ________________________________________________
Next Review: _________________________________________________

───────────────────────────────────────────────────────────────
SUMMARY DASHBOARD
───────────────────────────────────────────────────────────────

Total AI Systems: ____
Total Open Risks: ____

Risk Distribution:
  Critical: ____
  High: ____
  Medium: ____
  Low: ____

Trend (vs. last period): [ ]Improving [ ]Stable [ ]Worsening

───────────────────────────────────────────────────────────────
RISK REGISTER ENTRIES
───────────────────────────────────────────────────────────────

┌──────┬──────────────────────────────────────────────────────┐
│ ID   │ R-001                                                │
├──────┼──────────────────────────────────────────────────────┤
│System│                                                      │
├──────┼──────────────────────────────────────────────────────┤
│Risk  │                                                      │
│Desc  │                                                      │
├──────┼──────────────────────────────────────────────────────┤
│Category│ [ ]Bias [ ]Privacy [ ]Safety [ ]Reliability        │
│      │ [ ]Security [ ]Transparency [ ]Other                 │
├──────┼──────────────────────────────────────────────────────┤
│Likelihood│ [ ]High [ ]Medium [ ]Low                         │
├──────┼──────────────────────────────────────────────────────┤
│Impact│ [ ]High [ ]Medium [ ]Low                             │
├──────┼──────────────────────────────────────────────────────┤
│Risk  │ [ ]Critical [ ]High [ ]Medium [ ]Low                 │
│Level │                                                      │
├──────┼──────────────────────────────────────────────────────┤
│Current│                                                     │
│Controls│                                                    │
├──────┼──────────────────────────────────────────────────────┤
│Mitigation│                                                  │
│Plan   │                                                     │
├──────┼──────────────────────────────────────────────────────┤
│Owner │                                                      │
├──────┼──────────────────────────────────────────────────────┤
│Due   │                                                      │
│Date  │                                                      │
├──────┼──────────────────────────────────────────────────────┤
│Status│ [ ]Open [ ]In Progress [ ]Pending Review [ ]Closed   │
├──────┼──────────────────────────────────────────────────────┤
│Last  │                                                      │
│Update│                                                      │
├──────┼──────────────────────────────────────────────────────┤
│Notes │                                                      │
│      │                                                      │
└──────┴──────────────────────────────────────────────────────┘

[Repeat for each risk]

───────────────────────────────────────────────────────────────
CLOSED RISKS (Last 12 Months)
───────────────────────────────────────────────────────────────

┌──────┬─────────────┬──────────────┬────────────────┬────────┐
│ ID   │ System      │ Risk Desc    │ Resolution     │ Closed │
├──────┼─────────────┼──────────────┼────────────────┼────────┤
│      │             │              │                │        │
├──────┼─────────────┼──────────────┼────────────────┼────────┤
│      │             │              │                │        │
└──────┴─────────────┴──────────────┴────────────────┴────────┘

───────────────────────────────────────────────────────────────
RISK REGISTER CHANGE LOG
───────────────────────────────────────────────────────────────

┌────────────┬────────────────────────────────────────┬───────┐
│ Date       │ Change Description                     │ By    │
├────────────┼────────────────────────────────────────┼───────┤
│            │                                        │       │
├────────────┼────────────────────────────────────────┼───────┤
│            │                                        │       │
└────────────┴────────────────────────────────────────┴───────┘

═══════════════════════════════════════════════════════════════
```

---


## Template 4: AI Bias Assessment Checklist


### Purpose

Focused assessment of bias and fairness risks in an AI system.


### When to Use

- Part of broader risk assessment
- Pre-deployment fairness review
- Periodic bias audits

*Example:* Hiring AI undergoing pre-deployment bias assessment completes comprehensive checklist revealing: Context Assessment identifies employment decisions as critical harm domain subject to Title VII/EEOC regulations affecting age, gender, race protected groups historically disadvantaged in tech hiring; Data Assessment shows training data 23% women vs 28% applicant pool, 12% Black vs 18% applicant pool indicating historical bias; Feature Assessment identifies graduation year (0.87 correlation with age), university name (0.43 correlation with socioeconomic status) as problematic proxies; Outcome Testing reveals age discrimination (58% parity ratio failing four-fifths rule), racial bias (76% ratio for Black applicants), gender disparity (80% at threshold); Findings assign High Bias Risk Level requiring remediation before deployment with recommended actions to remove age proxies, apply fairness constraints, implement human review for all rejections, establish monthly demographic parity monitoring.


### Template

```
═══════════════════════════════════════════════════════════════
AI BIAS ASSESSMENT CHECKLIST
═══════════════════════════════════════════════════════════════

System: _____________________________________________________
Assessment Date: ____________________________________________
Assessor(s): ________________________________________________

───────────────────────────────────────────────────────────────
SECTION 1: CONTEXT ASSESSMENT
───────────────────────────────────────────────────────────────

1.1 Domain and Use Case
What decisions does this system inform?
______________________________________________________________

Could biased decisions in this domain cause significant harm?
[ ]Yes - Critical [ ]Yes - Moderate [ ]Minimal [ ]No

Relevant anti-discrimination laws/regulations:
______________________________________________________________

1.2 Protected Groups Analysis
Which protected characteristics could be affected?

[ ] Age
[ ] Gender/Sex
[ ] Race/Ethnicity
[ ] Disability
[ ] Religion
[ ] National Origin
[ ] Sexual Orientation
[ ] Veteran Status
[ ] Pregnancy
[ ] Genetic Information
[ ] Other: _____________________

Are any groups historically disadvantaged in this domain?
______________________________________________________________

───────────────────────────────────────────────────────────────
SECTION 2: DATA ASSESSMENT
───────────────────────────────────────────────────────────────

2.1 Training Data Review
Data source(s): ______________________________________________

Time period covered: _________________________________________

Geographic scope: ____________________________________________

2.2 Representation Analysis
Is demographic breakdown of training data known? [ ]Yes [ ]No

If yes, complete:
┌────────────────────┬────────────────┬────────────────────────┐
│ Group              │ % in Training  │ % in Target Population │
├────────────────────┼────────────────┼────────────────────────┤
│                    │                │                        │
├────────────────────┼────────────────┼────────────────────────┤
│                    │                │                        │
├────────────────────┼────────────────┼────────────────────────┤
│                    │                │                        │
└────────────────────┴────────────────┴────────────────────────┘

Underrepresented groups identified: ___________________________

2.3 Historical Bias
Could historical discrimination be reflected in data?
[ ]Yes - Likely [ ]Yes - Possible [ ]Unlikely [ ]No

Examples of potential historical bias:
______________________________________________________________

2.4 Label Quality
Who/what created the labels? __________________________________
Could labeling reflect human bias? [ ]Yes [ ]Possibly [ ]No

───────────────────────────────────────────────────────────────
SECTION 3: FEATURE ASSESSMENT
───────────────────────────────────────────────────────────────

3.1 Protected Characteristics as Features
Are protected characteristics used as model inputs?
[ ]Yes - directly  [ ]Yes - derived  [ ]No

If yes, justification: _______________________________________

3.2 Proxy Variable Analysis
Features that may proxy for protected characteristics:

┌────────────────────┬───────────────────────────────────────┐
│ Feature            │ May Proxy For                         │
├────────────────────┼───────────────────────────────────────┤
│ Zip code           │ Race, income, etc.                    │
├────────────────────┼───────────────────────────────────────┤
│                    │                                       │
├────────────────────┼───────────────────────────────────────┤
│                    │                                       │
├────────────────────┼───────────────────────────────────────┤
│                    │                                       │
└────────────────────┴───────────────────────────────────────┘

3.3 Feature Relevance
Are all features demonstrably relevant to legitimate purpose?
[ ]Yes - all validated [ ]Mostly [ ]Some unvalidated

Features requiring relevance review:
______________________________________________________________

───────────────────────────────────────────────────────────────
SECTION 4: OUTCOME TESTING
───────────────────────────────────────────────────────────────

4.1 Testing Methodology
Test data source: ____________________________________________
Sample size: _________________________________________________
Demographic labels available: [ ]Yes [ ]Partial [ ]No

4.2 Disparate Impact Analysis (if applicable)
Use 80% (4/5) rule as threshold

┌────────────────────┬────────────────┬────────────────┬──────┐
│ Group              │ Selection Rate │ vs. Highest    │ Pass │
├────────────────────┼────────────────┼────────────────┼──────┤
│                    │                │     %          │ Y/N  │
├────────────────────┼────────────────┼────────────────┼──────┤
│                    │                │     %          │ Y/N  │
├────────────────────┼────────────────┼────────────────┼──────┤
│                    │                │     %          │ Y/N  │
├────────────────────┼────────────────┼────────────────┼──────┤
│                    │                │     %          │ Y/N  │
└────────────────────┴────────────────┴────────────────┴──────┘

4.3 Error Rate Analysis
Are error rates (false positive/false negative) similar
across groups? [ ]Yes [ ]No [ ]Unable to test

If no, describe disparities:
______________________________________________________________

4.4 Other Fairness Metrics Tested
[ ] Demographic parity
[ ] Equal opportunity
[ ] Predictive parity
[ ] Calibration
[ ] Individual fairness
[ ] Other: ___________________

Results summary:
______________________________________________________________

───────────────────────────────────────────────────────────────
SECTION 5: FINDINGS AND RECOMMENDATIONS
───────────────────────────────────────────────────────────────

5.1 Key Findings
______________________________________________________________
______________________________________________________________
______________________________________________________________

5.2 Bias Risk Level
[ ] High - Significant disparities identified
[ ] Medium - Some concerns requiring attention
[ ] Low - No significant issues found

5.3 Recommended Actions
┌────────────────────────────────────────┬──────────┬─────────┐
│ Action                                 │ Priority │ Owner   │
├────────────────────────────────────────┼──────────┼─────────┤
│                                        │          │         │
├────────────────────────────────────────┼──────────┼─────────┤
│                                        │          │         │
├────────────────────────────────────────┼──────────┼─────────┤
│                                        │          │         │
└────────────────────────────────────────┴──────────┴─────────┘

5.4 Monitoring Recommendations
______________________________________________________________
______________________________________________________________

───────────────────────────────────────────────────────────────
APPROVAL
───────────────────────────────────────────────────────────────

Assessor Signature: __________________ Date: __________

Reviewer Signature: __________________ Date: __________

Deployment Decision:
[ ] Approved for deployment
[ ] Approved with conditions: ________________________________
[ ] Remediation required before deployment
[ ] Not approved

═══════════════════════════════════════════════════════════════
```

---


## Template 5: AI Incident Report


### Purpose

Document and learn from AI-related incidents.


### When to Use

- When an AI system causes harm or near-miss
- When bias or errors are discovered in production
- When complaints are received about AI decisions

*Example:* Credit scoring AI incident affecting 1,247 loan applicants over 3-month period discovered through external fair lending audit revealing discriminatory outcomes disproportionately denying qualified minority applicants. Incident Report documents: Impact Assessment (1,247 individuals affected, estimated $3.7M in denied credit access, reputational harm to organization); Immediate Response (system suspended pending investigation, affected applicants notified via letter offering reconsideration, CFPB proactively informed); Root Cause Analysis (technical root cause: training data reflected historical lending bias from 2015-2018 when discriminatory manual practices were common, process root cause: fairness testing conducted but used inadequate sample size failing to detect disparities, contributing factors: no ongoing monitoring post-deployment, rapid growth in minority applicant pool changing demographics from training data); Corrective Actions (retrain model with bias-aware sampling and fairness constraints by Data Science team due 30 days, implement automated monthly fairness monitoring with <85% parity triggering alerts by Analytics team due 45 days, enhance pre-deployment testing requiring minimum sample sizes by Governance team due 60 days, establish quarterly independent bias audits by External Auditor ongoing); Lessons Learned (static pre-deployment testing insufficient for evolving applicant demographics, one-time assessment inadequate without ongoing monitoring, all other credit-related AI systems require immediate bias audit triggering organization-wide review).


### Template

```
═══════════════════════════════════════════════════════════════
AI INCIDENT REPORT
═══════════════════════════════════════════════════════════════

INCIDENT IDENTIFICATION
Report Number: _______________________________________________
Report Date: _________________________________________________
Reporter Name/Role: __________________________________________
Incident Date: _______________________________________________

───────────────────────────────────────────────────────────────
SECTION 1: SYSTEM INFORMATION
───────────────────────────────────────────────────────────────

System Name: _________________________________________________
System Owner: ________________________________________________
System Version: ______________________________________________

───────────────────────────────────────────────────────────────
SECTION 2: INCIDENT DESCRIPTION
───────────────────────────────────────────────────────────────

2.1 Incident Summary (what happened):
______________________________________________________________
______________________________________________________________
______________________________________________________________

2.2 How was the incident discovered?
[ ] User complaint
[ ] Internal monitoring
[ ] External report
[ ] Audit finding
[ ] Other: ___________________________________________________

2.3 Incident Category
[ ] Discriminatory outcome
[ ] Incorrect decision
[ ] Privacy breach
[ ] System failure
[ ] Security incident
[ ] Safety issue
[ ] Other: ___________________________________________________

───────────────────────────────────────────────────────────────
SECTION 3: IMPACT ASSESSMENT
───────────────────────────────────────────────────────────────

3.1 Who was affected?
Number of individuals: _______________________________________
Groups particularly affected: ________________________________

3.2 What was the harm?
[ ] Financial loss: estimated $ ______________________________
[ ] Physical harm: describe __________________________________
[ ] Psychological harm: describe _____________________________
[ ] Privacy violation: describe ______________________________
[ ] Reputational harm: describe ______________________________
[ ] Other: ___________________________________________________

3.3 Severity Assessment
[ ] Critical - Significant harm to multiple individuals
[ ] High - Significant harm to individual(s) or moderate
    harm to many
[ ] Medium - Moderate harm to individual(s)
[ ] Low - Minor harm or near-miss

───────────────────────────────────────────────────────────────
SECTION 4: IMMEDIATE RESPONSE
───────────────────────────────────────────────────────────────

4.1 Immediate actions taken:
______________________________________________________________
______________________________________________________________

4.2 Was the system:
[ ] Continued operation
[ ] Modified operation
[ ] Suspended
[ ] Decommissioned

4.3 Were affected parties notified? [ ]Yes [ ]No [ ]N/A
If yes, when and how: ________________________________________

───────────────────────────────────────────────────────────────
SECTION 5: ROOT CAUSE ANALYSIS
───────────────────────────────────────────────────────────────

5.1 Technical root cause:
______________________________________________________________
______________________________________________________________

5.2 Process root cause (why wasn't this caught earlier?):
______________________________________________________________
______________________________________________________________

5.3 Contributing factors:
______________________________________________________________
______________________________________________________________

───────────────────────────────────────────────────────────────
SECTION 6: CORRECTIVE ACTIONS
───────────────────────────────────────────────────────────────

┌────────────────────────────────────────┬──────────┬─────────┐
│ Action                                 │ Owner    │ Due     │
├────────────────────────────────────────┼──────────┼─────────┤
│                                        │          │         │
├────────────────────────────────────────┼──────────┼─────────┤
│                                        │          │         │
├────────────────────────────────────────┼──────────┼─────────┤
│                                        │          │         │
├────────────────────────────────────────┼──────────┼─────────┤
│                                        │          │         │
└────────────────────────────────────────┴──────────┴─────────┘

───────────────────────────────────────────────────────────────
SECTION 7: LESSONS LEARNED
───────────────────────────────────────────────────────────────

What should we do differently?
______________________________________________________________
______________________________________________________________

What changes to prevent recurrence?
______________________________________________________________
______________________________________________________________

Should other systems be reviewed? [ ]Yes [ ]No
If yes, which: _______________________________________________

───────────────────────────────────────────────────────────────
APPROVALS AND CLOSURE
───────────────────────────────────────────────────────────────

Report completed by: __________________ Date: __________

Reviewed by: _________________________ Date: __________

Closed by: ___________________________ Date: __________

Closure verification:
[ ] All corrective actions completed
[ ] Effectiveness verified
[ ] Documentation updated
[ ] Lessons learned shared

═══════════════════════════════════════════════════════════════
```

---


## Using These Templates


### Customization Tips

1. **Adapt to your context:** These are starting points. Modify terminology, categories, and depth to fit your organization.

*Example:* Financial services organization adapts templates replacing generic "protected characteristics" with specific categories relevant to lending (race, national origin, age, gender, marital status matching ECOA/Regulation B requirements), adds bank-specific risk categories (model risk management, BSA/AML considerations), adjusts approval levels to match existing credit policy governance (loan committee approval for high-risk, CCO approval for critical risk), integrates regulatory reporting requirements (CFPB, OCC, Fed documentation standards).

2. **Integrate with existing processes:** Connect templates to your existing risk management, project management, and documentation systems.

*Example:* Organization integrates risk screening into project intake process (new AI project proposal requires completed screening form before project approval), links standard risk assessment to development milestones (assessment completion required gate before UAT phase), incorporates risk register into quarterly enterprise risk reporting (AI risks roll up to enterprise risk dashboard presented to board), connects incident reports to existing operational incident management system (AI incidents trigger same escalation, notification, and review processes as other operational incidents).

3. **Version control:** Maintain template versions and document changes.

*Example:* Templates versioned as Template-Risk-Screening-v2.1.docx with change log documenting: v1.0 (initial release March 2023), v1.1 (added EU AI Act regulatory question June 2023), v2.0 (restructured scoring adding vulnerable population section December 2023), v2.1 (clarified financial harm threshold to $1000 March 2024), ensuring teams use current version while maintaining historical assessments using version they were completed with.

4. **Training:** Ensure users understand how to complete templates correctly.

*Example:* Organization creates training program including: 2-hour template completion workshop with hands-on practice, reference guide with completed examples for each template, office hours twice monthly for questions, certification requirement (complete 2 practice assessments reviewed by experienced assessor before authorized to conduct independent assessments), refresher training annually covering template updates and lessons learned.


### Implementation Suggestions

**Start simple:** Begin with the screening template. Add complexity as maturity grows.

*Example:* Year 1: Implement only initial risk screening, completing for all 23 discovered AI systems, establishing basic risk classification. Year 2: Add standard risk assessment for medium/high risk systems (11 systems requiring full assessment), maintain screening for new systems. Year 3: Implement risk register for enterprise-level tracking and trending, add bias assessment checklist for fairness-sensitive systems. Year 4: Add incident reporting template after governance maturity sufficient to handle systematic incident learning. Progressive implementation prevents overwhelming teams while building capability and culture.

**Create examples:** Complete templates for a few real systems to create reference examples.

*Example:* AI Governance team completes templates for 3 representative systems: low-risk spam filter (abbreviated screening showing 3 Yes responses, brief documentation), medium-risk customer churn model (complete standard risk assessment demonstrating proper completion of all sections, approved example teams can reference), high-risk hiring AI (comprehensive assessment with bias checklist showing proper fairness testing documentation). Examples answer common questions ("How detailed should risk descriptions be?" "What constitutes adequate mitigation?" "How specific must monitoring thresholds be?") through demonstration rather than abstract instruction.

**Collect feedback:** Ask users what works and what doesn't. Iterate.

*Example:* After 6 months template use, survey users identifying: Section 2.5 Reliability Risks confusing ("accuracy concerns" overlaps with "performance degradation"), mitigation plan table needs priority column (all mitigations listed but unclear which to address first), monitoring section needs guidance on appropriate measurement frequency for different metric types. V2.0 update addresses feedback: splits reliability into accuracy/drift/availability subsections, adds priority column to mitigation table, includes monitoring frequency guidance table (technical metrics weekly, fairness metrics monthly, comprehensive review quarterly).

**Automate where possible:** Move templates to digital forms or GRC systems for better tracking.

*Example:* Organization migrates from Word/Excel templates to integrated GRC platform enabling: web forms for risk screening and assessment with conditional logic (high-risk classification auto-triggers comprehensive assessment requirement, bias category automatically expands bias assessment section), automated workflow routing (completed assessments route to appropriate approver based on risk level, overdue mitigations trigger escalation emails), centralized risk register auto-populated from individual assessments (no manual consolidation), dashboard analytics (risk trends, time-to-completion metrics, mitigation effectiveness), audit trail (who completed what when, approval history, document versions). Automation reduces administrative burden, improves compliance, enables analytics impossible with static documents.

---


## Conclusion

Templates are tools—they make AI risk assessment faster, more consistent, and more complete. But they're not magic. A template can't substitute for genuine analysis and judgment.

Use these templates to:
- Ensure you cover all important areas (systematic checklists prevent oversight)
- Create consistent documentation (enables comparison and trending)
- Save time on format and structure (focus energy on analysis not formatting)
- Focus energy on analysis and decisions (template handles "what to assess," you handle "how to assess it")

The best template is one that gets used. Start with what works, improve over time, and build a toolkit that serves your organization's needs.

A comprehensive template that's too burdensome and therefore skipped creates zero value. A simpler template that teams actually complete, finding it genuinely helpful, creates real value. Don't let perfect be the enemy of good—implement templates that fit your current maturity level, learn from experience, and evolve toward more comprehensive approaches as capability and culture develop.

Templates make governance operational. They're the bridge between abstract principles ("assess AI risks") and concrete practice ("here's how to assess AI risks systematically"). Used well, they enable scaling governance across organizations, creating consistency while allowing appropriate judgment. Used poorly, they become checkbox exercises creating documentation burden without genuine risk management benefit.

The choice is yours. Use these templates as starting points, adapt them to your context, train your teams, collect feedback, iterate based on experience, and build a practical toolkit enabling your organization to assess and manage AI risks effectively. The templates are ready—the real work is making them work for you.

---


## Sources and Further Reading

1. **NIST AI RMF** - Framework these templates align with. Available at: nist.gov/itl/ai-risk-management-framework

2. **ISO 31000** - Risk management standard informing template structure. Available at: iso.org

3. **EU AI Act** - Requirements informing high-risk assessments. Available at: eur-lex.europa.eu

4. **Canada Algorithmic Impact Assessment Tool** - Government template. Available at: canada.ca

5. **OECD** - AI risk assessment resources. Available at: oecd.ai

6. **NYC DCWP** - Bias audit requirements and guidance. Available at: nyc.gov

7. **Partnership on AI** - AI incident database and reporting frameworks. Available at: partnershiponai.org

8. **Singapore PDPC** - ISAGO self-assessment tools and guidance. Available at: pdpc.gov.sg

9. **ICO (UK)** - AI and data protection risk toolkit. Available at: ico.org.uk

10. **BSI** - ISO 31000 practical guidance and tools. Available at: bsigroup.com

11. **NIST Special Publication 800-53** - Security and privacy control templates adaptable for AI. Available at: nist.gov

12. **FAIR Institute** - Quantitative risk assessment methodologies. Available at: fairinstitute.org

---

*This article is part of the AI Governance Implementation Program. For the complete curriculum, visit suniliyer.ca or the AIDefence YouTube channel.*

**Next Article:** Article 76: Continuing the AI risk and principles curriculum (Publishing: October 31, 2025)
