---
title: EU AI Act Enforcement - Penalties and Compliance Timelines
slug: eu-ai-act-enforcement-penalties-and-compliance-timelines
path: responsibility
publishDate: 2025-08-29
tldr: EU AI Act establishes three-tier administrative fine structure exceeding GDPR penalties - Tier 1 up to €35 million or 7% global annual turnover for most serious prohibited AI practice violations (Article 5: social scoring, subliminal manipulation, real-time public biometric ID, workplace/school emotion recognition) signaling EU seriousness about certain AI harms exceeding GDPR 4% maximum, Tier 2 up to €15 million or 3% global turnover for high-risk AI requirement non-compliance (Articles 9-15: risk management, data governance, documentation, logging, transparency, human oversight, accuracy/robustness/security), GPAI model obligation violations, notified body violations conducting third-party conformity assessments, Tier 3 up to €7.5 million or 1.5% global turnover for providing incorrect/incomplete/misleading information to authorities or notified bodies. SME/startup special rules apply lower caps (absolute euro or percentage whichever lower), proportionality requirement (effective/proportionate/dissuasive considering company size/resources), specific startup viability considerations when authorities determine fines calculated considering nine factors - nature/gravity/duration, intentional or negligent character, harm mitigation actions taken, degree of responsibility given technical measures, previous violations by operator, cooperation degree with authorities, awareness manner (self-reporting helps), financial benefits gained or losses avoided, violation scale (people affected). National market surveillance authorities designated by each EU member state supervise AI systems, investigate complaints/potential violations, conduct market surveillance, issue corrective orders, impose fines while EU AI Office established for GPAI model direct oversight, national authority coordination, interpretation guidance and codes of practice issuance, cross-border systemic risk monitoring with powers including GPAI provider information requests, evaluation/testing, remedial measures, fine imposition. Phased implementation timeline Phase 0 August 1 2024 entry into force beginning preparation clock, Phase 1 February 2 2025 (6 months) prohibited practices enforceable requiring immediate cessation of social scoring/subliminal manipulation/workplace emotion recognition, Phase 2 August 2 2025 (12 months) GPAI obligations applicable with AI Office operational/codes of practice ready/national authorities designated requiring foundation model provider documentation/training data summaries/copyright policies/systemic-risk additional requirements, Phase 3 August 2 2026 (24 months) full high-risk requirements applicable plus limited-risk transparency obligations with full enforcement requiring all seven high-risk requirements met, conformity assessment complete, CE marking/EU database registration, deployer obligations effective, Phase 4 August 2 2027 (36 months) extended deadline for certain Annex I safety component products (vehicles, civil aviation, railways, medical devices, in vitro diagnostics) providing additional transition time. Enforcement authorities exercise investigation powers (information requests, AI system access for testing, documentation/record inspection, on-site inspections, member state assistance), corrective powers (corrective action orders, market withdrawal orders, non-compliant system recall, market placement prohibition, availability restrictions), enforcement actions (formal warnings, compliance deadlines, violation fines, non-compliance decision publication).
relatedConcepts:
  - eu-ai-act-enforcement
  - administrative-fines
  - three-tier-penalty-structure
  - tier-1-prohibited-violations
  - €35-million-7-percent-penalty
  - tier-2-high-risk-violations
  - €15-million-3-percent-penalty
  - tier-3-information-violations
  - €7.5-million-1.5-percent-penalty
  - sme-startup-special-rules
  - proportionality-requirement
  - startup-viability-consideration
  - fine-calculation-factors
  - nature-gravity-duration
  - intentional-negligent
  - harm-mitigation-actions
  - previous-violations
  - cooperation-degree
  - self-reporting-benefit
  - financial-benefits-gained
  - violation-scale
  - national-market-surveillance
  - national-competent-authorities
  - market-supervision
  - complaint-investigation
  - corrective-orders
  - fine-imposition
  - eu-ai-office
  - gpai-oversight
  - national-coordination
  - interpretation-guidance
  - codes-of-practice
  - systemic-risk-monitoring
  - ai-office-powers
  - information-requests
  - evaluation-testing
  - remedial-measures
  - phased-implementation
  - phase-0-entry-force
  - phase-1-prohibited-practices
  - february-2-2025
  - phase-2-gpai-rules
  - august-2-2025
  - phase-3-full-application
  - august-2-2026
  - phase-4-extended-deadline
  - august-2-2027
  - annex-i-safety-components
  - investigation-powers
  - information-request-power
  - system-access-power
  - inspection-power
  - corrective-powers
  - withdrawal-order
  - recall-order
  - prohibition-order
  - enforcement-actions
  - formal-warnings
  - compliance-deadlines
  - publication-decisions
examples:
  - ai-regulatory-compliance-examples
  - ai-governance-use-cases
templates:
  - ai-regulatory-readiness-assessment
  - ai-governance-framework-builder
crossPathRefs:
  - path: responsibility
    articles:
      - the-eu-ai-act-europes-landmark-regulation-explained
      - eu-ai-act-risk-classification-prohibited-high-risk-and-beyond
      - high-risk-ai-systems-the-complete-requirements-checklist
      - foundation-model-obligations-what-the-eu-ai-act-requires
  - path: risk
    articles:
      - algorithmic-bias-how-ai-discriminates-and-why
      - the-black-box-problem-why-ai-explainability-matters
tags:
  - eu-ai-act
  - enforcement
  - penalties
  - administrative-fines
  - compliance-timeline
  - national-authorities
  - eu-ai-office
  - phased-implementation
  - prohibited-practices
  - compliance
category: Legal Frameworks
image: eu-ai-act-enforcement-penalties-and-compliance-timelines.jpg
imageAlt: EU AI Act enforcement framework showing three-tier penalty structure (7%/3%/1.5% global revenue), phased timeline from 2024-2027, national authorities and EU AI Office powers, investigation/corrective/enforcement actions
author: Sunil Iyer
readingTime: 15
seoTitle: EU AI Act Enforcement - Penalties, Fines & Compliance Timeline Explained
seoDescription: EU AI Act enforcement - three-tier penalties (€35M/7% prohibited, €15M/3% high-risk, €7.5M/1.5% information), national authorities and AI Office powers, phased timeline (Feb 2025 prohibited, Aug 2025 GPAI, Aug 2026 high-risk, Aug 2027 extended), SME rules, investigation/corrective/enforcement actions.
---

## Summary

EU AI Act establishes robust enforcement framework with three-tier administrative fine structure designed to have board-level attention reaching significantly higher than GDPR maximum penalties signaling European Union seriousness about AI governance. Tier 1 penalties up to €35 million or 7% global annual turnover (whichever higher) apply to most serious prohibited AI practice violations under Article 5 including deploying banned systems like social scoring evaluating trustworthiness based on social behavior to determine promotions/raises, subliminal manipulation techniques, real-time public biometric identification for law enforcement beyond narrow exceptions, workplace/school emotion recognition creating coercive monitoring, biometric categorization by sensitive characteristics, facial database untargeted scraping—7% penalty exceeds GDPR 4% maximum demonstrating EU prioritization of fundamental rights protection against certain AI harms. Tier 2 penalties up to €15 million or 3% global turnover apply to high-risk AI requirement non-compliance (Articles 9-15 covering risk management system, data quality/governance, technical documentation, automatic logging, transparency/deployer information, human oversight, accuracy/robustness/cybersecurity), GPAI general-purpose AI model obligation violations (foundation model documentation, downstream provider information, copyright compliance, training data summary, systemic-risk additional requirements), notified body violations by third-party organizations conducting conformity assessments with example violations including selling hiring AI without proper documentation/risk management/conformity assessment. Tier 3 penalties up to €7.5 million or 1.5% global turnover apply to providing incorrect, incomplete, or misleading information to authorities or notified bodies with example including claiming AI system meets certain accuracy levels in conformity declaration when testing reveals significantly exaggerated claims.

SME and startup special rules recognize disproportionate fine impact: lower caps apply using lower of absolute euro amount or revenue percentage, proportionality requirement ensures fines effective/proportionate/dissuasive while considering company size/resources, specific startup considerations require authorities evaluating how penalties affect new business viability. Fine calculation considers nine factors: (1) nature, gravity, and duration of violation, (2) intentional or negligent character of infringement, (3) actions taken to mitigate harm suffered by affected persons, (4) degree of responsibility given technical and organizational measures in place, (5) previous violations by same operator establishing pattern, (6) degree of cooperation with authorities during investigation, (7) manner in which authorities became aware with self-reporting helping disposition, (8) financial benefits gained or losses avoided due to violation providing economic deterrence, (9) scale of violation measured by how many people affected assessing societal impact.

Enforcement operates at national and EU-wide levels: national market surveillance authorities designated by each EU member state supervise AI systems in markets, investigate complaints and potential violations, conduct market surveillance activities, issue corrective orders to fix problems, impose fines for violations creating multi-authority environment where selling AI across Europe may involve multiple national authority dealings. EU AI Office established under AI Act has special GPAI model oversight responsibilities directly supervising foundation model providers, coordinating national authorities working together, issuing interpretation guidance and codes of practice development, monitoring systemic risks crossing borders with powers including requesting information from GPAI providers, conducting evaluations and testing of models, requesting remedial measures for identified issues, imposing fines on GPAI model providers for non-compliance. Notified bodies serve as third-party organizations authorized by EU member states to verify AI systems meet requirements conducting conformity assessments like vehicle inspection stations except for AI systems.

Phased implementation timeline manages transition giving organizations preparation time: Phase 0 entry into force August 1 2024 officially adopts law starting clock with organizations beginning preparation, Phase 1 prohibited practices February 2 2025 (6 months after entry) makes all prohibited AI practices illegal requiring cessation of social scoring systems, subliminal manipulation, workplace/school emotion recognition, sensitive biometric categorization, untargeted facial scraping, Phase 2 GPAI rules and governance August 2 2025 (12 months) makes GPAI model obligations applicable, EU AI Office fully operational, codes of practice ready, national competent authorities designated requiring foundation model providers completing technical documentation, publishing training data summaries, establishing copyright compliance policies with systemic-risk providers facing model evaluations/risk mitigation/incident reporting/cybersecurity requirements, Phase 3 full application August 2 2026 (24 months) applies most high-risk AI requirements and limited-risk transparency obligations beginning full enforcement requiring high-risk AI meeting all seven requirements (risk management, data governance, documentation, logging, transparency, human oversight, accuracy/robustness/security), completing conformity assessment, obtaining CE marking and EU database registration, deployers meeting obligations, Phase 4 extended deadline August 2 2027 (36 months) for high-risk AI systems as safety components of certain EU product legislation covered products (vehicles, civil aviation, railways, medical devices, in vitro diagnostic devices) providing additional 12-month transition time recognizing integration complexity.

National competent authorities exercise significant enforcement powers across three categories: investigation powers including requesting information from providers and deployers, accessing AI systems for testing and evaluation, inspecting documentation and records, conducting on-site inspections of facilities, requesting assistance from other member states for cross-border coordination; corrective powers including ordering corrective actions to fix identified problems, ordering withdrawal from market of non-compliant systems, ordering recall of systems already deployed, prohibiting placement of non-compliant systems on market, imposing restrictions on making systems available to users; enforcement actions including issuing formal warnings to organizations, setting deadlines for achieving compliance, imposing fines for violations based on tier structure, publishing decisions on non-compliance creating reputational consequences. Three enforcement scenarios illustrate practical application: Scenario 1 undocumented high-risk system where German software company sells resume-screening AI without proper documentation/conformity assessment, job applicant files complaint after unexplained rejection, authority investigation finds inadequate documentation and no conformity evidence, outcome orders market withdrawal, 90-day conformity assessment completion, €8 million fine (3% revenue); Scenario 2 banned practice where employer uses AI scoring employees based on social media activity and off-work behavior, employee reports practice to authorities, investigation confirms social scoring prohibited practice, outcome requires immediate system cessation, collected score deletion, €25 million fine (7% revenue); Scenario 3 systemic risk failure where major foundation model exploited for sophisticated phishing email generation causing €50 million fraud across Europe, multiple member states report AI-generated fraud surge, EU AI Office investigation finds failed adversarial testing and no incident response plan, outcome orders 30-day enhanced cybersecurity, abuse detection system implementation, quarterly security audits mandate, €100 million fine.

Preparation actions phased across timeline: immediate actions (now through February 2025) audit for prohibited practices identifying banned AI use, inventory AI systems documenting all provided/deployed, classify systems determining risk level for each, designate responsibility for organizational AI governance; short-term actions (by August 2025) achieve GPAI compliance if applicable completing documentation requirements, begin high-risk preparation building compliance infrastructure, establish policies creating AI governance procedures, train staff ensuring relevant employee understanding; medium-term actions (by August 2026) complete high-risk compliance meeting all requirements, conduct conformity assessment self or third-party as required, register systems entering high-risk in EU database, implement monitoring establishing post-market surveillance; ongoing actions monitor for guidance following AI Office publications/codes of practice, update systems maintaining compliance as changes occur, report incidents as required for serious issues, cooperate with authorities responding promptly to inquiries. Key enforcement risk factors include high-risk situations (operating multiple EU member states, handling high-risk AI in sensitive sectors like hiring/credit/healthcare, high-volume consumer-facing AI applications, history of privacy/consumer protection violations, operating GPAI models with wide distribution), warning signs (incomplete documentation, no designated AI governance responsibility, lack of conformity assessment, no human oversight mechanisms, customer/employee complaints about AI decisions). EU AI Act enforcement framework transforms AI governance requiring organizations treating seriously not as mere regulatory management but fundamental operational transformation with key dates February 2025 prohibited practice cessation, August 2025 GPAI rules application, August 2026 full high-risk requirements application where organizations starting now positioned for compliance while waiting risks enforcement action, reputational damage, significant financial penalties.

## Key Learning Objectives

After reading this article, you will be able to:

1. **Understand three-tier penalty structure** - €35M/7% prohibited, €15M/3% high-risk/GPAI, €7.5M/1.5% information violations exceeding GDPR
2. **Apply SME/startup special rules** - Lower caps, proportionality requirement, viability considerations in fine calculation
3. **Calculate fine factors** - Nine consideration factors from nature/gravity through violation scale
4. **Navigate enforcement authorities** - National market surveillance authorities vs EU AI Office responsibilities and powers
5. **Execute phased timeline** - Phase 0 entry (Aug 2024) through Phase 4 extended deadline (Aug 2027)
6. **Implement Phase 1 requirements** - February 2025 prohibited practice cessation (social scoring, manipulation, emotion recognition)
7. **Meet Phase 2 obligations** - August 2025 GPAI requirements (documentation, training data, copyright, systemic-risk)
8. **Achieve Phase 3 compliance** - August 2026 high-risk requirements (seven pillars, conformity, CE marking, registration)
9. **Exercise authority powers** - Investigation powers, corrective powers, enforcement actions across scenarios
10. **Execute preparation roadmap** - Immediate/short/medium/ongoing actions from audit through monitoring

---

## The Penalty Structure: Three Tiers of Fines

The EU AI Act establishes three tiers of administrative fines based on the severity of the violation:

### Tier 1: Up to €35 Million or 7% of Global Revenue

*For the most serious violations*

This tier applies to:
- **Prohibited AI practices** (Article 5 violations)
- Deploying banned AI systems like social scoring or subliminal manipulation

*Example*: A company implements an AI system that rates employees based on their social behavior, using that score to determine promotions and raises. This violates the prohibition on social scoring and could face a Tier 1 fine.

### Tier 2: Up to €15 Million or 3% of Global Revenue

*For high-risk and GPAI violations*

This tier applies to:
- Non-compliance with **high-risk AI requirements** (Articles 9-15)
- Non-compliance with **GPAI model obligations**
- Violations by **notified bodies** (organizations that do third-party conformity assessments)

*Example*: A company sells hiring AI in Europe without proper technical documentation, risk management, or conformity assessment. This would face a Tier 2 fine.

### Tier 3: Up to €7.5 Million or 1% of Global Revenue

*For less serious violations*

This tier applies to:
- Providing **incorrect, incomplete, or misleading information** to authorities or notified bodies

*Example*: A company claims its AI system meets certain accuracy levels in its conformity declaration, but testing reveals the claims were significantly exaggerated.

### Special Rules for SMEs and Startups

Recognizing that startups and small businesses can't absorb fines the way large corporations can, the EU AI Act includes:

- **Lower caps for SMEs**: The lower of the absolute euro amount or percentage applies
- **Proportionality requirement**: Fines must be effective, proportionate, and dissuasive—regulators should consider the company's size and resources
- **Specific startup considerations**: Authorities must consider how penalties affect the viability of new businesses

### How Fines Are Calculated

When determining fine amounts, authorities must consider:

1. **Nature, gravity, and duration** of the violation
2. **Intentional or negligent** character of the infringement
3. **Actions taken to mitigate** harm
4. **Degree of responsibility** given technical measures in place
5. **Previous violations** by the same operator
6. **Degree of cooperation** with authorities
7. **Manner in which authorities became aware** (self-reporting helps)
8. **Financial benefits gained** or losses avoided due to the violation
9. **Scale of the violation** (how many people affected?)

---

## Comparing to Other Regulations

How do EU AI Act fines stack up against other major regulations?

| Regulation | Maximum Fine | Revenue Percentage |
|------------|--------------|-------------------|
| **EU AI Act** (prohibited AI) | €35 million | 7% |
| **EU AI Act** (high-risk) | €15 million | 3% |
| **GDPR** | €20 million | 4% |
| **EU Digital Services Act** | €20 million | 6% |
| **EU Digital Markets Act** | N/A | 10% (up to 20% repeat) |

The EU AI Act's 7% penalty for prohibited AI practices exceeds GDPR's maximum of 4%. This signals how seriously the EU takes certain AI harms.

---

## Who Enforces the EU AI Act?

Enforcement happens at two levels: national and EU-wide.

### National Market Surveillance Authorities

Each EU member state must designate one or more **national competent authorities** to enforce the AI Act.

These authorities:
- **Supervise** AI systems in their markets
- **Investigate** complaints and potential violations
- **Conduct** market surveillance activities
- **Issue** corrective orders
- **Impose** fines for violations

*In practice*: If you're selling AI systems in Germany, the German national authority will oversee your compliance. If you sell across Europe, you may deal with multiple national authorities.

### The EU AI Office

Established under the AI Act, the **EU AI Office** has special responsibilities for:

- **GPAI model oversight**: Directly supervising foundation model providers
- **Coordination**: Helping national authorities work together
- **Guidance**: Issuing interpretation guidance and codes of practice
- **Systemic risk monitoring**: Watching for AI risks that cross borders

The AI Office can:
- Request information from GPAI providers
- Conduct evaluations and testing
- Request remedial measures
- Impose fines on GPAI model providers

### Notified Bodies

For certain high-risk AI systems, third-party **notified bodies** conduct conformity assessments. These are organizations authorized by EU member states to verify that AI systems meet requirements.

*Think of them like*: The vehicle inspection stations that verify cars meet safety standards—except for AI systems.

---

## The Phased Implementation Timeline

The EU AI Act doesn't apply all at once. It uses a phased approach to give organizations time to prepare:

### Phase 0: Entry Into Force (August 1, 2024)

- The law is officially adopted
- The clock starts ticking
- Organizations should begin preparation

### Phase 1: Prohibited Practices (February 2, 2025)

**6 months after entry into force**
- All prohibited AI practices become illegal
- If you're using banned AI, you must stop

**What This Means**:
If your organization uses:
- Social scoring systems → Must stop by February 2025
- Subliminal manipulation → Must stop by February 2025
- Emotion recognition in workplaces → Must stop by February 2025

### Phase 2: GPAI Rules and Governance (August 2, 2025)

**12 months after entry into force**
- GPAI model obligations become applicable
- EU AI Office becomes fully operational
- Codes of practice should be ready
- National competent authorities must be designated

**What This Means**:
If you're a foundation model provider:
- Technical documentation must be ready
- Training data summaries must be published
- Copyright compliance policies must be in place
- Systemic risk providers face additional requirements

### Phase 3: Full Application (August 2, 2026)

**24 months after entry into force**
- Most high-risk AI requirements become applicable
- Transparency obligations for limited-risk AI apply
- Full enforcement begins

**What This Means**:
If you provide or deploy high-risk AI systems:
- All seven high-risk requirements must be met
- Conformity assessment must be complete
- CE marking and EU database registration required
- Deployer obligations take effect

### Phase 4: Extended Deadline for Certain Products (August 2, 2027)

**36 months after entry into force**
- High-risk AI systems that are safety components of products covered by certain EU product legislation get additional time

**Which products**:
- Vehicles
- Civil aviation
- Railways
- Medical devices
- In vitro diagnostic devices

### Visual Timeline

```
August 2024      February 2025      August 2025      August 2026      August 2027
    │                  │                 │                │                │
    ▼                  ▼                 ▼                ▼                ▼
┌────────────────┬─────────────────┬────────────────┬────────────────┬────────────────┐
│ Entry into    │ Prohibited     │ GPAI rules    │ Full high-risk │ Extended       │
│ force         │ practices      │ apply         │ requirements   │ deadline for   │
│               │ banned         │ AI Office     │ apply          │ some products  │
│               │                │ operational   │                │                │
└────────────────┴─────────────────┴────────────────┴────────────────┴────────────────┘
```

---

## Enforcement Powers: What Can Authorities Do?

National competent authorities have significant powers:

### Investigation Powers

- **Request information** from providers and deployers
- **Access** AI systems for testing and evaluation
- **Inspect** documentation and records
- **Conduct** on-site inspections
- **Request** assistance from other member states

### Corrective Powers

- **Order** corrective actions (fix the problem)
- **Order** withdrawal from the market
- **Order** recall of non-compliant systems
- **Prohibit** placing non-compliant systems on the market
- **Impose** restrictions on making systems available

### Enforcement Actions

- **Issue** formal warnings
- **Set** deadlines for compliance
- **Impose** fines for violations
- **Publish** decisions on non-compliance

---

## What Happens in Practice: Enforcement Scenarios

### Scenario 1: The Undocumented High-Risk System

**Situation**: A software company sells resume-screening AI in Germany without proper technical documentation or conformity assessment.

**Detection**: A job applicant files a complaint with the German national authority after being rejected without explanation.

**Investigation**: The authority requests the provider's documentation. The company can't produce adequate technical documentation or evidence of conformity assessment.

**Outcome**: The authority orders the company to:
1. Withdraw the product from the German market
2. Complete proper conformity assessment within 90 days
3. Pay a fine of €8 million (3% of annual revenue)

### Scenario 2: The Banned Practice

**Situation**: An employer uses AI to score employees based on their social media activity and off-work behavior.

**Detection**: An employee reports the practice to authorities.

**Investigation**: The authority confirms the system categorizes employees based on non-work behavior and uses those scores for promotion decisions.

**Outcome**: This is a prohibited practice (social scoring). The company must:
1. Immediately cease using the system
2. Delete collected scores
3. Pay a fine of €25 million (7% of annual revenue)

### Scenario 3: The Systemic Risk Failure

**Situation**: A major foundation model is exploited to generate sophisticated phishing emails at scale, causing €50 million in fraud losses across Europe.

**Detection**: Multiple member states report surge in AI-generated fraud.

**Investigation**: The EU AI Office investigates the model provider's systemic risk mitigation measures.

**Finding**: The provider failed to implement adequate adversarial testing and had no incident response plan.

**Outcome**: The AI Office:
1. Orders enhanced cybersecurity measures within 30 days
2. Requires implementation of abuse detection systems
3. Mandates quarterly security audits
4. Imposes a €100 million fine

---

## How to Prepare for Enforcement

### Immediate Actions (Now - February 2025)

1. **Audit for prohibited practices**: Are you using any banned AI?
2. **Inventory AI systems**: Document all AI you provide or deploy
3. **Classify systems**: Determine risk level for each AI system
4. **Designate responsibility**: Who owns AI governance in your organization?

### Short-Term Actions (By August 2025)

1. **GPAI compliance** (if applicable): Complete documentation requirements
2. **Begin high-risk preparation**: Start building compliance infrastructure
3. **Establish policies**: Create AI governance policies and procedures
4. **Train staff**: Ensure relevant employees understand obligations

### Medium-Term Actions (By August 2026)

1. **Complete high-risk compliance**: All requirements met
2. **Conduct conformity assessment**: Self-assessment or third-party, as required
3. **Register systems**: Enter high-risk systems in EU database
4. **Implement monitoring**: Set up post-market surveillance

### Ongoing Actions

1. **Monitor for guidance**: Follow AI Office publications and codes of practice
2. **Update systems**: Maintain compliance as systems change
3. **Report incidents**: Report serious incidents as required
4. **Cooperate with authorities**: Respond promptly to any inquiries

---

## Key Risk Factors for Enforcement

Certain situations increase your enforcement risk:

### High-Risk Situations

- Operating in multiple EU member states
- Handling high-risk AI in sensitive sectors (hiring, credit, healthcare)
- High-volume consumer-facing AI applications
- History of privacy or consumer protection violations
- Operating GPAI models with wide distribution

### Warning Signs

- Incomplete documentation
- No designated AI governance responsibility
- Lack of conformity assessment
- No human oversight mechanisms
- Customer or employee complaints about AI decisions

---

## Conclusion

The EU AI Act's enforcement framework is designed to have teeth. Penalties that can reach 7% of global revenue get attention at the board level. The phased timeline gives organizations time to prepare—but that time is limited.

The key dates to remember:
- **February 2025**: Prohibited practices must stop
- **August 2025**: GPAI rules apply
- **August 2026**: Full high-risk requirements apply

Organizations that start now will be positioned for compliance. Those who wait risk enforcement action, reputational damage, and significant financial penalties.

The EU AI Act isn't just another regulation to manage—it's a transformation in how AI is governed. Treat it accordingly.

---

## Sources

1. European Union. "Regulation (EU) 2024/1689 of the European Parliament and of the Council (EU AI Act)." Official Journal of the European Union, Chapter XII (Penalties) and Chapter XI (Enforcement), 2024.

2. European Commission. "AI Act: Questions and Answers on Enforcement." 2024.

3. EU AI Office. "Enforcement Framework and Procedures." 2024.

4. European Data Protection Board. "GDPR Enforcement Tracker: Lessons for AI Act." Various publications, 2018-2024.

5. IAPP. "EU AI Act Enforcement Guide." International Association of Privacy Professionals, 2024.

6. CMS Law. "EU AI Act: Fines and Enforcement Comparison." 2024.

7. Future of Life Institute. "EU AI Act Timeline and Implementation Guide." 2024.

8. DLA Piper. "Comparative Analysis: EU AI Act, GDPR, DSA, and DMA Penalties." 2024.

---

*Next: Beyond Europe - Global AI Regulation Landscape*
