---
title: "ISO 31000 for AI: Applying Risk Management Principles"
slug: iso-31000-for-ai-applying-risk-management-principles
path: risk
publishDate: 2025-10-14
tldr: ISO 31000 provides universal guidelines for managing risk in any organization, applicable to any type of risk. Unlike certifiable standards like ISO 42001, ISO 31000 is a guidance document offering a reference framework that organizations adapt to their needs. The 2018 version defines eight principles of effective risk management (integrated, structured and comprehensive, customized, inclusive, dynamic, best available information, human and cultural factors, continual improvement) and distinguishes between framework (organizational arrangements) and process (risk management activities). The process follows a logical sequence—communication and consultation, scope/context/criteria definition, risk assessment (identify, analyze, evaluate), risk treatment, and monitoring/review—all supported by recording and reporting. For AI specifically, ISO 31000 provides proven foundation for managing data risks (training bias, privacy, drift), model risks (algorithm bias, accuracy, explainability, robustness), system risks (integration, scalability, maintenance), human risks (over-reliance, skill gaps, accountability), and external risks (regulatory changes, stakeholder expectations). AI risk treatment options include avoid (don't deploy), reduce (add controls), transfer (insurance, contracts), accept (documented decision), or exploit (expand successful applications). The framework integrates naturally with NIST AI RMF (ISO 31000's process maps to MEASURE and MANAGE functions), ISO 42001 (provides risk management foundation), and EU AI Act (structures compliance for high-risk AI). The key insight is that AI risk management isn't separate from traditional risk management—it's an application of proven principles to new technology. Organizations with strong general risk management capabilities find AI risk management more natural, using ISO 31000 principles combined with AI-specific considerations from frameworks like NIST AI RMF to create rigorous yet practical approaches.
relatedConcepts:
  - iso-31000
  - risk-management-principles
  - iso-31000-2018
  - risk-management-framework
  - risk-management-process
  - eight-principles-of-risk-management
  - integrated-risk-management
  - structured-comprehensive-risk-management
  - customized-risk-management
  - inclusive-risk-management
  - dynamic-risk-management
  - best-available-information
  - human-cultural-factors
  - continual-improvement
  - leadership-commitment-risk
  - risk-integration
  - framework-design
  - risk-implementation
  - risk-evaluation
  - communication-consultation
  - scope-context-criteria
  - risk-identification
  - risk-analysis
  - risk-evaluation-iso
  - risk-treatment
  - monitoring-review
  - recording-reporting
  - avoid-risk
  - reduce-risk
  - transfer-risk
  - accept-risk
  - exploit-risk
  - data-risks-ai
  - model-risks
  - system-risks
  - human-risks-ai
  - external-risks
  - impact-on-individuals
  - reversibility
  - scale-of-impact
  - transparency-ai
  - technical-controls
  - procedural-controls
  - governance-controls
  - risk-appetite
  - risk-criteria
  - risk-register
  - qualitative-risk-analysis
  - semi-quantitative-risk-analysis
  - quantitative-risk-analysis
  - risk-identification-methods
  - brainstorming-risk
  - checklists-risk
  - scenario-analysis
  - swot-analysis
  - false-positives
  - false-negatives
  - demographic-bias
  - adversarial-attacks
  - model-drift
  - privacy-breach
  - fraud-detection-ai
  - training-data-bias
  - data-privacy-protection
  - data-drift
  - algorithm-bias-fairness
  - accuracy-reliability
  - explainability-transparency
  - robustness-security
  - integration-risks
  - scalability-performance
  - over-reliance-on-ai
  - skill-gaps-training
  - resistance-adoption
  - accountability-gaps
  - regulatory-changes
  - stakeholder-expectations
  - competitive-pressures
  - technological-changes
  - bias-mitigation-techniques
  - explainability-methods
  - security-measures-ai
  - monitoring-systems
  - human-oversight-requirements
  - approval-processes
  - incident-response-procedures
  - audit-mechanisms
  - iso-31000-nist-ai-rmf
  - iso-31000-iso-42001
  - iso-31000-eu-ai-act
  - iso-31010
  - iso-guide-73
  - enterprise-risk-management
  - risk-based-thinking
  - residual-risk
  - risk-appetite-statement
  - risk-tolerance
  - treatment-effectiveness
examples:
  - AI ethics review integrated into sprint planning, code reviews, and testing processes rather than standalone deployment gate
  - Hospital weighting patient safety heavily in AI risk assessments while marketing firm prioritizes reputational risk and consumer trust
  - AI trained on pre-pandemic data performing poorly post-pandemic due to data drift detected through continuous monitoring
  - Developer speed incentives deprioritizing risk considerations regardless of policies illustrating human and cultural factors
  - Customer service chatbot stakeholder consultation including customer support, IT security, legal, marketing, and customer representatives
  - Fraud detection AI in retail banking with comprehensive risk assessment covering false positives/negatives, demographic bias, adversarial attacks, model drift, system failure, and privacy breaches
  - Demographic bias treatment plan implementing fairness constraints, ongoing monitoring, and human review for flagged decisions
templates:
  - ISO 31000 Risk Management Framework Adaptation Template
  - AI Risk Identification Checklist (5 categories: data, model, system, human, external)
  - AI-Specific Risk Criteria Definition Template
  - Risk Assessment Process Template (identify, analyze, evaluate, treat)
  - Risk Treatment Plan Template (with actions, owners, timelines)
  - Monitoring and Review Schedule Template
  - Risk Register Template
crossPathRefs:
  - slug: nist-ai-risk-management-framework-the-complete-guide
    path: risk
    relevance: Complementary framework where ISO 31000 provides generic risk management principles while NIST AI RMF offers AI-specific considerations; ISO 31000 process maps to NIST's MEASURE and MANAGE functions
  - slug: nist-ai-rmf-core-functions-govern-map-measure-manage
    path: risk
    relevance: ISO 31000's risk assessment process (identify, analyze, evaluate, treat) directly aligns with NIST's MEASURE and MANAGE functions, providing methodological foundation for AI-specific risk management
  - slug: iso-iec-42001-ai-management-system-standard
    path: risk
    relevance: ISO 42001 AI management systems incorporate risk-based thinking consistent with ISO 31000; organizations can use ISO 31000 as foundation for ISO 42001 risk management processes
  - slug: eu-ai-act-the-complete-compliance-guide
    path: responsibility
    relevance: EU AI Act requires risk management systems for high-risk AI; ISO 31000 principles and processes can structure compliance with these requirements
  - slug: ai-risk-assessment-methodologies-and-frameworks
    path: responsibility
    relevance: ISO 31000 provides universal risk assessment methodology applicable to AI with specific adaptations for data, model, system, human, and external risk categories
tags:
  - article
  - iso-31000
  - risk-management
  - ai-governance
  - risk-framework
  - risk-assessment
  - ai-risk-management
  - iso-standards
  - enterprise-risk-management
  - risk-principles
  - risk-treatment
  - nist-ai-rmf
  - iso-42001
  - eu-ai-act
  - compliance
category: Risk Frameworks & Standards
image: article-71-iso-31000-for-ai-applying-risk-management-principles.jpg
imageAlt: ISO 31000 for AI - Applying Risk Management Principles
author: Sunil Iyer
readingTime: 16
seoTitle: ISO 31000 for AI - Applying Risk Management Principles
seoDescription: ISO 31000 provides universal guidelines for managing risk in any organization. Learn how to apply the eight principles and proven risk management process to AI systems with data, model, system, human, and external risk categories.
---



## Summary

ISO 31000:2018 provides universal guidelines for managing risk faced by organizations, applicable to any size, industry, sector, or type of risk. Unlike certifiable standards such as ISO 27001 (information security) or ISO 42001 (AI management), ISO 31000 is a guidance document, not a requirements standard—no third party will audit and certify compliance. Instead, it provides a reference framework that organizations adapt to their specific needs.

The current 2018 version emphasizes integration of risk management into all organizational activities, leadership responsibility, customization to organizational context, and continual improvement. It distinguishes between framework (the organization's arrangements for managing risk) and process (the activities of managing risk), providing comprehensive guidance for both.

The standard defines eight principles characterizing effective risk management: integrated (risk management as integral part of all activities), structured and comprehensive (systematic approach producing consistent results), customized (tailored to organization and context), inclusive (stakeholder involvement improves awareness), dynamic (anticipates and responds to change), best available information (uses historical data, expert judgment, stakeholder input while acknowledging limitations), human and cultural factors (recognizes behavior and culture influence risk management), and continual improvement (learns from experience).

The framework components include leadership and commitment (top management demonstrating commitment through policy, resources, authority assignment), integration (into governance, decision-making, processes, planning), design (understanding context, articulating commitment, defining roles, allocating resources, establishing communication), implementation (developing plans, identifying decision points, modifying processes), evaluation (measuring effectiveness through performance indicators, assessing appropriateness, identifying gaps), and improvement (adapting based on context changes, lessons learned, performance gaps).

The risk management process follows a logical sequence supported by communication and consultation throughout: scope, context, and criteria (define what you're assessing and how you'll evaluate risks); risk assessment consisting of identification (find, recognize, describe risks using methods like brainstorming, checklists, historical data analysis, expert interviews, scenario analysis), analysis (understand nature and level through likelihood and consequence assessment using qualitative, semi-quantitative, or quantitative approaches), and evaluation (compare results against criteria to determine required action); risk treatment (select and implement options: avoid, reduce, transfer, accept, or exploit); and monitoring and review (ensure continued effectiveness) with recording and reporting throughout (document activities, maintain registers, communicate appropriately).

For AI applications, organizations should consider five risk categories when identifying risks: data risks (training data quality and bias, privacy and protection, availability and access, drift and staleness), model risks (algorithm bias and fairness, accuracy and reliability, explainability and transparency, robustness and security), system risks (integration with other systems, scalability and performance, availability and reliability, maintenance and updates), human risks (over-reliance on AI, skill gaps and training needs, resistance and adoption, accountability gaps), and external risks (regulatory changes, stakeholder expectations, competitive pressures, technological changes).

AI-specific risk criteria should consider impact on individuals (fundamental rights, potential harm, vulnerable populations), reversibility (can decisions be undone, correction speed), scale (number affected, geographic scope), and transparency (can AI be explained, can decisions be understood). Treatment options employ technical controls (bias mitigation, explainability methods, security measures, monitoring systems), procedural controls (human oversight, approval processes, incident response, audit mechanisms), and governance controls (policies and standards, roles and responsibilities, accountability structures, training requirements).

ISO 31000 integrates naturally with other AI governance frameworks: with NIST AI RMF, ISO 31000's risk assessment process maps to MEASURE and MANAGE functions, providing the "how" while NIST provides AI-specific considerations; with ISO 42001, ISO 31000 serves as foundation for risk management processes required by the AI management system standard; with EU AI Act, ISO 31000 principles and processes structure compliance with risk management requirements for high-risk AI.

The key insight is that AI risk management isn't separate from traditional risk management—it's an application of proven principles to new technology. Organizations with strong general risk management capabilities will find AI risk management more natural. The approach combines ISO 31000 principles with AI-specific considerations from frameworks like NIST AI RMF, creating rigorous yet practical risk management that connects AI governance to enterprise risk management, facilitates communication between AI specialists and general risk management, and emphasizes continuous learning and adaptation.



## Key Learning Objectives

1. Understand ISO 31000 as universal risk management guidance applicable to any organization and any risk type, distinguishing it from certifiable standards
2. Master the eight principles of effective risk management and their specific application to AI systems
3. Comprehend the distinction between risk management framework (organizational arrangements) and process (risk management activities)
4. Learn the complete ISO 31000 risk management process from communication and consultation through treatment and monitoring
5. Apply systematic risk identification to five AI-specific categories: data, model, system, human, and external risks
6. Utilize qualitative, semi-quantitative, and quantitative approaches for analyzing AI risk likelihood and consequences
7. Implement appropriate risk treatment options (avoid, reduce, transfer, accept, exploit) with technical, procedural, and governance controls
8. Define AI-specific risk criteria considering impact on individuals, reversibility, scale, and transparency
9. Integrate ISO 31000 with complementary frameworks including NIST AI RMF, ISO 42001, and EU AI Act requirements
10. Establish continuous monitoring, review, recording, and reporting mechanisms for effective AI risk management



## What Is ISO 31000?


### The Standard's Purpose

ISO 31000 provides guidelines for managing risk faced by organizations. It's designed to:

- Be applicable to any organization, regardless of size, industry, or sector
- Be applicable to any type of risk, regardless of nature or cause
- Be used throughout the organization's life
- Support integration with other management activities


### Not Certifiable

Unlike ISO 27001 (information security) or ISO 42001 (AI management), ISO 31000 is not certifiable. It's a guidance document, not a requirements standard.

This means no third party will audit and certify your ISO 31000 compliance. Instead, ISO 31000 provides a reference framework that organizations adapt to their needs.

*Example:* An organization cannot claim "ISO 31000 certified" on marketing materials, but can state "risk management processes based on ISO 31000 principles," demonstrating structured approach to risk.


### The 2018 Version

The current version (ISO 31000:2018) is more concise than its 2009 predecessor. It emphasizes:
- Integration of risk management into all organizational activities
- Leadership responsibility for risk management
- Customization to organizational context
- Continual improvement

The 2018 revision removed detailed implementation guidance, focusing instead on principles and flexible framework that organizations adapt to their specific circumstances.

---


## ISO 31000 Principles

ISO 31000 defines eight principles that characterize effective risk management:


### 1. Integrated

Risk management should be an integral part of all organizational activities, not a separate exercise.

**For AI:** AI risk management shouldn't be a standalone function that reviews AI projects after they're built. It should be embedded in how AI projects are planned, developed, and operated.

*Example:* Instead of having an "AI ethics review" as a gate before deployment, build risk considerations into sprint planning, code reviews, and testing processes so developers address risks throughout development.


### 2. Structured and Comprehensive

A systematic approach produces consistent, comparable results.

**For AI:** Use the same risk assessment methodology across AI systems so you can compare risks and prioritize resources effectively.

*Example:* Create a standard AI risk assessment template used for all projects, ensuring consistent evaluation criteria (covering bias, privacy, accuracy, explainability) and documentation format, enabling comparison between chatbot project and fraud detection system risks.


### 3. Customized

The framework and process should be tailored to the organization and its context.

**For AI:** A healthcare organization's AI risk management will look different from a social media company's, even if both follow the same principles.

*Example:* A hospital might weight patient safety heavily in AI risk assessments (assigning 5x multiplier to harm severity), while a marketing firm might weight reputational risk and consumer trust more heavily, reflecting different organizational missions and stakeholder expectations.


### 4. Inclusive

Stakeholder involvement improves awareness and informed risk management.

**For AI:** Include diverse perspectives—not just data scientists, but legal, ethics, affected communities, end users.

*Example:* When assessing a hiring AI, include HR (operational needs), legal (compliance), diversity officers (equity concerns), recruiters (usability), and potentially job applicant advocates (affected party perspectives), each bringing unique risk insights.


### 5. Dynamic

Risks can emerge, change, or disappear. Risk management anticipates and responds to change.

**For AI:** AI systems change over time (retraining, data drift), and the risk landscape evolves. Risk management must be ongoing, not one-time.

*Example:* An AI trained on pre-pandemic data may perform poorly post-pandemic due to behavioral changes (remote work patterns, online shopping surge). Continuous monitoring detects this drift, triggering retraining or model revision.


### 6. Best Available Information

Risk management is informed by historical data, expert judgment, stakeholder input, and other information, while acknowledging limitations.

**For AI:** Use testing data, academic research, incident reports, and expert opinion—but recognize uncertainty, especially for novel AI applications.

*Example:* When assessing bias risk in facial recognition, use available fairness metrics (demographic parity, equalized odds) and academic studies on performance disparities, while acknowledging these metrics don't capture all aspects of fairness and may not predict real-world impacts perfectly.


### 7. Human and Cultural Factors

Human behavior and culture significantly influence risk management.

**For AI:** Technical controls alone aren't enough. Organizational culture, incentives, and human judgment all affect AI risk.

*Example:* If developers are rewarded only for speed (shipping features quickly), risk considerations will be deprioritized regardless of policies. Effective risk management requires aligning incentives with risk awareness and including risk management in performance evaluations.


### 8. Continual Improvement

Risk management improves through learning and experience.

**For AI:** Learn from incidents, near-misses, and successes. Update practices based on what works.

*Example:* After an AI bias incident (e.g., credit model disproportionately denying qualified applicants from certain demographics), analyze root causes (training data imbalance? proxy features?), implement corrective actions, and update assessment procedures to catch similar issues earlier in future projects.

---


## The ISO 31000 Framework

ISO 31000 distinguishes between framework (the organization's arrangements for risk management) and process (the activities of managing risk).


### Framework Components


#### Leadership and Commitment

Top management demonstrates commitment by:
- Defining risk management policy
- Allocating resources
- Assigning authority and responsibility
- Aligning risk management with objectives and strategy

**For AI:** Leadership must prioritize AI risk management, not just sign policies. This means budget, staffing, and decision-making authority.

*Example:* CEO assigns Chief Risk Officer accountability for AI risk governance with dedicated budget, establishes AI Risk Committee reporting to board, and requires AI risk assessment for all projects over $100K investment, demonstrating genuine commitment.


#### Integration

Risk management should be integrated into:
- Governance structures
- Decision-making
- Organizational processes
- Planning and strategy

**For AI:** AI risk considerations should be part of project approvals, budget allocations, and strategic planning—not afterthoughts.

*Example:* Product approval process includes AI risk assessment as mandatory gate (alongside business case and technical feasibility), with risk level determining approval authority (board for high-risk, VP for medium-risk, director for low-risk).


#### Design

Designing the framework includes:
- Understanding context
- Articulating risk management commitment
- Defining roles and responsibilities
- Allocating resources
- Establishing communication mechanisms

**For AI:** Design an AI risk management approach that fits your organization's structure, culture, and AI maturity.

*Example:* Startup with small team might assign AI risk ownership to CTO with support from external advisors, while enterprise might establish AI Governance Office with dedicated staff, AI Ethics Committee, and federated risk champions in each business unit.


#### Implementation

Put the framework into action through:
- Developing implementation plans
- Identifying decision points where risk should be considered
- Modifying processes to incorporate risk management

**For AI:** Roll out AI risk management practices systematically, starting with high-priority areas.

*Example:* Phased rollout starting with high-risk AI applications (those affecting individual rights or safety), then expanding to medium-risk (operational impacts), creating templates and training along the way, fully implementing across organization over 18 months.


#### Evaluation

Measure effectiveness by:
- Reviewing performance against indicators
- Assessing continued appropriateness
- Identifying gaps and improvement opportunities

**For AI:** Track metrics like: AI incidents prevented, assessment completion rates, time to identify issues.

*Example:* Quarterly metrics review tracking: 100% assessment completion for high-risk projects, average 15 days from risk identification to treatment implementation, 8 potential incidents prevented through proactive assessment, 3 false alarms (excessive caution), informing process refinement.


#### Improvement

Adapt and improve based on:
- Changes in context
- Lessons learned
- Performance gaps

**For AI:** Update AI risk practices as technology evolves, regulations change, and you learn from experience.

*Example:* After new EU AI Act requirements, update risk criteria to align with regulatory categories, add conformity assessment procedures for high-risk systems, and incorporate lessons from first year (e.g., adding explainability testing after discovering documentation gaps).

---


## The ISO 31000 Process

The process is the actual "doing" of risk management. It follows a logical sequence:

```
┌─────────────────────────────────────────────────────────┐
│                                                         │
│  ┌──────────────────┐                                  │
│  │ Communication &  │                                  │
│  │   Consultation   │                                  │
│  └────────┬─────────┘                                  │
│           │                                             │
│  ┌────────▼─────────┐                                  │
│  │ Scope, Context,  │                                  │
│  │    Criteria      │                                  │
│  └────────┬─────────┘                                  │
│           │                                             │
│  ┌────────▼─────────┐                                  │
│  │ Risk Assessment  │                                  │
│  │  ┌─────────────┐ │                                  │
│  │  │ Identify    │ │                                  │
│  │  ├─────────────┤ │                                  │
│  │  │ Analyze     │ │         ┌──────────────────┐    │
│  │  ├─────────────┤ │◄───────►│   Monitoring &   │    │
│  │  │ Evaluate    │ │         │     Review       │    │
│  │  └─────────────┘ │         └──────────────────┘    │
│  └────────┬─────────┘                                  │
│           │                                             │
│  ┌────────▼─────────┐                                  │
│  │  Risk Treatment  │                                  │
│  └──────────────────┘                                  │
│                                                         │
│  ┌──────────────────┐                                  │
│  │    Recording &   │                                  │
│  │    Reporting     │                                  │
│  └──────────────────┘                                  │
│                                                         │
└─────────────────────────────────────────────────────────┘
```


### Communication and Consultation

**Purpose:** Ensure stakeholders understand and contribute to risk management.

**Activities:**
- Identify stakeholders and their interests
- Plan communication approaches
- Gather information from stakeholders
- Share risk information appropriately

**For AI Example:** When assessing a customer service chatbot, consult with customer support leadership (operational needs and efficiency expectations), IT security (data protection concerns and system vulnerabilities), legal (liability and compliance with consumer protection laws), marketing (brand reputation and customer experience), and customer representatives (user experience and trust concerns), ensuring diverse perspectives inform risk identification.


### Scope, Context, and Criteria

**Purpose:** Define what you're assessing and how you'll evaluate risks.

**Activities:**
- Define assessment scope
- Understand external context (regulatory, social, competitive)
- Understand internal context (culture, capabilities, risk appetite)
- Define risk criteria (how you'll evaluate significance)

**For AI Example:**

**Scope:** Risk assessment for new fraud detection AI in retail banking

**External context:**
- Regulatory requirements (fair lending laws, consumer protection regulations)
- Industry standards (model risk management guidelines from banking regulators)
- Competitive pressure (other banks using AI, customer expectations for fast approvals)
- Social expectations (fairness, transparency, accountability in financial decisions)

**Internal context:**
- Existing model risk management framework from traditional credit models
- Data science team capabilities (strong in machine learning, developing fairness expertise)
- Risk appetite: "No discriminatory outcomes; acceptable 0.5% false positive rate"
- Available resources for monitoring (dedicated model validation team, real-time monitoring infrastructure)

**Risk criteria:**
- High risk: Potential regulatory violation or significant customer harm (defined as financial loss >$1000 or rights violation)
- Medium risk: Operational impact or moderate customer complaints (degraded customer experience, efficiency reduction >20%)
- Low risk: Minor efficiency impacts with no customer harm


### Risk Identification

**Purpose:** Find, recognize, and describe risks.

**Activities:**
- Identify sources of risk
- Identify events, causes, and consequences
- Generate comprehensive list of risks
- Consider both threat risks and opportunity risks

**Risk Identification Methods:**
- Brainstorming
- Checklists
- Historical data analysis
- Expert interviews
- Scenario analysis
- SWOT analysis

**For AI Example:** Fraud detection AI risks might include:

| Risk | Source | Consequence |
|------|--------|-------------|
| False positives | Model sensitivity settings too aggressive | Customer frustration, transaction delays, lost business |
| False negatives | Model misses sophisticated fraud patterns | Financial loss to bank, customer account compromise, regulatory action |
| Demographic bias | Training data bias or proxy features | Discrimination claims, regulatory action, reputational damage |
| Adversarial attacks | Sophisticated fraudsters gaming model | Model bypass, fraud increase, financial loss |
| Model drift | Changing fraud patterns over time | Degraded performance, increased false positives/negatives |
| System failure | Technical issues or integration problems | Operational disruption, manual processing fallback, delays |
| Privacy breach | Improper data handling or access | Regulatory fines, customer trust loss, reputational damage |


### Risk Analysis

**Purpose:** Understand the nature and level of risk.

**Activities:**
- Assess likelihood of each risk
- Assess consequences if risk materializes
- Consider uncertainty and sensitivity
- Consider effectiveness of existing controls
- Determine risk level

**Analysis Approaches:**

**Qualitative:** Use scales like High/Medium/Low

**Semi-quantitative:** Use numbers representing scales (1-5)

**Quantitative:** Use actual probabilities and monetary values

**For AI Example:**

| Risk | Likelihood | Consequence | Current Controls | Residual Risk |
|------|------------|-------------|------------------|---------------|
| Demographic bias | Medium | High | Bias testing planned at launch only | Medium-High |
| False positives | High | Medium | Human review thresholds at $5000 | Medium |
| Model drift | High | Medium | Quarterly retraining scheduled | Low-Medium |
| Adversarial attacks | Low | High | None implemented | Medium |


### Risk Evaluation

**Purpose:** Compare analysis results against criteria to determine required action.

**Activities:**
- Compare risk levels to defined criteria
- Prioritize risks for treatment
- Make decisions about treatment approach
- Consider risk interdependencies

**For AI Example:**

Based on criteria established earlier:

- **Demographic bias:** Medium-High risk → Exceeds tolerance (regulatory violation potential) → Treatment required before deployment
- **Adversarial attacks:** Medium risk → Close to tolerance → Treatment recommended, implement before launch
- **Model drift:** Low-Medium risk → Within tolerance but monitor closely → Accept with enhanced monitoring
- **False positives:** Medium risk → Acceptable but optimize → Reduce through model tuning


### Risk Treatment

**Purpose:** Select and implement options to address risks.

**Treatment Options:**

| Option | Description | AI Example |
|--------|-------------|------------|
| Avoid | Don't proceed with risky activity | Don't deploy high-risk AI use case without adequate controls |
| Reduce | Decrease likelihood or consequence | Add bias mitigation techniques, human oversight |
| Transfer | Shift risk to another party | Insurance, contractual liability allocation to vendor |
| Accept | Proceed knowing the risk | Deploy with documented acceptance by appropriate authority |
| Exploit | Increase exposure to opportunity | Expand successful AI application to new use cases |

**Treatment Process:**
1. Select treatment options
2. Prepare treatment plans
3. Implement plans
4. Assess residual risk
5. Document decisions

**For AI Example Treatment Plan:**

| Risk | Treatment | Actions | Owner | Timeline |
|------|-----------|---------|-------|----------|
| Demographic bias | Reduce | 1. Add fairness constraints to model training | Data Science Lead | Before deployment |
| | | 2. Implement ongoing bias monitoring dashboard | ML Operations | Deployment + ongoing |
| | | 3. Human review for all decisions flagged for bias risk | Operations Manager | Deployment + ongoing |
| Adversarial attacks | Reduce | 1. Add adversarial testing to validation process | Security Team | Before deployment |
| | | 2. Implement anomaly detection for unusual patterns | Security Team | Month 2 post-deployment |


### Monitoring and Review

**Purpose:** Ensure risk management remains effective.

**Activities:**
- Monitor risks and controls
- Review risk management process effectiveness
- Identify emerging risks
- Learn from events

**For AI Example:** Ongoing monitoring might include:
- **Weekly:** Automated performance metrics review (false positive/negative rates, demographic parity metrics)
- **Monthly:** Bias metrics dashboard review by AI Governance Committee, trend analysis
- **Quarterly:** Formal risk assessment update, model retraining evaluation, control effectiveness review
- **Annually:** Full risk management process review, framework update for regulatory changes


### Recording and Reporting

**Purpose:** Document risk management activities and communicate appropriately.

**Activities:**
- Maintain risk registers
- Document decisions and rationale
- Report to stakeholders
- Ensure traceability

**For AI Example Documentation:**
- **AI Risk Register:** Comprehensive list of identified risks, analysis, treatment status (updated monthly)
- **Risk Assessment Reports:** Detailed analysis for each major AI system (created at design, updated quarterly)
- **Treatment Plan Status Reports:** Progress on risk mitigation actions (monthly to governance committee)
- **Management Dashboard:** Real-time risk metrics and key indicators (continuous access for leadership)
- **Board Summary:** High-level risk overview, major decisions, emerging issues (quarterly)

---


## Applying ISO 31000 to AI: A Practical Framework

Here's how to adapt the generic ISO 31000 process specifically for AI risks:


### AI Risk Identification Categories

When identifying AI risks, consider these categories:

**Data Risks:**
- Training data quality and bias
- Data privacy and protection
- Data availability and access
- Data drift and staleness

**Model Risks:**
- Algorithm bias and fairness
- Accuracy and reliability
- Explainability and transparency
- Robustness and security

**System Risks:**
- Integration with other systems
- Scalability and performance
- Availability and reliability
- Maintenance and updates

**Human Risks:**
- Over-reliance on AI
- Skill gaps and training needs
- Resistance and adoption
- Accountability gaps

**External Risks:**
- Regulatory changes
- Stakeholder expectations
- Competitive pressures
- Technological changes


### AI-Specific Risk Criteria

Consider these factors when defining AI risk criteria:

**Impact on individuals:**
- Does the AI affect fundamental rights?
- Could it cause physical, psychological, or financial harm?
- Does it affect vulnerable populations?

**Reversibility:**
- Can AI decisions be undone?
- How quickly can harm be corrected?

**Scale:**
- How many people are affected?
- What's the geographic scope?

**Transparency:**
- Can the AI be explained?
- Can decisions be understood?


### AI Risk Treatment Considerations

When treating AI risks, consider:

**Technical controls:**
- Bias mitigation techniques (re-sampling, re-weighting, fairness constraints)
- Explainability methods (LIME, SHAP, attention mechanisms)
- Security measures (adversarial training, input validation, monitoring)
- Monitoring systems (performance dashboards, drift detection, anomaly detection)

**Procedural controls:**
- Human oversight requirements (human-in-the-loop, human-on-the-loop)
- Approval processes (risk-based approval authorities)
- Incident response procedures (detection, escalation, remediation)
- Audit mechanisms (internal review, external assessment)

**Governance controls:**
- Policies and standards (AI ethics policy, development standards)
- Roles and responsibilities (AI risk owner, ethics committee)
- Accountability structures (escalation paths, decision authorities)
- Training requirements (developer awareness, user training)

---


## ISO 31000 and Other Frameworks


### With NIST AI RMF

ISO 31000's risk assessment process (identify, analyze, evaluate, treat) maps well to NIST AI RMF's MEASURE and MANAGE functions. ISO 31000 provides the "how" of risk assessment while NIST AI RMF provides AI-specific considerations.

**Integration approach:** Use ISO 31000 as methodological foundation for risk management process, incorporate NIST AI RMF's detailed guidance on AI-specific risks (trustworthiness characteristics, categories, subcategories) when identifying and analyzing risks, apply ISO 31000 treatment options to NIST-identified risks.


### With ISO 42001

ISO 42001 (AI management systems) incorporates risk-based thinking consistent with ISO 31000. Organizations can use ISO 31000 as the foundation for their ISO 42001 risk management processes.

**Integration approach:** ISO 42001 Clause 6 (Planning) requires risk assessment—use ISO 31000 process to fulfill this requirement; ISO 42001 Annex A controls address risk treatment—use ISO 31000 treatment framework to select and implement controls; ISO 42001 Clause 9 (Performance Evaluation) requires monitoring—use ISO 31000 monitoring and review approach.


### With EU AI Act

The EU AI Act requires risk management systems for high-risk AI. ISO 31000 principles and processes can structure compliance with these requirements.

**Integration approach:** EU AI Act Article 9 requires risk management system—ISO 31000 framework provides structure; Article 9 requires identification and analysis of known and foreseeable risks—ISO 31000 identification and analysis process fulfills this; Article 9 requires risk mitigation measures—ISO 31000 treatment options provide approach; Article 9 requires testing and monitoring—ISO 31000 monitoring and review provides methodology.

---


## Conclusion

ISO 31000 provides a universal language and methodology for risk management. For AI governance, it offers several key benefits:

1. **Proven foundation:** Decades of risk management experience in a single standard, applicable across industries and risk types

2. **Common language:** Facilitates communication between AI specialists and general risk management, enabling integration with enterprise risk management

3. **Integration:** Connects AI risk management to enterprise risk management, avoiding isolated AI governance processes

4. **Flexibility:** Adapts to different organizations and AI applications through customization principle

5. **Continuous improvement:** Emphasizes learning and adaptation, essential for rapidly evolving AI technology

The key insight is that AI risk management isn't separate from risk management—it's an application of it. Organizations with strong general risk management capabilities will find AI risk management more natural.

Start with ISO 31000 principles. Apply them using AI-specific considerations (data risks, model risks, system risks, human risks, external risks). Connect to specialized frameworks like the NIST AI RMF for detailed AI-specific guidance. The result is AI risk management that's both rigorous and practical, grounded in proven methodology while addressing unique AI challenges.

Whether pursuing ISO 42001 certification, complying with EU AI Act requirements, or simply building responsible AI practices, ISO 31000 provides the foundation. It's not the complete answer for AI governance, but it's the essential starting point—the universal risk management language and process that makes everything else work together.

---


## Sources and Further Reading

1. **ISO 31000:2018** - Risk management guidelines. Available for purchase at: iso.org/standard/65694.html

2. **ISO 31010:2019** - Risk assessment techniques (companion to ISO 31000). Available at: iso.org

3. **IEC 31010:2019** - Risk assessment techniques (identical to ISO 31010). Available at: iec.ch

4. **ISO Guide 73:2009** - Risk management vocabulary. Available at: iso.org

5. **NIST AI Risk Management Framework** - AI-specific guidance that complements ISO 31000. Available at: nist.gov/itl/ai-risk-management-framework

6. **ISO/IEC 23894:2023** - AI risk management guidance. Available at: iso.org

7. **COSO ERM Framework** - Alternative enterprise risk management framework. Available at: coso.org

8. **Institute of Risk Management (IRM)** - Risk management resources and training. Available at: theirm.org

9. **Risk Management Association** - Industry resources. Available at: rmahq.org

10. **Federation of European Risk Management Associations (FERMA)** - European perspective on risk management. Available at: ferma.eu

11. **ISO 31000 Plain English Guide** - Simplified explanation of the standard. Available through ISO member bodies

12. **Project Management Institute (PMI)** - Risk management in project context. Available at: pmi.org

---

*This article is part of the AI Governance Implementation Program. For the complete curriculum, visit suniliyer.ca or the AIDefence YouTube channel.*

**Next Article:** Article 72: ISO/IEC 23894 - AI Risk Management Guidance (Publishing: October 17, 2025)
