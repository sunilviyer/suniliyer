---
title: 'Article 65: Global AI Law Tracker – Who''s Regulating What'
tldr: ''
category: AI Risks & Principles
learning_objectives:
- Understand the key concepts and principles of ai governance frameworks
- Implement ethical ai principles in real-world scenarios
- Evaluate regulatory requirements for organizational compliance
seo_keywords:
- article
- global
- AI governance
- artificial intelligence
- AI compliance
components:
- type: image_prompt
  label: Article Hero Image
  section: Header
  id: image-prompt-hero
  prompt: balanced composition showing risk and safety elements, warning symbols with
    protective shields, legal documents, regulatory symbols, compliance checkmarks,
    professional illustration, modern flat design style, clean and authoritative,
    high quality, blue and gray color scheme with accent colors, suitable for professional
    article header
- type: flowchart
  label: Conclusion Process
  section: Conclusion
  id: flowchart-conclusion
- type: flowchart
  label: Sources and Further Reading Process
  section: Sources and Further Reading
  id: flowchart-sources-and-further-reading
- type: template
  label: '*Example'
  section: 'European Union: The Comprehensive Approach'
  id: template-european-union-the-comprehensive-approach
  template_link: /templates/example.md
- type: template
  label: '*Example'
  section: 'United States: The Patchwork'
  id: template-united-states-the-patchwork
  template_link: /templates/example.md
- type: template
  label: '*Example'
  section: 'China: The Control Model'
  id: template-china-the-control-model
  template_link: /templates/example.md
- type: template
  label: '*Example'
  section: 'United Kingdom: Pro-Innovation'
  id: template-united-kingdom-pro-innovation
  template_link: /templates/example.md
- type: template
  label: '*Example'
  section: 'Canada: AIDA and Beyond'
  id: template-canada-aida-and-beyond
  template_link: /templates/example.md
topic_fingerprint:
- foundation model
- generative ai
- transparency
- oversight
- trustworthy ai
named_examples:
- aida
- colorado ai act
- congress
- deepfakes
- eu ai act
- european commission
- executive order
- fintech
- ftc
- nist
- nyc local law 144
- stanford
word_count: 2022
processed_date: '2025-12-18T02:16:34.342Z'
---


## The Major Players: Detailed Breakdown


### European Union: The Comprehensive Approach

**Status:** AI Act passed (August 2024), phased implementation through 2027

**Key Features:**
- Risk-based classification (prohibited, high-risk, limited risk, minimal risk)
- Strict requirements for high-risk AI systems
- Foundation model obligations
- Massive penalties (up to 7% of global revenue)
- Extraterritorial reach (applies to non-EU companies serving EU markets)

**What's Regulated:**
- Hiring and recruitment AI
- Credit and insurance scoring
- Law enforcement applications
- Educational assessment tools
- Critical infrastructure AI
- Biometric systems

**Current Phase:**
- Prohibited AI practices: February 2025
- General-purpose AI rules: August 2025
- High-risk system requirements: August 2026

<!-- component:template:template-european-union-the-comprehensive-approach -->
*Example:* A US company selling AI hiring software to European clients must comply with EU AI Act requirements, including bias testing, documentation, and human oversight provisions.

---


### United States: The Patchwork

**Federal Level:**

**Status:** No comprehensive federal AI law, but significant executive action and agency guidance

**Key Developments:**
- Executive Order 14110 on Safe, Secure, and Trustworthy AI (October 2023)
- NIST AI Risk Management Framework
- Agency-specific guidance (FDA for healthcare AI, FTC for consumer protection)
- Proposed legislation (various bills pending)

**State Level:**

**Colorado AI Act (2024)**
- First comprehensive state AI law
- Focus on high-risk decisions affecting consumers
- Requires impact assessments and disclosure
- Effective: February 2026

**California (Various Laws)**
- AB 331: Automated decision tool regulations
- SB 1047: AI safety requirements (amended)
- Deepfake disclosure requirements
- Multiple bills in progress

**NYC Local Law 144**
- Regulates automated employment decision tools
- Requires annual bias audits
- Public disclosure of audit results
- Already in effect

**Illinois**
- Biometric Information Privacy Act (BIPA)
- AI Video Interview Act
- Strong employee notification requirements

**Texas**
- Proposed AI legislation
- Focus on government AI use

<!-- component:template:template-united-states-the-patchwork -->
*Example:* A company using AI for hiring in multiple US states might need to: conduct bias audits (NYC), provide disclosures (Illinois), and prepare for impact assessments (Colorado)—all with different specific requirements.

---


### China: The Control Model

**Status:** Multiple binding regulations in effect

**Key Laws:**
- Algorithm Recommendation Regulation (2022)
- Deep Synthesis (Deepfake) Rules (2023)
- Generative AI Measures (2023)

**What's Required:**
- Algorithm registration with authorities
- Content moderation to prevent "illegal" content
- Real-name verification for users
- Socialist core values compliance
- Data localization requirements

**Key Differences:**
- Much heavier content control
- Government access to algorithms
- Focus on social stability
- Less emphasis on individual rights

<!-- component:template:template-china-the-control-model -->
*Example:* Any AI company operating in China must register their algorithms with the Cyberspace Administration and ensure AI outputs align with government content standards.

---


### United Kingdom: Pro-Innovation

**Status:** Principles-based approach via existing regulators

**Framework:**
- Five principles (safety, transparency, fairness, accountability, contestability)
- Sector-specific implementation
- No single AI law
- AI Safety Institute for advanced AI risks

**Regulators Involved:**
- Information Commissioner's Office (ICO)
- Financial Conduct Authority (FCA)
- Competition and Markets Authority (CMA)
- Ofcom
- Various sector regulators

<!-- component:template:template-united-kingdom-pro-innovation -->
*Example:* A UK fintech using AI for credit decisions follows FCA guidance on AI in financial services, ICO requirements for automated decision-making, and general fairness principles.

---


### Canada: AIDA and Beyond

**Status:** AIDA (Artificial Intelligence and Data Act) pending as part of Bill C-27

**Key Provisions:**
- High-impact AI system designation
- Impact assessments required
- Transparency obligations
- New AI and Data Commissioner role
- Significant penalties

**Current Reality:**
- Bill has faced delays
- Provincial laws also emerging
- Quebec's Bill 64 affects AI data use

<!-- component:template:template-canada-aida-and-beyond -->
*Example:* A Canadian bank using AI for loan decisions will need to assess whether the system qualifies as "high-impact" and implement corresponding safeguards once AIDA passes.

---


## Regional Overviews


### Asia-Pacific

**Japan**
- Status: Soft law approach
- Key: AI Guidelines for Business (voluntary)
- Trend: Moving toward binding rules
- Focus: Privacy, safety, security

**South Korea**
- Status: AI Framework Act under consideration
- Key: AI Ethics Standards (2020)
- Trend: Increasing regulation
- Focus: High-risk AI, data protection

**Singapore**
- Status: Model AI Governance Framework (voluntary)
- Key: Practical, business-friendly guidance
- Trend: Light touch but comprehensive
- Focus: Accountability, transparency

**Australia**
- Status: Voluntary AI Ethics Framework
- Key: Eight AI ethics principles
- Trend: Consultation on mandatory rules
- Focus: High-risk AI applications

**India**
- Status: No comprehensive law yet
- Key: Draft AI regulations under development
- Trend: Sector-specific rules emerging
- Focus: Government AI use, data protection

---


### Latin America

**Brazil**
- Status: AI Bill (PL 2338/2023) advancing
- Key: Risk-based approach similar to EU
- Trend: Comprehensive legislation likely
- Focus: Fundamental rights, transparency

**Mexico**
- Status: Proposed legislation pending
- Key: Various bills introduced
- Trend: Watching regional developments
- Focus: Government AI use

**Argentina**
- Status: National AI strategy but limited binding rules
- Key: Ethical AI principles
- Trend: Regulatory development ongoing
- Focus: Public sector AI

**Chile**
- Status: AI policy in development
- Key: Principles-based approach
- Trend: Looking at EU model
- Focus: Transparency, accountability

---


### Middle East and Africa

**United Arab Emirates**
- Status: AI strategy and guidelines
- Key: AI Minister appointed
- Trend: Proactive AI development
- Focus: Economic growth, safety

**Saudi Arabia**
- Status: National AI strategy
- Key: Focus on development over regulation
- Trend: Rules emerging
- Focus: Economic diversification

**Israel**
- Status: Policy documents and guidelines
- Key: Privacy-focused rules
- Trend: Increased attention to AI governance
- Focus: Innovation and security balance

**South Africa**
- Status: Draft AI policy framework
- Key: Focus on ethical AI
- Trend: Regulatory development
- Focus: Inequality, access

**Kenya**
- Status: AI strategy in development
- Key: Focus on opportunity
- Trend: Early stage
- Focus: Development, privacy

**Nigeria**
- Status: National AI strategy (2023)
- Key: Focus on development
- Trend: Regulatory framework emerging
- Focus: Economic growth

---


## Key Regulatory Patterns


### What Almost Everyone Agrees On

Across all these different approaches, certain themes keep appearing:

**1. High-Risk AI Needs More Oversight**

Whether it's the EU's detailed classification or Singapore's guidance, everyone agrees that AI used for consequential decisions (hiring, credit, healthcare, law enforcement) needs extra safeguards.

**2. Transparency Is Essential**

People should know when AI is being used to make decisions about them. This requirement appears in virtually every framework worldwide.

**3. Human Oversight Matters**

Even automated systems need human involvement, especially for significant decisions. The exact requirements vary, but the principle is universal.

**4. Accountability Must Be Clear**

Someone needs to be responsible when AI goes wrong. Organizations can't hide behind "the algorithm did it."

**5. Bias and Discrimination Are Concerns**

AI systems shouldn't discriminate unfairly. This connects to existing anti-discrimination laws but applies them to algorithmic contexts.

---


### Where Countries Diverge

**Prescriptive vs. Principles-Based**

- EU: Detailed requirements, specific rules
- UK: Broad principles, sector adaptation
- Singapore: Practical guidance, flexibility

**Government Access**

- China: Extensive government oversight of algorithms
- EU/US: Limited government access, privacy protections
- Others: Varying approaches

**Content Control**

- China: Heavy content requirements
- EU: Focus on illegal content, disinformation
- US: Speech protections limit content rules

**Enforcement Approach**

- EU: Heavy fines, new enforcement bodies
- US: Existing agencies, varied enforcement
- Asia: Often softer enforcement initially

---


## Practical Tracking Tools and Resources


### Official Government Sources

**European Union:**
- EUR-Lex for official legislation
- European Commission AI webpage
- EU AI Office announcements

**United States:**
- State legislature websites
- FTC, FDA, EEOC guidance
- WhiteHouse.gov for executive orders

**United Kingdom:**
- gov.uk for policy documents
- Regulator websites (ICO, FCA, etc.)

**International:**
- OECD AI Policy Observatory (oecd.ai)
- UNESCO AI resources
- World Economic Forum AI governance


### Non-Governmental Trackers

**IAPP AI Governance Resource Center**
- Comprehensive tracker of global AI laws
- Regular updates and analysis
- Member resources

**Stanford HAI AI Index**
- Annual report on AI developments
- Policy tracking across countries
- Comparative analysis

**Future of Life Institute**
- AI policy tracking
- Focus on safety and governance
- International coverage

**Access Now**
- Human rights perspective on AI
- Policy tracking
- Advocacy reports

---


## Building Your Tracking System


### For Organizations

If you're responsible for AI compliance across multiple jurisdictions, here's a practical approach:

**Step 1: Map Your Exposure**

Identify every country where you:
- Have customers
- Have employees
- Process data
- Provide services
- Have physical presence

**Step 2: Prioritize by Risk**

Not all jurisdictions matter equally. Focus first on:
- Jurisdictions with binding laws (EU, China, certain US states)
- Places with significant business operations
- Markets you're planning to enter

**Step 3: Create a Monitoring System**

- Subscribe to regulatory updates from key jurisdictions
- Follow relevant law firms and consultancies
- Join industry associations that track developments
- Set regular review cadences (monthly, quarterly)

**Step 4: Build Flexibility In**

Design compliance programs that can adapt:
- Use principles-based frameworks that satisfy multiple jurisdictions
- Document in ways that work for various regulatory requirements
- Build systems that can be adjusted as laws change

---


## Future Trends to Watch


### Convergence or Divergence?

The big question: Will global AI regulation converge toward common standards or fragment further?

**Arguments for Convergence:**
- International organizations pushing harmonization
- Companies wanting consistent rules
- AI principles are broadly similar worldwide
- Trade agreements may include AI provisions

**Arguments for Divergence:**
- Different political systems, different priorities
- China vs. West divide likely to persist
- Economic competition through regulatory arbitrage
- Cultural differences in privacy, autonomy values

**Most Likely Outcome:**
Partial convergence on principles, continued divergence on specifics. International companies will need to navigate this complexity for the foreseeable future.


### Emerging Regulatory Targets

Watch for new rules on:
- Foundation models and general-purpose AI
- AI-generated content and deepfakes
- AI in elections and democratic processes
- AI and environmental impact
- AI in children's products and services
- Autonomous systems (vehicles, weapons)

---


## Conclusion

Global AI regulation is complex, varied, and constantly evolving. No single article can capture every development, and anything written today may need updating tomorrow.

But the fundamental landscape is clear:

- **The EU** leads on comprehensive, binding regulation
- **The US** has a patchwork that varies by state and sector
- **China** prioritizes control and content oversight
- **The UK** experiments with principles-based, regulator-led governance
- **Most other countries** are somewhere in between, watching and learning

For AI governance professionals, this means:

<!-- component:flowchart:flowchart-conclusion -->
1. **Stay informed** about developments in relevant jurisdictions
2. **Build flexible** compliance programs
3. **Plan for change** as laws evolve
4. **Focus on principles** that satisfy multiple requirements
5. **Track enforcement** to understand how rules are actually applied

The companies that succeed will be those that see this complexity not as a burden but as a competitive advantage. Understanding global AI regulation isn't just about avoiding penalties—it's about building trust with customers worldwide.

---


## Sources and Further Reading

1. **OECD AI Policy Observatory** - Comprehensive database of AI policies worldwide. Available at: oecd.ai

2. **European Union AI Act** - Official legislation and guidance. Available at: digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai

3. **US Executive Order 14110** - Safe, Secure, and Trustworthy AI. Available at: whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/

4. **Colorado AI Act (SB 21-169)** - State legislation text. Available at: leg.colorado.gov

5. **NYC Local Law 144** - Automated employment decision tools. Available at: rules.cityofnewyork.us

6. **China Cyberspace Administration** - Algorithm and AI regulations. Available at: cac.gov.cn (in Chinese)

7. **UK Government** - Pro-innovation AI regulation. Available at: gov.uk/government/publications/ai-regulation-a-pro-innovation-approach

8. **IAPP** - AI Governance Global Tracker. Available at: iapp.org/resources/topics/artificial-intelligence/

9. **Stanford HAI** - AI Index Report and policy tracking. Available at: hai.stanford.edu

10. **UNESCO** - Recommendation on the Ethics of AI. Available at: unesco.org/en/artificial-intelligence/recommendation-ethics

11. **World Economic Forum** - AI governance resources. Available at: weforum.org/topics/artificial-intelligence-and-robotics/

12. **Brazil AI Bill (PL 2338/2023)** - National Congress tracking. Available at: camara.leg.br

---

*This article is part of the AI Governance Implementation Program. For the complete curriculum, visit suniliyer.ca or the AIDefence YouTube channel.*
