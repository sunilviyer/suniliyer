---
title: 'Article 136: The Future of AI Regulation – What''s Coming Next'
tldr: ''
category: AI Laws
learning_objectives:
- Understand the key concepts and principles of ai governance frameworks
- Implement model validation processes in real-world scenarios
- Evaluate regulatory requirements for organizational compliance
seo_keywords:
- article
- future
- AI governance
- artificial intelligence
- AI risk management
components:
- type: image_prompt
  label: Article Hero Image
  section: Header
  id: image-prompt-hero
  prompt: legislative building, legal codes, international flags, compliance checkmarks,
    legal documents, regulatory symbols, compliance checkmarks, professional illustration,
    modern flat design style, clean and authoritative, high quality, blue and gray
    color scheme with accent colors, suitable for professional article header
- type: table
  label: Provision vs Effective Date Table
  section: 'The EU AI Act: The Global Standard-Setter'
  id: table-the-eu-ai-act-the-global-standard-setter
- type: table
  label: State vs Key Law Table
  section: 'United States: Patchwork Becoming Pattern'
  id: table-united-states-patchwork-becoming-pattern
- type: table
  label: Jurisdiction vs Status Table
  section: Other Major Jurisdictions
  id: table-other-major-jurisdictions
- type: table
  label: Type vs Requirement Table
  section: 'Trend 2: Transparency and Disclosure'
  id: table-trend-2-transparency-and-disclosure
- type: table
  label: Mechanism vs Where Required Table
  section: 'Trend 4: Accountability Mechanisms'
  id: table-trend-4-accountability-mechanisms
- type: table
  label: Element vs Purpose Table
  section: Building Regulatory-Ready Governance
  id: table-building-regulatory-ready-governance
- type: flowchart
  label: Conclusion Process
  section: Conclusion
  id: flowchart-conclusion
- type: flowchart
  label: Sources and Further Reading Process
  section: Sources and Further Reading
  id: flowchart-sources-and-further-reading
topic_fingerprint:
- foundation model
- generative ai
- machine learning
- transparency
- accountability
named_examples:
- aida
- canada aida
- colorado ai act
- eu ai act
- european parliament
- executive order
- fair
- federal trade commission
- ftc
- iec
- ieee
- international organization for standardization
- iso
- national institute of standards
- nist
- nyc local law 144
- white house
word_count: 1942
processed_date: '2025-12-18T20:05:32.091Z'
---


## The Current Regulatory Landscape


### The EU AI Act: The Global Standard-Setter

The EU AI Act, which entered into force in 2024, is the world's first comprehensive AI law:

**Key features:**
- Risk-based classification (prohibited, high-risk, limited risk, minimal risk)
- Extensive requirements for high-risk AI systems
- Foundation model obligations
- Transparency requirements
- Significant penalties (up to 7% of global revenue)

**Timeline:**
| Provision | Effective Date |
<!-- component:table:table-the-eu-ai-act-the-global-standard-setter -->
|-----------|---------------|
| Prohibited practices | February 2025 |
| GPAI/Foundation model rules | August 2025 |
| Most high-risk requirements | August 2026 |
| Certain product safety AI | August 2027 |

**Global impact:**
The "Brussels Effect"—companies building for the EU market often apply EU standards globally, making the AI Act a de facto global standard.


### United States: Patchwork Becoming Pattern

The U.S. lacks comprehensive federal AI legislation but has significant activity:

**Federal:**
- Executive Order on AI (October 2023): Reporting requirements, safety standards development, agency guidance
- NIST AI Risk Management Framework: Voluntary but influential
- Agency enforcement: FTC, EEOC, CFPB, FDA all active on AI

**State level:**
| State | Key Law | Focus |
<!-- component:table:table-united-states-patchwork-becoming-pattern -->
|-------|---------|-------|
| Colorado | Colorado AI Act | Consumer protection, high-risk systems |
| California | Various bills | Transparency, employment, safety |
| Illinois | BIPA, AI Video Interview Act | Biometrics, hiring |
| New York City | Local Law 144 | Hiring AI bias audits |
| Texas | Deepfake laws | Election integrity |

**Emerging federal proposals:**
- Algorithmic Accountability Act
- AI RIGHTS Act
- Various sector-specific bills


### China: Control-Oriented Regulation

China has enacted multiple AI-specific regulations:

**Key regulations:**
- Algorithm Recommendation Regulations (2022)
- Deep Synthesis (Deepfake) Regulations (2023)
- Generative AI Regulations (2023)

**Characteristics:**
- Content control focus
- Registration requirements
- State oversight mechanisms
- Different philosophy than Western approaches


### Other Major Jurisdictions

| Jurisdiction | Status | Approach |
<!-- component:table:table-other-major-jurisdictions -->
|--------------|--------|----------|
| UK | Post-Brexit framework | Pro-innovation, sector-led |
| Canada | AIDA (proposed) | Federal framework pending |
| Brazil | AI Bill (advancing) | Rights-based approach |
| Japan | Guidelines-based | Flexible, innovation-friendly |
| Singapore | Model framework | Business-friendly, voluntary |
| India | Emerging framework | Sector-specific focus |
| Australia | Guidelines, proposed legislation | Risk-based approach |

---


## Key Regulatory Trends


### Trend 1: Risk-Based Regulation

**The pattern:** Regulations increasingly categorize AI systems by risk level, with requirements proportional to potential harm.

**Examples:**
- EU AI Act's four-tier system
- Colorado AI Act's high-risk focus
- NIST AI RMF's risk management approach

**What this means:**
- Not all AI faces the same requirements
- High-stakes uses (hiring, credit, healthcare) face most scrutiny
- Low-risk applications largely unregulated
- Risk assessment becomes critical compliance activity

**Practical implication:** Organizations need robust AI risk classification processes.


### Trend 2: Transparency and Disclosure

**The pattern:** Requirements to tell people when they're interacting with AI and what AI is doing.

**Examples:**
- EU AI Act: Disclosure when interacting with AI systems
- California Bot Disclosure Law: Bots must identify themselves
- NYC Local Law 144: Public disclosure of bias audit results
- FTC: Deceptive AI practices enforcement

**Types of transparency:**
| Type | Requirement |
<!-- component:table:table-trend-2-transparency-and-disclosure -->
|------|-------------|
| Interaction disclosure | Tell users they're dealing with AI |
| Decision explanation | Explain how AI reached a decision |
| Audit disclosure | Publish audit results |
| Training data disclosure | Describe what AI was trained on |

**Practical implication:** Build disclosure into AI systems from the start.


### Trend 3: Sector-Specific Rules

**The pattern:** AI rules tailored to specific industries, often building on existing regulatory frameworks.

**Key sectors:**
- **Healthcare:** FDA guidance on AI/ML medical devices
- **Financial services:** Banking regulator guidance, model risk management
- **Employment:** EEOC guidance, state hiring AI laws
- **Insurance:** State insurance commissioner guidance
- **Housing:** Fair housing AI concerns

**Why sector-specific:**
- Different risk profiles
- Existing regulatory expertise
- Industry-specific concerns
- Faster to implement than comprehensive law

**Practical implication:** Know your sector's specific AI requirements.


### Trend 4: Accountability Mechanisms

**The pattern:** Moving from voluntary commitments to enforceable accountability.

**Mechanisms emerging:**
- Impact assessments (required documentation of AI effects)
- Audit requirements (independent examination)
- Registration/notification (telling regulators about AI systems)
- Conformity assessment (proving compliance before deployment)

**Examples:**
| Mechanism | Where Required |
<!-- component:table:table-trend-4-accountability-mechanisms -->
|-----------|---------------|
| Algorithmic impact assessment | NYC (proposed), Canada AIDA |
| Bias audit | NYC Local Law 144 |
| Conformity assessment | EU AI Act (high-risk) |
| Registration | EU AI Act database, China |

**Practical implication:** Prepare for external accountability, not just internal governance.


### Trend 5: International Coordination (and Fragmentation)

**The pattern:** Efforts to coordinate internationally, but significant divergence remaining.

**Coordination efforts:**
- G7 AI principles
- OECD AI Policy Observatory
- UN discussions
- Bilateral agreements

**Fragmentation reality:**
- EU, U.S., China approaches fundamentally different
- No global standard emerging
- Companies face multiple compliance regimes
- "Brussels Effect" provides some de facto harmonization

**Practical implication:** Plan for multi-jurisdictional compliance.

---


## What's Coming Next: Predictions


### Near-Term (2025-2026)

**Highly likely:**
- EU AI Act implementation and enforcement begins
- More U.S. state AI laws
- Increased federal agency enforcement
- Sector-specific guidance expansion

**Probable:**
- More countries adopt comprehensive AI laws
- First significant EU AI Act enforcement actions
- Federal AI legislation advances (though may not pass)
- Standards development accelerates (ISO, NIST)

**Possible:**
- Major AI incident drives emergency regulation
- International coordination breakthrough
- Significant court decisions on AI liability


### Medium-Term (2027-2030)

**Expected:**
- Mature EU AI Act compliance ecosystem
- Federal U.S. AI legislation (in some form)
- AI auditing profession established
- Insurance market for AI risks developed

**Likely:**
- Liability frameworks clarified by courts
- International frameworks emerge (at least among allies)
- Automated enforcement of AI regulations
- AI used to regulate AI

**Possible:**
- Global AI treaty (limited scope)
- Major regulatory failure prompts overhaul
- AI capabilities outpace regulatory frameworks


### Long-Term (2030+)

**The big questions:**
- Will AGI require fundamentally different governance?
- Can national regulation address global AI development?
- Will technical standards or legal rules dominate?
- How will AI liability frameworks evolve?

---


## Preparing Your Organization


### Assessment: Where Are You Today?

**Inventory your AI:**
- What AI systems do you use or develop?
- What decisions do they affect?
- What jurisdictions are they deployed in?
- What risk level are they under emerging frameworks?

**Gap analysis:**
- Current practices vs. EU AI Act requirements
- Current practices vs. U.S. state laws
- Current practices vs. sector-specific guidance
- Documentation and audit readiness


### Building Regulatory-Ready Governance

**Governance structure:**
| Element | Purpose |
<!-- component:table:table-building-regulatory-ready-governance -->
|---------|---------|
| AI governance committee | Oversight and accountability |
| Responsible AI lead | Day-to-day governance |
| Cross-functional team | Legal, tech, business integration |
| Reporting structure | Board and executive visibility |

**Core processes:**
- AI inventory and classification
- Risk assessment methodology
- Impact assessment procedures
- Documentation requirements
- Monitoring and audit

**Documentation essentials:**
- Technical documentation (per AI Act requirements)
- Risk assessments
- Testing and validation records
- Human oversight procedures
- Incident logs


### Monitoring Regulatory Developments

**What to watch:**
- Legislative developments in key jurisdictions
- Regulatory guidance and enforcement
- Court decisions on AI liability
- Standards development (ISO, NIST, IEEE)
- Industry best practices

**Resources:**
- IAPP (International Association of Privacy Professionals)
- AI-specific regulatory trackers
- Law firm alerts
- Industry association updates
- Academic and policy research


### Strategic Positioning

**Proactive approach:**
- Engage with regulatory development processes
- Participate in standards setting
- Join industry coalitions
- Share best practices

**Competitive advantage:**
- Early compliance builds trust
- Governance infrastructure takes time
- Being ahead reduces scramble risk
- Reputation for responsibility matters

---


## Regulatory Scenarios: Planning for Uncertainty


### Scenario 1: Accelerated Regulation

**Trigger:** Major AI incident (autonomous vehicle deaths, healthcare AI harm, election manipulation)

**What happens:**
- Emergency legislation
- Aggressive enforcement
- International coordination pressure
- Public backlash against AI

**Preparation:**
- Robust incident response plans
- Conservative AI deployment
- Strong documentation
- Stakeholder communication ready


### Scenario 2: Regulatory Fragmentation

**Trigger:** U.S.-EU-China divergence continues; no coordination

**What happens:**
- Multiple compliance regimes
- Market fragmentation
- Increased compliance costs
- Competitive distortions

**Preparation:**
- Multi-jurisdictional compliance program
- Flexible governance frameworks
- Clear jurisdiction analysis
- Localized AI systems where needed


### Scenario 3: Industry Self-Regulation

**Trigger:** Government regulation stalls; industry steps up

**What happens:**
- Industry standards dominate
- Certification schemes emerge
- Variable compliance
- Faster evolution of practices

**Preparation:**
- Participate in industry initiatives
- Lead on standards development
- Build certification capability
- Document voluntary commitments


### Scenario 4: Technical Standards Leadership

**Trigger:** ISO/NIST/IEEE standards gain legal force

**What happens:**
- Standards become compliance baseline
- Certification becomes essential
- Technical expertise at premium
- Clearer compliance path

**Preparation:**
- Engage with standards development
- Build standards-based governance
- Develop certification relationships
- Train staff on standards

---


## Key Regulatory Questions to Watch


### The Liability Question

**Unresolved:** When AI causes harm, who's liable?

**Competing answers:**
- Traditional product liability (adapted)
- New AI-specific liability frameworks
- Insurance-based approaches
- Regulatory enforcement focus

**Watch:** EU AI Liability Directive development, U.S. court decisions


### The Foundation Model Question

**Unresolved:** How should general-purpose AI models be regulated?

**Challenges:**
- Many applications, varying risk
- Provider vs. deployer responsibility
- Open source complications
- Rapid capability evolution

**Watch:** EU AI Act GPAI implementation, U.S. executive order implementation


### The Cross-Border Question

**Unresolved:** How to govern AI that crosses jurisdictions?

**Issues:**
- Extraterritorial reach of regulations
- Data localization and AI
- Enforcement across borders
- Harmonization vs. sovereignty

**Watch:** International coordination efforts, trade agreement provisions


### The Enforcement Question

**Unresolved:** How will AI regulations actually be enforced?

**Challenges:**
- Technical complexity
- Resource constraints
- Rapidly evolving technology
- Global nature of AI development

**Watch:** Early EU AI Act enforcement, agency capacity building

---


## Conclusion

The future of AI regulation is more regulation—the only questions are form, timing, and scope. The EU AI Act provides a model that others will adapt. The U.S. patchwork is becoming a pattern. Sector-specific rules are expanding. Accountability mechanisms are strengthening.

For organizations, the strategic implications are clear:

<!-- component:flowchart:flowchart-conclusion -->
1. **Regulation is coming:** The question isn't whether but when and what form
2. **Build infrastructure now:** Governance takes time; starting early provides advantage
3. **Monitor actively:** The landscape changes rapidly
4. **Prepare for multiple scenarios:** Flexibility is essential
5. **Engage proactively:** Influence the rules rather than just react

Organizations that treat AI governance as a strategic priority—not just a compliance burden—will be best positioned for whatever regulatory future emerges. Those that wait will face scramble, cost, and competitive disadvantage.

The regulatory future is being written now. The time to prepare is today.

---


## Sources and Further Reading

1. **EU AI Act:** European Parliament and Council. (2024). Regulation (EU) 2024/1689 laying down harmonised rules on artificial intelligence.

2. **U.S. Executive Order on AI:** The White House. (2023). Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence.

3. **NIST AI RMF:** National Institute of Standards and Technology. (2023). AI Risk Management Framework 1.0.

4. **Colorado AI Act:** Colorado General Assembly. (2024). SB24-205 Consumer Protections for Artificial Intelligence.

5. **NYC Local Law 144:** New York City Department of Consumer and Worker Protection. (2023). Automated Employment Decision Tools.

6. **China Generative AI Regulations:** Cyberspace Administration of China. (2023). Interim Measures for the Management of Generative Artificial Intelligence Services.

7. **Canada AIDA:** Parliament of Canada. Bill C-27, Part 3: Artificial Intelligence and Data Act.

8. **OECD AI Policy Observatory:** OECD. AI policy developments tracker. https://oecd.ai/

9. **FTC AI Enforcement:** Federal Trade Commission. AI and algorithm enforcement actions and guidance.

10. **FDA AI/ML Guidance:** U.S. Food and Drug Administration. Artificial Intelligence and Machine Learning in Software as a Medical Device.

11. **ISO/IEC 42001:** International Organization for Standardization. (2023). AI Management System Standard.

12. **IAPP AI Governance Resources:** IAPP. AI governance center. https://iapp.org/

---

*This article is part of the AI Governance Mastery Program by AIDefence (suniliyer.ca). For more resources on AI governance, visit the complete article series.*
