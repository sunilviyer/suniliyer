{\rtf1\ansi\ansicpg1252\cocoartf2867
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 article_id: "term-04"\
title: "Foundation Models"\
slug: "foundation-models"\
path: "terminology"\
header_image: "/images/terminology/foundation-models.png"\
navigation:\
  prev:\
    slug: "/terminology/data-behind-ai"\
    title: "The Data Behind AI"\
  next:\
    slug: "/terminology/multimodal-ai"\
    title: "Multimodal AI"\
key_learnings:\
  - "Foundation models are large-scale systems trained on broad data that can be adapted to many different tasks."\
  - "The shift to foundation models allows organizations to specialize one model for many uses rather than building new models from scratch."\
  - "Homogenization risk means that a single flaw in a foundation model can cascade through every application built on top of it."\
  - "The EU AI Act regulates these as 'General-Purpose AI' (GPAI) models, with stricter rules for those posing 'systemic risk.'"\
  - "Adaptation through prompting or fine-tuning allows these general systems to solve specific business problems."\
read_time: "8 min read"\
updated_date: "January 2025"\
tags:\
  - Foundation Models\
  - GPAI\
  - AI Infrastructure\
seo:\
  description: "Learn what foundation models are and why they have become the primary building blocks of modern AI systems like GPT-4 and Claude."\
  keywords:\
    - foundation models\
    - general purpose AI\
    - GPAI\
    - transfer learning\
    - model adaptation\
content: |\
  <h2>The Skyscraper and the Foundation</h2>\
  <p>Think of it this way: In the past, if you wanted to build a house, you built a unique foundation specifically for that one structure. If you then wanted a warehouse, you started from scratch with a different foundation. In the world of AI, we used to do the same\'97we built one specialized model for translation, another for sentiment analysis, and a third for summarizing reports.</p>\
  <p>Here is the key insight: We have moved to a world where we build one massive, incredibly strong foundation that can support a skyscraper, a cottage, or a warehouse all at once. In AI, we call these <strong>foundation models</strong>. They are large models trained on a broad ocean of data that can be adapted to a wide range of downstream tasks.</p>\
\
  <h2>Scale and Emergence</h2>\
  <p>You might wonder what makes these models so much more powerful than the tools of five years ago. It comes down to scale\'97billions or even trillions of parameters trained on a substantial portion of the written internet. This broad training allows the model to learn language patterns, facts, and reasoning skills that it was never explicitly told to learn.</p>\
  <p>We call these emergent capabilities. For example, a model trained primarily to predict the next word in a sentence might suddenly "emerge" with the ability to write computer code or solve logic puzzles. Because these models, such as a <card type="article-link" id="article-link-large-language-models">Large Language Model (LLM)</card>, serve as the base for many different products, they have become the essential infrastructure of the modern AI ecosystem.</p>\
\
  <h2>The Governance Jenga Tower</h2>\
  <p>While foundation models make development faster and cheaper, they introduce a significant challenge for leadership: homogenization risk. If a single foundation model has a hidden bias or a security flaw, every application your company builds on top of it inherits that same flaw. If the foundation is unstable, the whole building is at risk.</p>\
  <p>This is why the <card type="framework" id="fw-eu-ai-act">EU AI Act</card> created a special category for these systems called General-Purpose AI (GPAI). Regulators recognize that because these models are "general," their risks are also general. Providers must now document their training data and comply with copyright laws to ensure the foundation they provide to the rest of us is reliable.</p>\
\
  <h2>How We Specialize</h2>\
  <p>Most organizations don't need to build their own foundation model from scratch\'97which can cost over $100 million in compute power alone. Instead, we adapt existing models to our needs. You might use fine-tuning to teach a model your company's specific legal terminology, or use <card type="concept" id="concept-rag">Retrieval-Augmented Generation (RAG)</card> to ensure the model only answers questions using your private internal documents.</p>\
  <p>By using these general building blocks, we can achieve high performance on specialized tasks without the "skyscrapers" cost. As a leader, your role is to ensure that the foundation model you select is well-documented, tested for your specific use cases, and monitored for the unexpected capabilities that may emerge as the technology continues to advance.</p>}